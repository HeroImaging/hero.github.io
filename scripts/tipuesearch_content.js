var tipuesearch = {"pages": [
{"title": "Home", "text": "Welcome to MICE Toolkit! These pages will eventually contain all documentation for MICE Toolkit and will be updated regularly. Please check back soon for more information. MICE Toolkit (Medical Interactive Creative Environment) is a graphical programming user interface that is user friendly while still highly flexible. Complex image analysis processes can be constructed rapidly, and users can easily share workflows with the community in a standardized way, which makes it an ideal platform for research. The aim is to make advanced and complex image processing and analysis available to all professionals, including medical fields such as radiotherapy, radiology and pathology. MICE Toolkit provides advanced tools for complex processing and analysis which will simplify the work process and make it far less time consuming to generate results suited to the users particular needs – be it further analysis or formal presentation of your research. Downloading The latest stable release of MICE Toolkit is version 1.1.0, you can download it here: Download Stable v1.1.0 Installing Install the software by running the downloaded .exe file. The installation requires approximately 1.5GB of free space. License To run the software a license is needed. If you don't have a license you can register for a lite license HERE. In order to use all features you need a premium license. You can order one HERE. The license is verified against a license server when you run the software. If you have a premium license you need an internet connection to get access to all of the features in your license. Virtual Machines You can use a lite license on a virtual machine, however the premium license can only be run on physical machines. If you need to use your premium license on a virtual machine, please contact us. Remote Desktop If you want to run MICE Toolkit via windows built in remote desktop (RDP) you need to start MICE Toolkit locally on the machine before you connect. This is due to the way windows handle graphics in the remote desktop software. Other remote desktop software like VNC seems to work fine. Hardware Requirements OS We recommend using Windows 10 but it will run on Windows 7, 8 and 8.1 as well. CPU MICE Toolkit uses the CPU with multiple threads for most of the processing so a fast multi core CPU is preferred. Memory Image analysis is memory intense! We recommend at least 8GB of RAM for most applications. Graphics MICE Toolkit uses VTK to visualize images, so before deciding on a graphics card please read the following statement taken from the VTK/FAQ: Modern graphics cards that supports OpenGL 2.1 or better typically provide all the functionality that VTK needs. However, there is good deal of variability in results across OS platform and vendor's OpenGL implementation. NVidia cards and drivers work the best. Intel HD integrated graphics and ATI Radeon HD devices and drivers are known to have a few issues. Mesa3D OpenGL although claiming support for a wide range of devices is highly unstable and the overall buggy-ness of their implementation changes daily and by renderer. Mesa's llvmpipe drivers are expected to generally work well. Our experience tells us that cards from NVidia are the most compatible. Disk Space The installation requires approximately 1.5GB of free space. ", "tags": "", "url": "home.html"},
{"title": "Add", "text": "Add Class: NodeImageAdd Adds two or more images together element-wise, or a scalar to an image. If multiple images are added, matrix sizes must be equal. Example workflows Simple math operations example Inputs Add One or multiple images to be added. If multiple images are added, the matrix sizes must be equal. Type: Image4DFloat, Required, Multiple Outputs Out The resulting image. Type: Image4DFloat Settings Number Number The scalar to add to an image. Disregarded if more than one image is connected to the input. Keywords: Math ", "tags": "", "url": "nodes.image.math._operations.add.html"},
{"title": "Subtract", "text": "Subtract Class: NodeImageSubtract Subtracts two or more images from another element-wise, or a scalar from an image. If one or several images are subtracted from another, all matrix sizes must be equal. Example workflows Simple math operations example Inputs Image The image which is to be subtracted from. Type: Image4DFloat, Required, Single Subtract One or multiple images to be subtracted from the first input image. Must be of equal matrix size to the first input image. Type: Image4DFloat, Optional, Multiple Outputs Out The resulting image. Type: Image4DFloat Settings Number Number The scalar to subtract from an image. Disregarded if more than one image is connected to the inputs. Keywords: Math ", "tags": "", "url": "nodes.image.math._operations.subtract.html"},
{"title": "Multiply", "text": "Multiply Class: NodeImageMultiply Multiplies two or more images together element-wise, or an image with a scalar. If multiple images are multiplied, matrix sizes must be equal. Example workflows Simple math operations example Inputs Multiply Images One or multiple images to be multiplied. If a single image is connected, it will be multiplied with the scalar specified in the Node settings. Multiple images to be multiplied must be of equal matrix size. Type: Image4DFloat, Required, Multiple Outputs Out The resulting image. Type: Image4DFloat Settings Scalar Number The scalar to multiply with an image. Disregarded if more than one image is connected to the input. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.multiply.html"},
{"title": "Divide", "text": "Divide Class: NodeImageDivide Divides one image with one or multiple others element-wise, or an image by a scalar. If an image is divided by one or several others, all matrix sizes must be equal. Example workflows Simple math operations example Inputs Image The image which is to be divided. Type: Image4DFloat, Required, Single Divide Images One or multiple images to divide the first input image with. Must be of equal matrix size to the first input image. No elements in these images can be 0. Type: Image4DFloat, Optional, Multiple Outputs Out The resulting image. Type: Image4DFloat Settings Scalar Number Divide the input with this scalar. Disregarded if more than one image is connected to the inputs. Cannot be 0. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.divide.html"},
{"title": "Absolute Value", "text": "Absolute Value Class: NodeImageAbs Calculates the absolute value of each voxel in the image. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Out The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.absolute_value.html"},
{"title": "Ceiling", "text": "Ceiling Class: NodeImageCeiling Rounds each voxel value to the closest, larger integer. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Out The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.ceiling.html"},
{"title": "Floor", "text": "Floor Class: NodeImageFloor Rounds each voxel value to the closest, smaller integer. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Result The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.floor.html"},
{"title": "Round", "text": "Round Class: NodeImageRound Rounds each voxel value to the closest integer. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Result The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.round.html"},
{"title": "Raise To Power", "text": "Raise To Power Class: NodeImageRaiseToPower Raise each voxel \(A_i\) in the input image to the power of the voxel value in the secondary input image(s) \(B_{i,j}\), or by a scalar. \[ \begin{equation} R_i = A_i^{\sum_j{B_{i,j}}} \label{eq:sample} \end{equation} \] If multiple inputs are used, all matrix sizes must be equal. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Raise to One or multiple images containing the values with which to raise the primary input image. Type: Image4DFloat, Optional, Single Outputs Out The resulting image. Type: Image4DFloat Settings Number Number Raise each voxel in the input image to the power of specified number. Disregarded if an image is connected to the secondary input. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.raise_to_power.html"},
{"title": "Square Root", "text": "Square Root Class: NodeImageSquareRoot Calculate the square root of each voxel in the input image. Example workflows Simple math operations example Inputs Image The input image. All elements must be \(&gt;0\). Type: Image4DFloat, Required, Single Outputs Result The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.square_root.html"},
{"title": "Principal Component Analysis", "text": "PCA Class: NodeImagePCA Principal component analysis (PCA) is a method that is often used to reduce the dimensionality of data, by transforming a large set of variables into a smaller one that still contain most of the information contained in the full dataset. It can make data easier to explore and visualize. By expressing the dataset in terms of componenents (combination of variables) that contributes most to the variation in the data, the number of variables used to describe the dataset can be reduced. The cost is that some high-frequency information is lost (which can be used as a noise reduction technique). The figure shows PCA of a 2D dataset. After PCA, component 2 contains very little information and practically all of the variance in the dataset is described by component 1. The PCA in MICE is based on Extreme Optimization. Example workflows Noise reduction with PCA example Inputs Image The input image to be analyzed. Type: Image4DFloat, Required, Single Mask A mask defining which area should be included in the analysis. Must have the same matrix size as the input image. Type: Image4DBool, Optional, Single Outputs Components The components found using PCA. Will have have the same dimensionality as the input data, i.e. if you input 3 frames of a time series and perform PCA along the T dimension, the number of components will be 3. Type: Image4DFloat Prediction The prediction of the input data using the Number of Components defined in the Node settings. Type: Image4DFloat Data A table containing the eigen values and eigen vectors of the components. Type: DataCollection Settings Scaling Method Selection When the variables in a PCA analysis use very different scales, the principal components will give more weight to the variable with the larger values. To put all variables on an equal footing, the variables are often scaled. The ScalingMethod property determines if and how this transformation is performed. This value is of type ScalingMethod which can take on the following values: Property Description None No scaling is performed. UnitVariance The columns are scaled to have unit variance. This is the default. VectorNorm The columns are scaled to have unit norm. Pareto The columns are scaled by the square root of the standard deviation. Range The columns are scaled to have unit range (difference between largest and smallest value). Level The columns are scaled by the column mean. Values: None, UnitVariance, VectorNorm, Pareto, Range, Level Number of Components Integer The number of components that is used to recreate the prediction of the output data, given the input data. If the number of components is set to the same number as the dimensionality of the input data, the output will equal the input. If set to a lower value, it will contain less noise. Dimension Selection Along which image dimension should the PCA be performed. Values: X, Y, Z, T Zero Variance Compensation Number If value scaling is used this value will be added to one element of columns with no variance, otherwise the scaling will fail. References Principal component analysis on Wikipedia Principal component analysis on Extreme Optimization Keywords: Principal component analysis, dimensionality reduction, noise reduction, eigen values, eigen vectors ", "tags": "", "url": "nodes.image.math._operations.principal_component_analysis.html"},
{"title": "Convolution", "text": "Convolution Class: NodeImageConvolution Convolve a given image with an arbitrary image kernel. Inputs Image Input image. Type: Image4DFloat, Required, Single Kernel Image to use as convolution kernel. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Normalize Boolean Normalize the output image by the sum of the kernel components. Boundary Condition Selection Set the boundary condition. Values: ZeroPad, ZeroFluxNeumannPad, PeriodicPad Output Region Mode Selection Sets the output region mode. If set to SAME, the output region will be the same as the input region, and regions of the image near the boundaries will contain contributions from outside the input image as determined by the boundary condition. If set to VALID, the output region consists of pixels computed only from pixels in the input image (no extrapolated contributions from the boundary condition are needed). The output is therefore smaller than the input region. Values: Same, Valid References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.convolution.html"},
{"title": "Forward FFT", "text": "Forward FFT Class: NodeFlexibleForwardFFT Calculates the forward FFT. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DComplex Settings Input &amp; Output Input Type Selection Select the type of input the node should accept. Can be real or complex images. Values: Real, Complex Output Type Selection Select if imaginary part of the output should be supressed or not. Values: Real, Complex Configurations Transform X-dimension Boolean Perform the FFT operation for the X-dimension. Transform Y-dimension Boolean Perform the FFT operation for the Y-dimension. Transform Z-dimension Boolean Perform the FFT operation for the Z-dimension. Transform T-dimension Boolean Perform the FFT operation for the T-dimension. Centered FFT Boolean Put the zero-frequency at the image center. Normalization Type Selection Select how the FFT should be normalized. Can be orthonormal or none. Values: Orthonormal, None See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.forward_fft.html"},
{"title": "Inverse FFT", "text": "Inverse FFT Class: NodeFlexibleInverseFFT Calculates the inverse FFT. Inputs Image Input image. Type: Image4DComplex, Required, Single Outputs Output Resulting image. Type: Image4DComplex Settings Input &amp; Output Input Type Selection Select the type of input the node should accept. Can be real or complex images. Values: Real, Complex Output Type Selection Select if imaginary part of the output should be supressed or not. Values: Real, Complex Configurations Transform X-dimension Boolean Perform the FFT operation for the X-dimension. Transform Y-dimension Boolean Perform the FFT operation for the Y-dimension. Transform Z-dimension Boolean Perform the FFT operation for the Z-dimension. Transform T-dimension Boolean Perform the FFT operation for the T-dimension. Centered FFT Boolean Put the zero-frequency at the image center. Normalization Type Selection Select how the FFT should be normalized. Can be orthonormal or none. Values: Orthonormal, None See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.inverse_fft.html"},
{"title": "FFT Shift", "text": "FFT Shift Class: NodeForwardFFTShift Perform FFT shift along selected dimensions. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Input &amp; Output Input Type Selection Select the type of input the node should accept. Can be real or complex images. Values: Real, Complex Configurations Shift X-dimension Boolean Perform the FFT shift operation for the X-dimension. Shift Y-dimension Boolean Perform the FFT shift operation for the Y-dimension. Shift Z-dimension Boolean Perform the FFT shift operation for the Z-dimension. Shift T-dimension Boolean Perform the FFT shift operation for the T-dimension. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.fft_shift.html"},
{"title": "Inverse FFT Shift", "text": "Inverse FFT Shift Class: NodeInverseFFTShift Perform inverse FFT shift along selected dimensions. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Input &amp; Output Input Type Selection Select the type of input the node should accept. Can be real or complex images. Values: Real, Complex Configurations Shift X-dimension Boolean Perform the FFT shift operation for the X-dimension. Shift Y-dimension Boolean Perform the FFT shift operation for the Y-dimension. Shift Z-dimension Boolean Perform the FFT shift operation for the Z-dimension. Shift T-dimension Boolean Perform the FFT shift operation for the T-dimension. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.inverse_fft_shift.html"},
{"title": "FFT Convolution", "text": "FFT Convolution Class: NodeImageFFTConvolution Convolve a given image with an arbitrary image kernel using multiplication in the Fourier domain. Inputs Image Input image. Type: Image4DFloat, Required, Single Kernel Image to use as kernel. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.fft_convolution.html"},
{"title": "Create Expression", "text": "Expression Class: NodeImageExpression Create a custom expression which applies to the elements of the input image. The user can specify an arbitrary number of input images, numbers and bits which are assigned a variable name, starting with \(a\). Atleast one image is mandatory. The variable names can then be used to create an expression to be calculated. As an example, to create a node that takes an input image \(a\), ads it to a second input image \(b\), and multiplies the result with \(e\) raised to the power of an input number \(c\), you would write: (a+b)*e^c Special Variables: e: The natural logarithmic base. pi: The ratio of the circumference of a circle to its diameter. vpx, vpy, vpz: The x, y, and z coordinate of the current voxel. vix, viy, viz: The x, y, and z index of the current voxel. vsx, vsy, vsz: The x, y, and z size of one voxel. vcx, vcy, vcz: The x, y, and z voxel count of the image. ipx, ipy, ipz: The x, y, and z position of the image. Some Functions: abs(x), acos(x), asin(x), atan(x), atan2(x, y), ceiling(x), cos(x), cosh(x), floor(x), log(x), log(x, b), log10(x), max(x, y), min(x, y), rand(x), rande(x), randg(o, s), randn(m, sd), round(x), sign(x), sin(x), sinh(x), sqrt(x), tan(x), tanh(x), truncate(x) Example workflows Custom expressions example Hausdorff and Maurer distance example Advanced use of custom expressions Inputs a The default image input. Type: Image4DFloat, Required, Single Outputs Result The resulting image. Type: Image4DFloat Settings Display Show Expression Boolean If checked, the expression will be displayed beneath the node name in the process window. Node Name Text The display name of the node in the process window. Expression Expression Text The expression which should be calculated. Inputs Images Integer The number of input images. Numbers Integer The number of input numbers. Bits Integer The number of input bits. Result Set Infinity To Number What value should Infity be set to. Set Undefined Numbers To Number What value should Undifined numbers be set to. Resulting Image Name Text The name of the resulting image. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.create_expression.html"},
{"title": "Normal (Gaussian)", "text": "Normal Noise Class: NodeImageNormalNoise Alter an image with normally distributed noise. Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Normal Distribution Mean Number Mean value of the noise. Standard Deviation Number Standard deviation of the added noise. Value As Mean Boolean Use each voxel value as mean for the distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.normal_(gaussian).html"},
{"title": "Gamma", "text": "Gamma Noise Class: NodeImageGammaNoise Alter an image with gamma distributed noise. Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Gamma Distribution Shape Number Shape parameter of the gamma distribution. Rate Number Rate parameter of the gamma distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.gamma.html"},
{"title": "Log-Normal", "text": "Log Normal Noise Class: NodeImageLogNormalNoise Alter an image with lognormal distributed noise. Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Log-Normal Distribution Mean Number Mean value of the noise. Standard Deviation Number Standard deviation of the added noise. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.log-normal.html"},
{"title": "Poission", "text": "Poisson Noise Class: NodeImagePoissonNoise Alter an image with poisson distributed noise. Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Poisson Distribution Lambda Number Lambda parameter of the poisson distribution. Value As Lambda Boolean Use each voxel value as lambda for the distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.poission.html"},
{"title": "Laplace", "text": "Laplace Noise Class: NodeImageLaplaceNoise Alter an image with laplace distributed noise. Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Laplace Distribution Location Number Location parameter of the laplace distribution. Laplace Scale Number Scale parameter of the laplace distribution. Value As Location Boolean Use each voxel value as location for the distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.laplace.html"},
{"title": "Beta", "text": "Beta Noise Class: NodeImageBetaNoise Alter an image with beta distributed noise. Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Beta Distribution Shape A Number Shape parameter A of the beta distribution. Shape B Number Shape parameter B of the beta distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.beta.html"},
{"title": "Chi", "text": "Chi Noise Class: NodeImageChiNoise Alter an image with chi distributed noise. Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Chi Distribution Degrees of Freedom Integer Degrees of freedom parameter of the chi distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.chi.html"},
{"title": "Rician", "text": "Rician Noise Class: NodeImageRicianNoise Alter an image with rician distributed noise. Inputs Image Image to apply the noise to. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Rician Distribution v Number Distance between the reference point and the center of the bivariate distribution. Sigma Number Scale. Value As v Boolean Use each voxel value as v for the distribution. Keywords: Noise ", "tags": "", "url": "nodes.image.filters.noise.rician.html"},
{"title": "Gaussian Blur", "text": "Gaussian Blur Class: NodeSimpleGaussian Computes the smoothing of an image by convolution with the Gaussian kernel. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Algorithm Selection Sets the algorithm to use for the filter. Values: SmoothingRecursive, Discrete Sigma Number Set Sigma value. Sigma is measured in the units of image spacing. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.denoise.gaussian_blur.html"},
{"title": "Median", "text": "Median Class: NodeImageMedianFilter Applies a median filter to an image.Computes an image where a given pixel is the median value of the the pixels in a neighborhood about the corresponding input pixel. A median filter is one of the family of nonlinear filters. It is used to smooth an image without being biased by outliers or shot noise. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Radius X Integer Radius in the X-direction of the kernel in voxels. Radius Y Integer Radius in the Y-direction of the kernel in voxels. Radius Z Integer Radius in the Z-direction of the kernel in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.denoise.median.html"},
{"title": "Box Mean", "text": "Box Mean Class: NodeBoxMeanFilter Applies a box mean filter to an image.Computes an image where a given pixel is the mean value of the the pixels in a neighborhood about the corresponding input pixel. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Radius X Integer Radius in the X-direction of the kernel in voxels. Radius Y Integer Radius in the Y-direction of the kernel in voxels. Radius Z Integer Radius in the Z-direction of the kernel in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.denoise.box_mean.html"},
{"title": "Curvature Flow", "text": "Curvature Flow Class: NodeImageCurvatureFlowFilter Curvature driven image denoising algorithm. Iso-brightness contours in the grayscale input image are viewed as a level set. The level set is then evolved using a curvature-based speed function. The advantage of this approach is that sharp boundaries are preserved with smoothing occurring only within a region. However, it should be noted that continuous application of this scheme will result in the eventual removal of all information as each contour shrinks to zero and disappear. This filter has two parameters: the number of update iterations to be performed and the timestep between each update. The timestep should be &ldquo;small enough&rdquo; to ensure numerical stability. Stability is guarantee when the timestep meets the CFL (Courant-Friedrichs-Levy) condition. Broadly speaking, this condition ensures that each contour does not move more than one grid position at each timestep. In the literature, the timestep is typically user specified and have to manually tuned to the application. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Time Step Number Set the timestep parameter. Iterations Integer Set the number of iterations. References &ldquo;Level Set Methods and Fast Marching Methods&rdquo;, J.A.Sethian, Cambridge Press, Chapter 16, Second edition, 1999. &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.denoise.curvature_flow.html"},
{"title": "Min/Max Curvature Flow", "text": "Curvature Flow Class: NodeImageMinMaxCurvatureFlowFilter Curvature driven image denoising algorithm. Iso-brightness contours in the grayscale input image are viewed as a level set. The level set is then evolved using a curvature-based speed function.In min/max curvature flow, movement is turned on or off depending on the scale of the noise one wants to remove. Switching depends on the average image value of a region, the stencil radius, governs the scale of the noise to be removed. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Time Step Number Set the timestep parameter. Iterations Integer Set the number of iterations. Stencil Radius Integer The scale of the noise to be removed. References &ldquo;Level Set Methods and Fast Marching Methods&rdquo;, J.A.Sethian, Cambridge Press, Chapter 16, Second edition, 1999. &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.denoise.minmax_curvature_flow.html"},
{"title": "Patch Based Denoising", "text": "Denoising Class: NodePatchBasedDenoising Implements a denoising filter that uses iterative non-local, or semi-local, weighted averaging of image patches for image denoising. The intensity at each pixel &lsquo;p&rsquo; gets updated as a weighted average of intensities of a chosen subset of pixels from the image. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Model Selection Select model. Values: NoModel, Gaussian, Rician, Poisson Noise Sigma Number Noise std. dev. Fidelity Weight Number Set the fidelity weight. This weight prevents large deviations of the denoised image from the noisy data. Kernel Bandwidth Estimation Use Estimation Boolean If TRUE, the kernal bandwith will be estimated automatically. Fraction Pixels Number Set the fraction of voxels in the image that will be used for kernel bandwidth sigma estimation. To reduce the computational burden for computing sigma, a small random fraction of the image pixels can be used. Multiplication Factor Number Set the kernel bandwidth sigma multiplication factor used to modify the automatically-estimated kernel bandwidth sigma. At times, it may be desirable to modify the value of the automatically-estimated sigma. Typically, this number isn't very far from 1. Note: This is used only when Use Estimation is TRUE. Kernel Sigma Number Set initial kernel bandwidth estimate. Note: This is changed when Use Estimation is TRUE. Update Frequencey Integer Set the update frequency. An optimal bandwidth will be re-estimated based on the denoised image after every &lsquo;n&rsquo; iterations. Defaults to 3, i.e. bandwidth updated after every 3 denoising iteration. Filter Number Of Iterations Integer Set the number of denoising iterations to perform. Defaults to 3. Number Of Sample Patches Integer Set the number of patches to sample for each pixel. Patch Radius Integer Set the patch radius specified in physical coordinates. Patch radius is preferably set to an even number. Currently, only isotropic patches in physical space are allowed; patches can be anisotropic in voxel space. Sample Varience Number Set the variance of the domain where patches are sampled. References Patch Based Denoising in SimpleITK Patch Based Denoising base class in SimpleITK Keywords: patch, denoising, noise ", "tags": "", "url": "nodes.image.filters.denoise.patch_based_denoising.html"},
{"title": "Curvature Anisotropic Diffusion", "text": "CAD Class: NodeCurvatureDiffusion This filter performs anisotropic diffusion on a scalar image using the modified curvature diffusion equation (MCDE). Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Conductance Number The conductance parameter controls the sensitivity of the conductance term in the basic anisotropic diffusion equation. It affect the conductance term in different ways depending on the particular variation on the basic equation. As a general rule, the lower the value, the more strongly the diffusion equation preserves image features (such as high gradients or curvature). A high value for conductance will cause the filter to diffuse image features more readily. Typical values range from 0.5 to 2.0 for data like the Visible Human color data, but the correct value for your application is wholly dependent on the results you want from a specific data set and the number or iterations you perform. Scaling Update Interval Integer Set the interval at which a new scaling for the conductance term is calculated. Time Step Number Sets the time step to be used for each iteration (update). The time step is constrained at run-time to keep the solution stable. In general, the time step should be at or below (PixelSpacing)/2^(N+1), where N is the dimensionality of the image. Iterations Integer Set the number of iterations. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.denoise.curvature_anisotropic_diffusion.html"},
{"title": "Laplacian", "text": "Sharpen Class: NodeImageLaplacianSharpening This filter sharpens an image using a Laplacian that highlights regions of rapid intensity change and therefore highlights or enhances the edges. The result is an image that appears more in focus. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. An image of the same size as the input image. Type: Image4DFloat Settings Use Image Spacing Boolean Set whether or not the filter will use the spacing of the input image in its calculations. References Laplacian sharpening image filter in SimpleITK Keywords: Laplacian, sharpening, SimpleITK ", "tags": "", "url": "nodes.image.filters.sharpen.laplacian.html"},
{"title": "Landweber Deconvolution", "text": "Deconvolution Class: NodeImageLandweberDeconvolution Deconvolve an image using the Landweber deconvolution algorithm as defined in Bertero M and Boccacci P, &ldquo;Introduction to Inverse Problems in Imaging&rdquo;, 1998. The algorithm assumes that the input image has been formed by a linear shift-invariant system with a known kernel and is best suited for images that have zero-mean Gaussian white noise.This is the base implementation of the Landweber algorithm. It may produce results with negative values. For a version of this algorithm that enforces a positivity constraint on each intermediate solution, use Projected Landweber Deconvolution. Inputs Image Input image. Type: Image4DFloat, Required, Single Kernel Kernel image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Boundary Condition Selection Sets the method to use when calculating voxels close to the bounds of the image. Values: ZeroPad, ZeroFluxNeumannPad, PeriodicPad Output Region Mode Selection Sets the output region mode. Values: Same, Valid Alpha Number Relaxation factor. Normalize Boolean Normalize the output image by the sum of the kernel components. Iterations Integer Set the number of iterations. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.sharpen.landweber_deconvolution.html"},
{"title": "Projected Landweber Deconvolution", "text": "Deconvolution Class: NodeImageProjectedLandweberDeconvolution Deconvolve an image using the Landweber deconvolution algorithm as defined in Bertero M and Boccacci P, &ldquo;Introduction to Inverse Problems in Imaging&rdquo;, 1998. The algorithm assumes that the input image has been formed by a linear shift-invariant system with a known kernel and is best suited for images that have zero-mean Gaussian white noise.At each iteration, negative pixels in the intermediate result are projected (set) to zero. This is useful if the solution is assumed to always be non-negative, which is the case when dealing with images formed by counting photons, for example. Inputs Image Input image. Type: Image4DFloat, Required, Single Kernel Image to use as kernel. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Boundary Condition Selection Sets the method to use around the boundaries. Values: ZeroPad, ZeroFluxNeumannPad, PeriodicPad Output Region Mode Selection Sets the output region mode. Values: Same, Valid Alpha Number Relaxation factor. Normalize Boolean Normalize the output image by the sum of the kernel components. Iterations Integer Set the number of iterations. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.sharpen.projected_landweber_deconvolution.html"},
{"title": "Adaptive Histogram Equalization", "text": "AHE Class: NodeAdaptiveHistogramEqualization Histogram equalization modifies the contrast in an image. By modifying parameters (alpha, beta, and radius), the filter can produce an adaptively equalized histogram or a version of unsharp mask (local mean subtraction). Instead of applying a strict histogram equalization in a window about a pixel, this filter prescribes a mapping function (power law) controlled by the parameters alpha and beta. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Adaptive Histogram Equalization Alpha Number Controls how much the filter acts like the classical histogram equalization method (alpha=0) to how much the filter acts like an unsharp mask (alpha=1). Beta Number Controls how much the filter acts like an unsharp mask (beta=0) to much the filter acts like pass through (beta=1, with alpha=1). Region Radius X Integer Size of the region over which local statistics are calculated in the X direction, specified in voxels. Radius Y Integer Size of the region over which local statistics are calculated in the Y direction, specified in voxels. Radius Z Integer Size of the region over which local statistics are calculated in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.adaptive_histogram_equalization.html"},
{"title": "N4 Bias Field Correction", "text": "Bias Field Correction Class: NodeN4BiasFieldCorrection The nonparametric nonuniform intensity normalization (N3) algorithm, as introduced by Sled et al. in 1998 is a method for correcting nonuniformity associated with MR images. The algorithm assumes a simple parametric model (Gaussian) for the bias field and does not require tissue class segmentation. In addition, there are only a couple of parameters to tune with the default values performing quite well.The N4 algorithm is a variation of the original N3 algorithm with the additional benefits of an improved B-spline fitting routine which allows for multiple resolutions to be used during the correction process. Inputs Image Input image. Type: Image4DFloat, Required, Single Mask Image to use as mask. Type: Image4DBool, Optional, Single Outputs Output Corrected image. Type: Image4DFloat Bias Field An approximation of the bias field. Type: Image4DFloat Settings Convergence Threshold Number Set the convergence threshold. Convergence is determined by the coefficient of variation of the difference image between the current bias field estimate and the previous estimate. If this value is less than the specified threshold, the algorithm proceeds to the next fitting level or terminates if it is at the last level. Field Width at Half Maximum Number Set the full width at half maximum parameter characterizing the width of the Gaussian deconvolution. Default = 0.15. Number of Control Points Integer Set the control point grid size defining the B-spline estimate of the scalar bias field. In each dimension, the B-spline mesh size is equal to the number of control points in that dimension minus the spline order. Default = 4 control points in each dimension for a mesh size of 1 in each dimension. Number of Histogram Bins Integer Set number of bins defining the log input intensity histogram. Default = 200. Spline Order Integer Set the spline order defining the bias field estimate. Default = 3. Wiener Filter Noise Number Set the noise estimate defining the Wiener filter. Default = 0.01. Downsample Boolean If set the filter will downsample the image before calculating the bias field, this is recommended. Shrink Factor Integer The shrink factor for the downsample. Upsample Interpolator Selection The interpolator to use when upsampling the resulting bias field before applying it to the original image. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References Tustison N., Gee J. N4ITK: Nick's N3 ITK Implementation For MRI Bias Field Correction. 2010 Dec. J.G. Sled, A.P. Zijdenbos and A.C. Evans. &lsquo;A Nonparametric Method for Automatic Correction of Intensity Nonuniformity in Data&rsquo; IEEE Transactions on Medical Imaging, Vol 17, No 1. Feb 1998. N.J. Tustison, B.B. Avants, P.A. Cook, Y. Zheng, A. Egan, P.A. Yushkevich, and J.C. Gee. &lsquo;N4ITK: Improved N3 Bias Correction&rsquo; IEEE Transactions on Medical Imaging, 29(6):1310-1320, June 2010. &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.n4_bias_field_correction.html"},
{"title": "Normalize", "text": "Normalize Class: NodeNormalize Normalizes an image to a specified intensity range. Inputs In Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings New Min Number New minimum intensity value. New Max Number New maximum intensity value. Silcewise Boolean Perform the normalization on a slice-by-slice basis. ", "tags": "", "url": "nodes.image.filters.normalize.html"},
{"title": "Truncate", "text": "Truncate Class: NodeImageTruncate Truncates the intensity range of the input to a specified range, i.e. all values larger than the specified max value will be set to the max value, and conversely for the set min value. Inputs In Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting truncated image. Type: Image4DFloat Settings Min Level Number All voxel values below this value will be set to this value. Max Level Number All voxel values above this value will be set to this value. Keywords: Truncate ", "tags": "", "url": "nodes.image.filters.truncate.html"},
{"title": "Sigmoid", "text": "Sigmoid Class: NodeSigmoidFilter Computes the sigmoid function pixel-wise. A linear transformation is applied first on the argument of the sigmoid function. The resulting total transform is given by f(x) = (Max-Min) * 1/(1+e^( -(x - beta) / alpha )) + Min Every output pixel is equal to f(x). Where x is the intensity of the homologous input pixel, and alpha and beta are user-provided constants. Inputs Image input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Alpha Number Alpha parameter. Beta Number Beta parameter. Output Maximum Number Output max value. Output Minimum Number Output min value. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.sigmoid.html"},
{"title": "Sobel", "text": "Sobel Class: NodeSobelFilter Edge detection using the Sobel operator. This filter uses the Sobel operator to calculate the image gradient and then finds the magnitude of this gradient vector. The Sobel gradient magnitude (square-root sum of squares) is an indication of edge strength. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.sobel.html"},
{"title": "Erode", "text": "Erode Class: NodeImageErode Erode an image using grayscale morphology. Erosion takes the minimum of all the pixels identified by the structuring element (kernel) defined in the options. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.erode.html"},
{"title": "Dilate", "text": "Dilate Class: NodeImageDilate Dilate an image using grayscale morphology. Dilate takes the maximum of all the pixels identified by the structuring element (kernel) defined in the options. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.dilate.html"},
{"title": "Opening", "text": "Opening Class: NodeImageOpening Removes small (i.e., smaller than the structuring element) structures in the interior or at the boundaries of the image.The morphological opening of an image &ldquo;f&rdquo; is defined as: Opening(f) = Dilatation(Erosion(f)). Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.opening.html"},
{"title": "Closing", "text": "Closing Class: NodeImageClosing This filter removes small (i.e., smaller than the structuring element) holes and tube like structures in the interior or at the boundaries of the image.The morphological closing of an image &ldquo;f&rdquo; is defined as: Closing(f) = Erosion(Dilation(f)). Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.closing.html"},
{"title": "Opening by Reconstruction", "text": "Reconstruction Class: NodeImageOpeningByReconstruction This filter preserves regions, in the foreground, that can completely contain the structuring element. At the same time, this filter eliminates all other regions of foreground pixels. Contrary to the morphological opening, the opening by reconstruction preserves the shape of the components that are not removed by erosion. The opening by reconstruction of an image &ldquo;f&rdquo; is defined as:OpeningByReconstruction(f) = DilationByRecontruction(f, Erosion(f)).Opening by reconstruction not only removes structures destroyed by the erosion, but also levels down the contrast of the brightest regions. If PreserveIntensities is on, a subsequent reconstruction by dilation using a marker image that is the original image for all unaffected pixels.Opening by reconstruction is described in Chapter 6.3.9 of Pierre Soille's book &quot;Morphological Image Analysis: Principles and Applications&quot;, Second Edition, Springer, 2003. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.opening_by_reconstruction.html"},
{"title": "Closing by Reconstruction", "text": "Reconstruction Class: NodeImageClosingByReconstruction This filter is similar to the morphological closing, but contrary to the morphological closing, the closing by reconstruction preserves the shape of the components. The closing by reconstruction of an image &ldquo;f&rdquo; is defined as:ClosingByReconstruction(f) = ErosionByReconstruction(f, Dilation(f)).Closing by reconstruction not only preserves structures preserved by the dilation, but also levels raises the contrast of the darkest regions. If PreserveIntensities is on, a subsequent reconstruction by dilation using a marker image that is the original image for all unaffected pixels.Closing by reconstruction is described in Chapter 6.3.9 of Pierre Soille's book &quot;Morphological Image Analysis: Principles and Applications&quot;, Second Edition, Springer, 2003. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.closing_by_reconstruction.html"},
{"title": "Fill Hole", "text": "Fill Hole Class: NodeImageFillHole Fills holes in a grayscale image. Holes are local minima in the grayscale topography that are not connected to boundaries of the image. Gray level values adjacent to a hole are extrapolated across the hole.Note: Geodesic morphology and the Fillhole algorithm is described in Chapter 6 of Pierre Soille's book &lsquo;Morphological Image Analysis: Principles and Applications&rsquo;, Second Edition, Springer, 2003. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Fully Connected Boolean Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. For objects that are 1 pixel wide, use On. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.fill_hole.html"},
{"title": "From Four Images", "text": "Select Class: NodeImageSelectFour Selects an output image from four input images using two bits. Inputs 0 Input image 1. Type: Image4DFloat, Required, Single 1 Input image 2. Type: Image4DFloat, Required, Single 2 Input image 3. Type: Image4DFloat, Required, Single 3 Input image 4. Type: Image4DFloat, Required, Single Bit 0 First bit. Type: Boolean, Required, Single Bit 1 Second bit bit. Type: Boolean, Required, Single Outputs Out Resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.flow_control.select.from_four_images.html"},
{"title": "From Two Images", "text": "Select Class: NodeImageSelectTwo Selects an output image from four input images using one bit. Inputs 0 Input image 1. Type: Image4DFloat, Required, Single 1 Input image 2. Type: Image4DFloat, Required, Single Bit Selection bit. Type: Boolean, Required, Single Outputs Out Resulting image. Type: Image4DFloat ", "tags": "", "url": "nodes.image.flow_control.select.from_two_images.html"},
{"title": "Texture Analysis", "text": "Texture Class: NodeTextureAnalyzeGLCM Calculate Haralick Texture Features from a Gray level co-occurrence matrix (GLCM). Inputs GLCM Inputs One or more GLCMs. Type: Image4DFloat, Required, Multiple Outputs Result A data Table containing the resulting texture values. Type: DataCollection Settings Node Dataset Name Text The name or title of the data set. Gray Level Invariant Features Boolean Select if the resulting Haralick texture feature values should be invariant to the number of gray levels in the image. This is described in reference 4. Features Contrast Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Inverse Difference Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Energy Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Entropy Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Maximum Probability Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Correlation Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Sum of Squares: Variance Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Homogeneity Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Dissimilarity Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Sum Average Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Sum Variance Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Sum Entropy Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Difference Variance Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Difference Entropy Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Information Measure of Correlation 1 Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Information Measure of Correlation 2 Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Autoorrelation Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Cluster Shade Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Cluster Prominence Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Difference Average Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. References Haralick, R. M., Shanmugam, K. &amp; Dinstein, I. Textural Features for Image Classification. IEEE Trans. Syst. Man. Cybern. 3, 610–621 (1973). Soh, L., Tsatsoulis, C. &amp; Member, S. Texture Analysis of SAR Sea Ice Imagery Using Gray Level Co-Occurence Matrices. IEEE Trans. Geosci. Remote Sens. 37, 780–795 (1999). Clausi, D. a. An analysis of co-occurrence texture statistics as a function of grey level quantization. Can. J. Remote Sens. 28, 45–62 (2002). Löfstedt, T., Brynolfsson, P., Asklund, T., Nyholm, T., &amp; Garpebring, A. Gray-level invariant Haralick texture features. PLOS ONE, 14(2) (2019). Keywords: Haralick, texture ", "tags": "", "url": "nodes.image.texture.texture_analysis.html"},
{"title": "Texture GLCM", "text": "Texture GLCM Class: NodeTextureGLCM Generates a 2D gray-level co-occurrence matrix for each direction in one slice orientation of the 3D image. Inputs Input An image. Type: Image4DFloat, Required, Single Mask A mask with the same size as the image, which defines the region in which the GLCMs are calculated. Type: Image4DBool, Optional, Single Outputs Horizontal The resulting GLCM with horizontal neighbors. Type: Image4DFloat Vertical The resulting GLCM with vertical neighbors. Type: Image4DFloat Diagonal Left The resulting GLCM with diagonal left neighbors. Type: Image4DFloat Diagonal Right The resulting GLCM with diagonal right neighbors. Type: Image4DFloat Quantized Image The input image quantized to the number of gray levels. Type: Image4DFloat Settings Node Orientation Selection The orientation of the planes on which the GLCMs are created. X,Y,Z are the first, second and third dimensions of the image matrix volume, and not the physical coordinate directions. Values: XY, XZ, YZ Quantization Bins Integer The number of gray levels in the quantized image, which determines the size of the GLCM. Slicewise max-min Boolean Quantize the image slice by slice, using the min and max in each slice. Use Fixed Window Boolean Use a global min and max value when quantizing the image. Ignore Voxels Outside Window Boolean Ignore Voxels that are smaller or larger than the quantization limits. If this is unchecked, they will be set to the quantization limits. Fixed Window Min Number The lower quantization limit. Fixed Window Max Number The upper quantization limit. References Haralick, R. M., Shanmugam, K. &amp; Dinstein, I. Textural Features for Image Classification. IEEE Trans. Syst. Man. Cybern. 3, 610–621 (1973). See also Keywords: ", "tags": "", "url": "nodes.image.texture.texture_glcm.html"},
{"title": "Texture LBP", "text": "Texture Class: NodeTextureLBP Calculates the 8 bit local binary patterns (LBP) texture measure using the closest 8 neighbors to each pixel. Inputs Input An image. Type: Image4DFloat, Required, Single Mask A mask with the same size as the image, which defines the region where the local binary pattern is calculated. Type: Image4DBool, Optional, Single Outputs LBP Image The LBP image. Type: Image4DFloat Settings Orientation Selection The orientation of the planes on which the LBP are created. X,Y,Z are the first, second and third dimensions of the image matrix volume, and not the physical coordinate directions. Values: XY, XZ, YZ Rotation Invariant Boolean Makes the LBP rotation invariant, by shifting each pattern in steps of one, a full rotation around the ceter voxel. This reduces the number of unique patterns from 256 to 36. Method Selection &ldquo;Less is more&rdquo; sets a bit in the resulting number to 1 if the value of the current neighbour is larger than the voxel value. &quot;More is more&quot; sets a bit in the resulting number to 1 if the value of the current neighbour is smaller than the voxel value. Values: LessIsMore, MoreIsMore References 1. Ojala, T., Pietikainen, M. & Harwood, D. Performance evaluation of texture measures with classification based on Kullback discrimination of distributions. Pattern Recognition, 1994. Vol. 1 - Conf. A Comput. Vis. amp; Image Process. Proc. 12th IAPR Int. Conf. 1, 582–585 vol.1 (1994). See also Keywords: ", "tags": "", "url": "nodes.image.texture.texture_lbp.html"},
{"title": "Noise Image", "text": "Noise Image Class: NodeNoiseImageFilter Calculate the local noise in an image. Computes an image where a given pixel is the standard deviation of the pixels in a neighborhood about the corresponding input pixel. This serves as an estimate of the local noise (or texture) in an image. Currently, this noise estimate assume a piecewise constant image. Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Output The resulting noise image. Type: Image4DFloat Settings Radius Integer The distance from the center where pixels are included when calculating the standard deviation. References Noise image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.texture.noise_image.html"},
{"title": "Grid", "text": "Grid Class: NodeImageToGrid Generates a grid in the attached image space. This can be useful to evaluate registrations and deformation, or to illustrate scale. Example workflows Grid example Inputs Image An image which serves as a reference space for the grid. Type: Image4DFloat, Required, Single Outputs Grid The grid image. Type: Image4DFloat Settings Sigma Number The standard deviation of the low pass filter applied to the grid. Must be larger than 0. Value Number The voxel value in spaces between grid lines. The value in the grid lines is always 0. Offset X (mm) Number Offset in mm of the first grid line in X-direction. Offset can be negative, but the grid is not generated further than the extent of the original image so this is not recommended. Offset Y (mm) Number Offset in mm of the first grid line in Y-direction. Offset can be negative, but the grid is not generated further than the extent of the original image so this is not recommended. Offset Z (mm) Number Offset in mm of the first grid line in Y-direction. Offset can be negative, but the grid is not generated further than the extent of the original image so this is not recommended. Spacing X (mm) Number Spacing in mm between center of grid lines in X-direction. Spacing Y (mm) Number Spacing in mm between center of grid lines in Y-direction. Spacing Z (mm) Number Spacing in mm between center of grid lines in Z-direction. References GridImageSource on sitk See also Keywords: ", "tags": "", "url": "nodes.image.convert_to.grid.html"},
{"title": "Label Map (Region) Mask", "text": "Label Map To Mask Class: NodeRegionShapeKeep Converts a label map image (i.e. an image with different segmentations, each having a specific intensity) to a Mask by analyzing the shape of each label. A label map can be produced by Label Map (Regions) from a mask. 0 is considered as background. Example workflows Label map example Inputs Label Map The input label image, i.e. an image containing different regions with specific intensities. Type: Image4DFloat, Required, Single Outputs Mask The output mask created by keeping one or several specified label(s). Type: Image4DBool Kept Labels A label map containing only the kept labels. Type: Image4DFloat Settings Number of labels to keep Integer How many labels to keep. Sort By Selection Sets the property to sort the labels by. Values: Elongation, FeretDiameter, Flatness, NumberOfPixels, NumberOfPixelsOnBorder, Perimeter, PerimeterOnBorder, PerimeterOnBorderRatio, PhysicalSize, Roundness Reverse Order Boolean Reverse the sorting order. References LabelIntensityStatisticsImageFilter on sitk See also Keywords: regions, shape ", "tags": "", "url": "nodes.image.convert_to.label_map_(region)_mask.html"},
{"title": "Line Profile", "text": "Line Profile Class: NodeImageLineProfile Extracts a line profile from one dimension in an image. Example workflows Line profile example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Profile The output plot. Type: CurveCollection Settings Profile Dimension Selection Sets the dimension to create the profile from. Values: X, Y, Z, T Voxel Index X Integer X-Index of the voxel to create the profile from. Y Integer Y-Index of the voxel to create the profile from. Z Integer Z-Index of the voxel to create the profile from. Keywords: plot ", "tags": "", "url": "nodes.image.convert_to.line_profile.html"},
{"title": "Threshold", "text": "Threshold Class: NodeImageToMask Converts an image to a binary Mask using thresholding. Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Mask The resulting mask. A binary mask with the same size as the input image. Type: Image4DBool Settings Division Level Number This value is used to divide the image into two bins. Depending on what division type you select voxel values above and below this value will be converted into 1 or 0 in the resulting mask. Division Type Selection The type of criteria used to set the resulting mask voxel to 1. Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals Use Otsu Thresholding Boolean If TRUE, use the Otsu method of finding a threshold. Using this will ignore the division level value. See also Keywords: Threshold, Thresholding ", "tags": "", "url": "nodes.image.segmentation.threshold.html"},
{"title": "Adaptive Threshold", "text": "Adaptive Threshold Class: NodeImageAdaptiveThreshold Threshold an image using adaptive thresholding. This node calculates a median or mean value in the neighbourhood of each voxel as defined by the kernel radius. The value is multiplied with a threshold criteria and compared with the value of the active voxel, if the voxel value is above or below (depending on polarity) the neighbourhood value of the resulting voxel will be set to TRUE. Example Workflows Adaptive Threshold workflow Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Output A binary mask. Type: Image4DBool Settings Kernel Radius X Integer Radius in the X-direction of the kernel in voxels. Radius Y Integer Radius in the Y-direction of the kernel in voxels. Radius Z Integer Radius in the Z-direction of the kernel in voxels. Threshold Value Type Selection Sets the type of value to be calculated for the kernel. Values: Mean, Median Threshold Criteria Number Sets the relative thershold between the mean/median value of the kernel and the active voxel for it to be set to true. If this value is set to 1.1 the voxel will be true if the voxel value is equal or higher/lower (depending on polarity) than 1.1 times the meadian/mean value of the kernel voxels. Switch Polarity Boolean If set to true the resulting voxel will be set to true if the voxel value is less or equal to (Criteria * median/mean) value. See also Keywords: ", "tags": "", "url": "nodes.image.segmentation.adaptive_threshold.html"},
{"title": "Connected Threshold", "text": "Connected Threshold Class: NodeImageConnectedThreshold Finds voxels that are connected to a seed voxel and lie within a range of values. Two voxels are connected if they share a face, or alternatively an edge or a vertex. A voxel has 6 neighbors with which it shares a face, and 26 neighbors with which it shares a face, an edge or a vertex. Example Workflows Connected threshold Inputs Image The image you wish to apply the threshold to. Type: Image4DFloat, Required, Single Outputs Out The resulting binary mask. Type: Image4DBool Settings Connected Threshold Connectivity Selection Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. Values: Full, Face Seed Seed I Integer X index of the seed voxel. Seed J Integer Y index of the seed voxel. Seed K Integer Z index of the seed voxel. Threshold Lower Threshold Number Lower threshold value. Upper Threshold Number Upper threshold value. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.segmentation.connected_threshold.html"},
{"title": "Watershed", "text": "Watershed Class: NodeImageWatershedSegmentation Watershed segmentation implementation with morphogical operators. Intuitively, watershed segmentation views the image as a landscape, where each pixel value defines the &ldquo;height&rdquo; of the ground at that point. The watershed segmentation fills the lanscape with water, and each pool or basin gets its own label. As the water rises, the entire image is divided into a number of pools. The figure illustrates the intuitive concept of how the watershed algorithm works in a line profile of an image. Initial pools are created at the staring level of the water, and new pools are created as the water rises. Example Workflows Watershed example Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Out A labelmap, where each intensity label represent one pool. Type: Image4DFloat Settings Fully Connected Boolean Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. For objects that are 1 pixel wide, use FullyConnectedOn. Level Number Set the starting level of the segmentation. Lines Enabled Boolean Sets whether the watershed pixel must be marked or not. Default is true. Set it to false do not only avoid writing watershed pixels, it also decrease algorithm complexity. References Morphological watershed in SimpleITK Chapter 9.2 in &ldquo;Morphological Image Analysis: Principles and Applications&rdquo;, Second Edition, Springer, 2003, Pierre Soille The watershed transform in ITK - discussion and new developments ", "tags": "", "url": "nodes.image.segmentation.watershed.html"},
{"title": "Gradient Magnitude", "text": "Gradient Magnitude Class: NodeGradientMagnitude Computes the gradient magnitude of an image region at each pixel. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Use Image Spacing Boolean Set whether or not the filter will use the spacing of the input image in its calculations. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.segmentation.gradient_magnitude.html"},
{"title": "K-Means", "text": "K-Means Class: NodeKMeansFilter Classify the intensity values using the K-Means algorithm. This method assigns each voxel a cluster (i.e. label) such that the within-label variance is minimized. This node is useful when the number of clusters are known beforehand, such as classifying CT intensities to Air, Tissue and Bone. Example Workflows K-Means clustering Inputs Image Image to be segmented. Type: Image4DFloat, Required, Single Outputs Output Label map of the same size as the input image. Type: Image4DFloat Settings Use Non Contiguous Labels Boolean When set to FALSE, the labels are numbered contiguously: {0,1,2..N}. When set to TRUE, the labels are selected in order to span the dynamic range of the output image. Classes Text Initial mean of each class, specified as a comma separated list of numbers. References ScalarImageKmeansImageFilter in SimpleITK K-means clustering on Wikipedia ", "tags": "", "url": "nodes.image.segmentation.k-means.html"},
{"title": "Gradient Magnitude Recursive Gaussian", "text": "Gradient Magnitude Class: NodeGradientMagnitudeRecursiveGaussian Computes the magnitude of the gradient of an image by convolution with the first derivative of a Gaussian. Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Output An image with the same size as the input image, where the voxel values represent the gaussian gradient magnitude. Type: Image4DFloat Settings Sigma Number Set Sigma value. Sigma is measured in the units of image spacing. References Gradient-magnitude recursive gaussian image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.segmentation.gradient_magnitude_recursive_gaussian.html"},
{"title": "Geodesic Active Contour Level Set", "text": "Geodesic Segmentation Class: NodeImageGeodesicSegmentation Segments structures in images based on a user supplied edge potential map. An initial contour is propagated outwards (or inwards) until it &ldquo;sticks&rdquo; to the shape boundaries. This is done by using a level set speed function based on a user supplied edge potential map.This filter requires two inputs. The first input is a initial level set. The initial level set is a real image which contains the initial contour/surface as the zero level set. For example, a signed distance function from the initial contour/surface is typically used. Unlike the simpler Shape Detection Level Set Image Filter the initial contour does not have to lie wholly within the shape to be segmented. The initial contour is allow to overlap the shape boundary. The extra advection term in the update equation behaves like a doublet and attracts the contour to the boundary. This approach for segmentation follows that of Caselles et al (1997).The second input is the feature image. For this filter, this is the edge potential map. General characteristics of an edge potential map is that it has values close to zero in regions near the edges and values close to one inside the shape itself. Typically, the edge potential map is computed from the image gradient. Inputs Initial Level Missing description. Type: Image4DFloat, Required, Single Edge Potential Missing description. Type: Image4DFloat, Required, Single Outputs Output Missing description. Type: Image4DFloat Settings Advection Scaling Number Missing description. Curvature Scaling Number Missing description. Propagation Scaling Number Missing description. Maximum RMS Error Number Missing description. Reverse Expansion Direction Boolean Missing description. Iterations Integer Set the number of iterations. References &ldquo;Geodesic Active Contours&rdquo;, V. Caselles, R. Kimmel and G. Sapiro. International Journal on Computer Vision, Vol 22, No. 1, pp 61-97, 1997 &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.segmentation.geodesic_active_contour_level_set.html"},
{"title": "Canny Edge Detection", "text": "Edge Detection Class: NodeCannyFilter Based on John Canny's paper &ldquo;A Computational Approach to Edge Detection&rdquo;(IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. PAMI-8, No.6, November 1986), there are four major steps used in the edge-detection scheme: (1) Smooth the input image with Gaussian filter. (2) Calculate the second directional derivatives of the smoothed image. (3) Non-Maximum Suppression: the zero-crossings of 2nd derivative are found, and the sign of third derivative is used to find the correct extrema. (4) The hysteresis thresholding is applied to the gradient magnitude (multiplied with zero-crossings) of the smoothed image to find and link edges. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Lower Threshold Number Define the lower threshold for detection edges. Upper Threshold Number Define the upper threshold for detection edges. Variance Number Set the variance of the Gaussian smoothing filter. Maximum Error Number Set the MaximumError parameter used by the Gaussian smoothing filter in this algorithm. References Canny edge detection in SimpleITK Keywords: Canny, edge, edge-detection ", "tags": "", "url": "nodes.image.segmentation.canny_edge_detection.html"},
{"title": "Otsu  Thresholding", "text": "Otsu Class: NodeOtsuThreshold Converts an image to a binary Mask using otsu thresholding. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Mask The resulting mask. A binary mask with the same size as the input image. Type: Image4DBool References Otsu thresholding in SimpleITK See also Keywords: Threshold, Thresholding, Otsu ", "tags": "", "url": "nodes.image.segmentation.otsu__thresholding.html"},
{"title": "Otsu Multi Thresholding", "text": "Otsu Multi Class: NodeOtsuMulti Threshold an image using multiple Otsu Thresholds. This node creates a label map that separates the input image a set number of classes. The number of histogram bins and number of thresholds can be defined in the node settings. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Output label map. Type: Image4DFloat Thresholds Output resulting thresholds in a data table. Type: DataCollection Settings Number of Thresholds Integer Set the number of thresholds. Number of Bins Integer Set the number of histogram bins. Label Offset Integer Set the offset which labels start from. References Otsu multiple threshold in SimpleITK Description of Otsu's method on Wikipedia Keywords: ", "tags": "", "url": "nodes.image.segmentation.otsu_multi_thresholding.html"},
{"title": "Elastix Registration", "text": "Elastix Class: NodeElastixProcessor Uses elastix to register images using specified parameters. It requires at least one fixed and one moving image as input, and will output the moving image registered and resampled to the fixed image coordinate system. The default registration method is rigid multimodal registration using mutual information. To change it, click the Edit Parameters button in the node settings panel or double-click on the Elastix node in the process window. The parameters are saved with the Registration (Elastix) node in the workflow (.ice-file). Parameters can also be imported from a .txt file from within the Parameter editor. There are a multitude of different settings and parameters that can be changed to achieve a wide variety of registrations and results. We have written a separate article to exemplify and describe some possible settings, and for even further information, we refer the user to the elastix homepage and their manual. Inputs The inputs are dynamic, and the ones listed below are just the default settings. Fixed The fixed input image to register to. Type: Image4DFloat, Required, Single Moving 1 The moving input image that will be registered. Type: Image4DFloat, Required, Single Outputs Out 1 The registered moving image. Type: Image4DFloat Settings Input Number of Moving Images Integer Specifies the number of moving images to be registered to one or more fixed images. Use Initial Transform Boolean Input an initial transform (Transformix Parameter data type) that is applied to the moving image before registration starts. Use Fixed Masks Boolean Creates input(s) for fixed mask(s). If used, the sampler draws the required number of samples from within the valid region of the fixed image. Use Moving Masks Boolean Creates input(s) for moving mask(s). If used, the sampler will discard any samples drawn from outside the valid region of the moving image. Use Multiple Fixed Images Boolean Register all moving images to separate fixed images. Multi Metric Boolean Use this option to register a set of moving and fixed images using different metrics simultaneously. A metric need to be specified for each set of images. Number of Auxiliary Images Integer Sets the number of auxiliary images. To use them enter the name of the auxiliary image into your parameters file. Output Transformix Transforms Boolean Creates an output for the Transformix Parameters of the resulting registration. Output Affine Transforms Boolean Creates an output for affine transforms. This is a Data data type output, which gives the augmented affine transformation matrix, as well as the Euler angles. Parameters Parameters Text Parameters for the registration. Processing 2D/2D Registration Boolean If set the images will be treated as having two dimensions. This is uesful when trying to register single slice images.Note: For this to work you need to change FixedImageDimension and MovingImageDimension to 2 in your parameters. Z position and rotation of all images will be discarded. Single Thread Boolean If selected only one instance of elastix will be used by this node. References S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, 2010. &ldquo;elastix: a toolbox for intensity based medical image registration&rdquo; See also Image registration Keywords: Registration ", "tags": "", "url": "nodes.image.registration.elastix_registration.html"},
{"title": "Demons Registration", "text": "Demons Registration Class: NodeRegistrationDemons The classic demons algorithm will register two images by computing the displacement field which will map a moving image onto a fixed image. It is quite fast, but only works for mono-modal images. For details regarding the itkDemons filter, look at the sitk class and their use example. You can also review the paper by Pennec et al. Example workflows Demons registration example Inputs Fixed The fixed image. Type: Image4DFloat, Required, Single Moving The image to be registered. Should have the same intensity distribution as the fixed, i.e. the same modality. If there are differences in intensity distribution, pre-processing by histogram matching can be helpful in some cases. Type: Image4DFloat, Required, Single Outputs Out The displacement field which aligns the moving image to the fixed. Type: Image4DVector3 Settings Intensity Difference Threshold Number Set the threshold below which the absolute difference of intensity yields a match. When the intensities match between a moving and fixed image pixel, the update vector (for that iteration) will be the zero vector. Maximum Error Number Set the desired maximum error of the Guassian kernel approximate. Maximum RMS Error Number The Root Mean Square of the levelset upon termination. Maximum Kernel Width Integer Set the desired limits of the Gaussian kernel width. Standard Deviation X Number Set the Gaussian smoothing standard deviation in X-direction for the displacement field. The values are set with respect to pixel coordinates. Standard Deviation Y Number Set the Gaussian smoothing standard deviation in Y-direction for the displacement field. The values are set with respect to pixel coordinates. Standard Deviation Z Number Set the Gaussian smoothing standard deviation in Z-direction for the displacement field. The values are set with respect to pixel coordinates. Update Field Standard Deviation X Number Set the Gaussian smoothing standard deviation in X-direction for the update field. The values are set with respect to pixel coordinates. Update Field Standard Deviation Y Number Set the Gaussian smoothing standard deviation in Y-direction for the update field. The values are set with respect to pixel coordinates. Update Field Standard Deviation Z Number Set the Gaussian smoothing standard deviation in Z-direction for the update field. The values are set with respect to pixel coordinates. Use Image Spacing Boolean Set the value of UseImageSpacing to true or false respectfully. Use Moving Image Gradient Boolean Switch between using the fixed image and moving image gradient for computing the displacement field updates. Smooth Displacement Field Boolean Set whether the displacement field is smoothed (regularized). Smoothing the displacement yields a solution elastic in nature. If Smooth Displacement Field is on, then the displacement field is smoothed with a Gaussian whose standard deviations are specified with Standard Deviation X, Y, Z Smooth Update Field Boolean Set whether the update field is smoothed (regularized). Smoothing the update field yields a solution viscous in nature. If Smooth Update Field is on, then the update field is smoothed with a Gaussian whose standard deviations are specified with Update Field Standard Deviation X, Y, Z. Number of Iterations Integer Number of iterations run. References DemonsRegistrationFilter on sitk Use example on sitk Paper by Pennec et al See also Keywords: Deformable, non-rigid, mono-modal ", "tags": "", "url": "nodes.image.registration.demons_registration.html"},
{"title": "Optical Flow Registration", "text": "Optical Flow Class: NodeImageOpticalFlow Registers two images from the same modality, i.e. their intensity distributions need to be similar. Images need to lie in the same coordinate system and be of the same size. Moving input image can be a time series in which case each consecutive image is individually registered against the fixed image. Since optical flow only handles small movements a pyramid approach is implemented for handling large motions. The user specifies the downsampling steps, i.e. the number of pyramid levels, and a joint downsampling factor. Gaussian smoothing is also applied for each downsampling step as well as median filtering of the displacement between each step. The user can choose to stop the registration at the next highest resolution level, both to save time and possibly to avoid inaccuracies due to noise in the images. Alpha is the factor controlling the smoothness of the registration. A higher alpha value gives a smoother displacement, its square should be set roughly to the noise level in the images. Since the images are not normalized in the process the alpha is with respect to voxelvalues in the images. Output is the resulting images and the displacement fields. Example workflows Optical flow registration example Inputs Fixed The fixed image. Type: Image4DFloat, Required, Single Moving The moving image to be registered. Must be in the same coordinate system and of the same size as the fixed image, i.e. perform a rigid registration first if necessary. Type: Image4DFloat, Required, Single Outputs Deformation The deformation field. Type: Image4DVector3 Result The registered moving image. Type: Image4DFloat Settings Alpha Number Alpha value in registration that controls the smoothness. Iterations Integer Set number of iterations to run. Downsampling Steps Integer Set number of downsampling steps. Downsampling Factor Number Set downsampling factor. Stop at Next Highest Resolution Level Boolean Set stop at next highest resolution level. References Horn, B., Schunck, B. (1981). “Determining optical flow.” Sun, D. (2010). “Secrets of Optical Flow Estimation and Their Principles.” See also Keywords: deformable, non-rigid ", "tags": "", "url": "nodes.image.registration.optical_flow_registration.html"},
{"title": "Inverse Transform", "text": "Inverse Class: NodeInverseTransform Calculates the inverse transform of the connected transformix transform. Currently only linear transforms are supported (translation, rigid, affine). To specify the new image space a reference image must be used. Inputs Transform The transformix parameters to be applied. Type: TransformixParameter, Required, Single Reference Reference image to use when setting the new image space. If this is not used the resulting images will use the image space of the original transform. Type: Image4DFloat, Optional, Single Outputs Inverse The inverse transformix transform. Type: TransformixParameter References S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, 2010. &ldquo;elastix: a toolbox for intensity based medical image registration&rdquo; &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.registration.inverse_transform.html"},
{"title": "Apply Transformix Registration", "text": "Transformix Class: NodeTransformixProcessor Uses Transformix to transform the input image(s) according to the parameters supplied in the Transformix Parameters data type input. For more information about elastix and transformix, see the elastix manual. Example workflows Transformix example Inputs Transformix The transformix parameters to be applied. Type: TransformixParameter, Required, Single Image 1 The image to be transformed. Type: Image4DFloat, Required, Single Outputs Out 1 The transformed image. Type: Image4DFloat Settings Input Number of Moving Images Integer Specifies the number of images to be transformed. Use Initial Transform Boolean Input an initial transform (Transformix Parameter data type) that is applied to the input image before the Transformix parameters are applied. Use Resample Reference Boolean Resample the output data to a different coordinate system than supplied in the Transformix Parameter file. Transformix Per Frame Transform Boolean If set the node will use one transformix per frame if available, by default only the first transformix frame will be used. If there is not enough transformix frames to match the moving data the last transformix will be used for the last frames. Ignore Existing Initial Transform Boolean Ignores the initial transform specified in the parameters file. Custom Settings Use Custom Settings Boolean Select to apply custom settings to the transform. Final B-Spline Interpolation Order Integer Set the order of the b-spline interpolation of the image. References S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, 2010. &ldquo;elastix: a toolbox for intensity based medical image registration&rdquo; See also Keywords: registration ", "tags": "", "url": "nodes.image.registration.apply_transformix_registration.html"},
{"title": "Apply DICOM Registration", "text": "Apply Registration Class: NodeRegistrationPreDefined Applies the transform specified in a DICOM REG file. It can only be applied between the two Frame of reference UIDs specified in the file. It requires one fixed, one moving image and a Registration data type input, and will output the moving image registered and resampled to the fixed image coordinate system. Inputs Fixed Image The fixed image. Type: Image4DFloat, Required, Single Moving Image The moving image to be registered. Type: Image4DFloat, Required, Single Registration The DICOM registration. Type: RegistrationCollection, Required, Single Outputs Out The registered image. Type: Image4DFloat Settings Interpolator Selection Specifies which interpolator should be used to resample the moving image. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc Matrix Type Selection Specifies the matrix type of the registration to use, can be RIGID, RIGID_SCALE or AFFINE. Values: RIGID, RIGID_SCALE, AFFINE Matrix Type Code Selection Selects which registration should be applied based on the DICOM-tag (0008,0104) CodeMeaning. Values: ImageContentBased, Fiducial, Visual, AcquisitionEquipment, FrameOfReferenceIdentity, Unknown Set new frame of reference Boolean Changes the MICE specific Frame of reference tag of the input image to that of the reference image. This is the default setting and is recommended in most applications. See also Keywords: ", "tags": "", "url": "nodes.image.registration.apply_dicom_registration.html"},
{"title": "Deformation Analysis", "text": "Deformation Analysis Class: NodeDeformationAnalysis Takes a transformix parameter input and will output the movement in each pixel of the fixed image as a vector image. If an image reference is supplied, the movement will be evaluated at the voxel positions of the image reference. Note that this is much slower. This node is especially useful for analyzing deformations resulting from non-rigid image registrations. Input points are specified in the fixed image domain, since the transformation direction is from fixed to moving image. Example workflows Deformation analysis example Inputs Image Reference Optional input image. If supplied, the deformation will be evaluated at the voxel positions of the image reference. Type: Image4DFloat, Optional, Single Transformix The transformix parameter input to be evaluated. Type: TransformixParameter, Required, Single Mask Optional mask. Only voxel positions marked as true will be evaluated. Only applies if an optional image reference is supplied. Type: Image4DBool, Optional, Single Outputs Deformation The deformation field at the specified voxel positions. Type: Image4DVector3 Settings Ignore Existing Initial Transform Boolean Ignores the initial transform specified in the parameters file. References S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, 2010. &ldquo;elastix: a toolbox for intensity based medical image registration&rdquo; See also Keywords: registration, elastix ", "tags": "", "url": "nodes.image.registration.deformation_analysis.html"},
{"title": "Set Position", "text": "Position Class: NodeImagePosition Change the position of the input image, either to a manually defined position or to the position of a reference image. It will NOT affect the pixel data of the image, only the metadata of the image object. Example Workflows Transformation examples Inputs Image 1 An image. Type: Image4DFloat, Required, Single Outputs Out 1 The same image with a new position. Type: Image4DFloat Settings Input Number of Images Integer Specifies the number of input images to change position on. Use Reference Image Boolean Adds an input for a reference image. The position of the reference image will be copied to all input images. Manual Position Position X (mm) Number Defines the physical coordinate of the center of the top left voxel in the image stack in the x-direction. Position Y (mm) Number Defines the physical coordinate of the center of the top left voxel in the image stack in the y-direction. Position Z (mm) Number Defines the physical coordinate of the center of the top left voxel in the image stack in the z-direction. See also Keywords: ", "tags": "", "url": "nodes.image.transform.set_position.html"},
{"title": "Set Voxel Size", "text": "Voxel Size Class: NodeImageVoxelSize Change the voxel size of the input image in the metadata of the image object, either to a manually defined voxel size or to the voxel size of a reference image. This will NOT affect the pixel data of the image. Example Workflows Transformation examples Inputs Image 1 An image. Type: Image4DFloat, Required, Single Outputs Out 1 The same image with a new voxel size. Type: Image4DFloat Settings Input Number of Images Integer Specifies the number of input images to change voxel size on. Use Reference Image Boolean Adds an input for a reference image. The voxel size of the reference image will be copied to all input images. Voxel Size Voxel Size X Number Defines the physical voxel size in the x-direction. Voxel Size Y Number Defines the physical voxel size in the y-direction. Voxel Size Z Number Defines the physical voxel size in the z-direction. See also Keywords: ", "tags": "", "url": "nodes.image.transform.set_voxel_size.html"},
{"title": "Set Orientation", "text": "Orientation Class: NodeImageOrientation Change the orientation (i.e. the rotation matrix) of the input image to that of a reference image. This will NOT affect the pixel data of the image. Example Workflows Transformation examples Inputs Reference An image from where the rotation matrix is copied. Type: Image4DFloat, Required, Single Image The image where the rotation matrix will be changed. Type: Image4DFloat, Required, Single Outputs Out The same image with a new rotation matrix. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.transform.set_orientation.html"},
{"title": "Translate", "text": "Translate Class: NodeImageTranslate Translate the input image by either a specified distance or to a position relative to a reference image. This will NOT affect the pixel data of the image. Example Workflows Transformation examples Inputs Image 1 An image. Type: Image4DFloat, Required, Single Outputs Out 1 The same image with a new position. Type: Image4DFloat Settings Input Number of Images Integer Specifies the number of input images to change position on. Use Reference Image Boolean If set the image will be translated to a position relative to a reference image Reference Translate Type Selection &ldquo;Origin To Origin&rdquo; will move the input image origin (top left voxel) to the origin of the reference image. &quot;Center To Center&quot; will move the input image center to the center of the reference image. Values: OriginToOrigin, CenterToCenter Manual Translation Translate X (mm) Number Size of translation in the x-direction. Translate Y (mm) Number Size of translation in the y-direction. Translate Z (mm) Number Size of translation in the z-direction. See also Keywords: ", "tags": "", "url": "nodes.image.transform.translate.html"},
{"title": "Resample To Reference", "text": "Resample Class: NodeResampleImageFilter Resample the image data from an input image to the coordinates, resolution and orientation of a reference image. This WILL affect the pixel data of the input image. Example Workflows Transformation examples Inputs Reference The image frame of reference to be used. Type: Image4DFloat, Required, Single Input An image. Type: Image4DFloat, Required, Single Outputs Output An image with the same position, voxel size and orientation as the reference, with the resampled pixel data from the input image. Type: Image4DFloat Settings Interpolator Selection Specifies which interpolation method should be used for the resampling. The default interpolator is the Linear interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc Set new frame of reference Boolean Changes the MICE specific Frame of reference tag of the input image to that of the reference image. This is the default setting and is recommended in most applications. Default Voxel Value Number Value assigned to extrapolated voxels, i.e. voxels not present in the input image. References Resample image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.transform.resample_to_reference.html"},
{"title": "Change Voxel Size", "text": "Resolution Class: NodeResampleImageResolution Resample the input image to a new resolution, using a user specified voxel size. This WILL affect the pixel data of the input image. Example Workflows Transformation examples Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Out The resampled input image with a new resolution. Type: Image4DFloat Settings Voxel Size New Voxel Size X (mm) Number Defines the physical voxel size in the x-direction. New Voxel Size Y (mm) Number Defines the physical voxel size in the y-direction. New Voxel Size Z (mm) Number Defines the physical voxel size in the z-direction. Node Interpolator Selection Specifies which interpolation method should be used for the resampling. Default is Linear interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References Resample image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.transform.change_voxel_size.html"},
{"title": "Deform Using Vector Field", "text": "Deform Class: NodeImageDeformVectorField Deform an image using a supplied vector field. A vector field is an image with three components, which describes the displacement of each point in x, y and z directions. Each vector represent the distance between a geometric point in the input image and the corresponding point in the output image. The resulting image is created using inverse mapping; the pixels in the output image are mapped back onto the input image. This means a displacement of e.g. 10 mm in the x direction of the deformation vector field results in a shift of -10 mm of the output image for that position. Like other medical images, vector fields have a resolution, orientation and a position in space. A vector field does NOT have to have the same matrix size, position, orientation or resolution as the input image, the positions of the vectors and image voxels are interpolated when the deformation occurs. Where the vector field is not defined, no deformation occurs. This is illustrated in the figures below. The left figure shows a vector field, which displaces points diagonally with varying magnitude. The right figure shows the result of applying this deformation vector field on an image. The outline of the vector field is also shown. These images are the result of the first example workflow. Example Workflows Create and apply a deformation vector field Advanced application of deformation vector field Inputs Image An image. Type: Image4DFloat, Required, Single Vector A vector field. Type: Image4DVector3, Required, Single Outputs Output An image with the same size as the input image. Type: Image4DFloat Settings Interpolator Selection Specifies which interpolation method should be used for the resampling. Default is BSpline interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References Warp Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.transform.deform_using_vector_field.html"},
{"title": "Extract Frames", "text": "Extract Frames Class: NodeExtractFrames Extracts frames from a time series to create a shorter time series or a single time frame (3D image). Example Workflows Reshape examples Inputs Time Series An image with at least two frames. Type: Image4DFloat, Required, Single Outputs Out An image with the user defined frames remaining. Type: Image4DFloat Settings End Frame Integer Selects the final time frame to be included in the output. Must be larger or equal to the start frame. If its larger than the size of the time series, end frame will be set to the final frame of the input time series. Start Frame Integer Selects the first time frame to be included in the output. Must be larger than zero and smaller than or equal to the end frame See also Keywords: ", "tags": "", "url": "nodes.image.reshape.extract_frames.html"},
{"title": "Extract Slices", "text": "Extract Slices Class: NodeExtractSlices Extracts slices from an image to create an image with fewer slices. Example Workflows Reshape examples Inputs In An image with at least two slices. Type: Image4DFloat, Required, Single Outputs Out An image with a subset of slices from the input image. Type: Image4DFloat Settings Orientation Selection Specifies the orientation of slices. E.g. if slice orientation is XY, slice extraction will be in the z-direction. Values: XY, XZ, YZ End Slice Integer Selects the last slice to be included in the output. If the start slice is larger than the end slice the end slice will be used as start slice. If its larger than the size of stack it will be set to the final slice of the input stack. Start Slice Integer Selects the first slice to be included in the output. If the start slice is larger than the end slice the end slice will be used as start slice. If its larger than the size of stack it will be set to the final slice of the input stack. See also Keywords: ", "tags": "", "url": "nodes.image.reshape.extract_slices.html"},
{"title": "Merge Frames", "text": "Merge Frames Class: NodeTimeMean Merge a time series into a single 3D image by averaging over time, maximum intensity projection of minimum intensity projection. Example Workflows Reshape examples Inputs Time Series An image with at least two frames. Type: Image4DFloat, Required, Single Outputs Mean An image with one frame, where intensity in each voxel is the average value of that voxel in the time series. Type: Image4DFloat MIP An image with one frame, where intensity in each voxel is maximum value of that voxel in the time series. Type: Image4DFloat MinIP An image with one frame, where intensity in each voxel is minimum value of that voxel in the time series. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.reshape.merge_frames.html"},
{"title": "Projection", "text": "Projection Class: NodeProjectionParallel Orthogonally projects a slice stack into a single slice in the x, y and z-directions. The resulting images are the average, minimum or maximum of all voxel in the specified direction. Example Workflows Reshape examples Inputs Image An image. Type: Image4DFloat, Required, Single Outputs X A projected single slice in the YZ plane. Type: Image4DFloat Y A projected single slice in the XZ plane. Type: Image4DFloat Z A projected single slice in the XY plane. Type: Image4DFloat Settings Projection Method Selection Specifies the projection method, either average, maximum or minimum intensity projection. Values: Min, Max, Average See also Keywords: ", "tags": "", "url": "nodes.image.reshape.projection.html"},
{"title": "Image Paste", "text": "Image Paste Class: NodeImagePaste Paste multiple images into a single image. The output image covers the bounding box of all input images combined, with the resolution of the first input image. All images will be resampled to the output matrix space using linear interpolation. Example Workflows Reshape examples Inputs Paste At least two input images, to be pasted. Type: Image4DFloat, Required, Multiple Outputs Out An image covering the extent of all input images, with the resolution of the first connected input image. Type: Image4DFloat Settings Use Overlap Average Boolean In case of overlapping information in two or more image stacks, this option specifies if the information should be averaged instead of added. Overlap Norm Threshold Number This option specifies a relative threshold value, ranging from 0 to 1 for each image, below which voxels are ignored. Setting this value to e.g. 0.5 will ignore voxels with values lower than the mean for each image. See also Keywords: ", "tags": "", "url": "nodes.image.reshape.image_paste.html"},
{"title": "Pad", "text": "Pad Class: NodeImagePad Increase the matrix size of the input image by a specified amount by padding the boundaries of the image. The spatial position of the image content will not be affected. Example Workflows Reshape examples Inputs In An image. Type: Image4DFloat, Required, Single Outputs Out An image with a larger matrix than the input image. Type: Image4DFloat Settings Pad Value Number The pixel value assigned to the padding. X Lower Integer Number of voxels that will be added before current lower bound in x-direction. Y Lower Integer Number of voxels that will be added before current lower bound in y-direction. Z Lower Integer Number of voxels that will be added before current lower bound in z-direction. X Upper Integer Number of voxels that will be added after current upper bound in x-direction. Y Upper Integer Number of voxels that will be added after current upper bound in y-direction. Z Upper Integer Number of voxels that will be added after current upper bound in z-direction. References Constant Pad Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.reshape.pad.html"},
{"title": "Flip Axes", "text": "Flip Class: NodeImageFlip Flip an image across user specified axes. Example Workflows Reshape examples Inputs In An image. Type: Image4DFloat, Required, Single Outputs Out The image with flipped a image matrix in the specified directions. Type: Image4DFloat Settings Flip About Origin Boolean Controls how the output origin is computed. If TRUE, the flip will occur about the origin of the axis, otherwise, the flip will occur about the center of the axis. Flip X-Axis Boolean Flips the X-Axis. Flip Y-Axis Boolean Flips the Y-Axis. Flip Z-Axis Boolean Flips the Z-Axis. References Flip Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.reshape.flip_axes.html"},
{"title": "Permute Axes", "text": "Permute Axes Class: NodePermuteAxes Permutes the image axes according to a user specified order. The output image information (spacing, orientation) is computed by permuting the corresponding input meta information. Example Workflows Reshape examples Inputs In An image. Type: Image4DFloat, Required, Single Outputs Out The input image with permutet axes. Type: Image4DFloat Settings New First Axis Integer Sets the new first axis. New Second Axis Integer Sets the new second axis. New Third Axis Integer Sets the new third axis. References Permute Axes Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.reshape.permute_axes.html"},
{"title": "Create Stack", "text": "Create Stack Class: NodeImageCreateStack Stack multiple images in the slice direction. Example Workflows Reshape examples Inputs Slice 1 The first image in the stack. Type: Image4DFloat, Required, Single Outputs Stack All images, stacked in the z direction. Type: Image4DFloat Settings Input Number of Images Integer Specify the number of input images to create stack. Slice Thickness Slice Thickness Number Specifies the thickness of the slices in the stack. Use First Slice Thickness Boolean If TRUE, slice thickness will be set to the thickness of the first stack (input Slice 1). See also Keywords: ", "tags": "", "url": "nodes.image.reshape.create_stack.html"},
{"title": "Create Time Series", "text": "Create Time Series Class: NodeImageCreateTimeSeries Creates a time series from multiple images with the same matrix size. Position, orientation and voxel size is copied from the first frame. Example Workflows Reshape examples Inputs Frame 1 The first frame in the time series. Type: Image4DFloat, Required, Single Outputs Time Series A time series. Type: Image4DFloat Settings Input Number of Frames Integer Specifies the number of input images to construct time frame. Time Series Timestep Between Frames(s) Number Specifies the timestep between each frame in output timeseries. See also Keywords: ", "tags": "", "url": "nodes.image.reshape.create_time_series.html"},
{"title": "ADC Map", "text": "ADC Map Class: NodeADCMap Calculates an ADC map based on diffusion weighted images. At least 2 images are required and b-values are automatically extracted from the images. An optional mask can also be provided to limit the calculations to a region.Two methods can be used in the calculation of the ADC map; a linear(fast) method and a nonlinear(slower) method.Typically both methods give good results but the linear method involves taking the logarithm of a signal before fitting parameters and will therefore not treat noise optimally. Consequently, for lower SNR data the nonlinear method is to be preferred.Produces a ADC map in units [mm^2/s] and a signal map. Inputs B-Value Series Input images with differnt b-values. Type: Image4DFloat, Required, Single Mask Input mask. Type: Image4DBool, Optional, Single Outputs ADC Resulting ADC map. Type: Image4DFloat Signal Resulting signal map. Type: Image4DFloat Settings Method Selection Use a linear or a nonlinear fitting algorithm. Values: Linear, NonLinear References Bernstein, K. F. King, and X. J. Zhou, Handbook of MRI Pulse Sequences. Amsterdam: Elsevier Academic Press, pp. 830 - 53, 2004. Keywords: ADC, MD, map, diffusion, mri ", "tags": "", "url": "nodes.image.mri.adc_map.html"},
{"title": "Inversion Recovery", "text": "T1 IR Class: NodeT1IR Calculate a T1 map using spin echo inversion recovery (IR) data. Atleast two images are required, however, more images are advised if a larger range of T1 values are expected. Inversion times, inversion flip angle (FA) and repetition time (TR) are detected automatically and it is required that the FA and TR is the same in all images. An optional mask can also be provided to limit the calculations to a region.Produces a T1 map[ms], and S0 which is a proton and T2 weighted image. The parameter values are obtained by fitting the data to the signal equation: \(\displaystyle S = S_0(1–(1-\cos(FA))\exp(-T_1/T_I)+\exp(-T_R/T_1))\) Inputs Dataset At least two inut images with different inversion times. Type: Image4DFloat, Required, Multiple (Minimum = 2) Mask A mask which defines the region in which the T1 values will be calculated. Type: Image4DBool, Optional, Single Outputs T1 The T1 map. Type: Image4DFloat S0 The S0 map. Type: Image4DFloat Settings Model Selection For phase sensitive IR use the Real model, otherwise use the magnitude model. Values: Real, Magnitude References Gowland and V. L. Stevenson, “T1: the longitudinal relaxation time,” in Quantitative MRI of the brain: Measuring changes caused by disease, P. S. Tofts, Ed. Chichester: Wiley, 2003, pp. 111–41. Keywords: T1, IR, spin, echo, inversion, recovery, longitudinal, relaxation ", "tags": "", "url": "nodes.image.mri.t1_map.inversion_recovery.html"},
{"title": "Variable Flip Angles", "text": "T1 VFA Class: NodeT1VFA Calculate a T1 map using the variable flip angle (VFA) method. At least two images are required, however, more images are advised if a larger range of T1 values are expected. Flip angle (FA) and repetition time (TR) are detected automatically and it is required that the TR is the same in all images. In addition to images with varying flip angle, a B1 map can also be provided to improve the accuracy. This is particularly useful at high field strengths. The B1 map represents a scaling of the FA, hence value 1 indicates that the nominal FA is achieved. An optional mask can also be provided to limit the calculations to a region. Produces a T1 map [ms], and S0 which is a proton and T2*-weighted image. The parameter values are obtained by fitting the data to a linearized version of the spoiled gradient echo equation: \(\displaystyle S = S0\frac{1-\exp(-T_R/T_1)}{1-\cos(FA \cdot B_1)\exp(-T_R/T_1)}\sin(FA\cdot B_1).\) Inputs Dataset Input images with varying FA. Type: Image4DFloat, Required, Multiple (Minimum = 2) Mask Input binary mask. Type: Image4DBool, Optional, Single B1 Correction Input B1 correction image. Type: Image4DFloat, Optional, Single Outputs T1 T1 map. Type: Image4DFloat S0 S0 map. Type: Image4DFloat References S.C.L. Deoni, T. M. Peters, and B. K. Rutt, “High-resolution T1 andT2 mapping of the brain in a clinically acceptable time with DESPOT1 and DESPOT2,” Magn. Reson. Med., vol. 53, no. 1, pp. 237–241, Jan. 2005. Keywords: T1, longitudinal, map, relaxation, B1, flip, angle, mri, dce ", "tags": "", "url": "nodes.image.mri.t1_map.variable_flip_angles.html"},
{"title": "Schuff", "text": "T1 Schuff Class: NodeT1Schuff Calculate a T1 map using two inversion recovery images and a reference spin echo image. Inversion times, and repetition time (TR) are detected from the input images. The equation for calculating the T1 map is: \(\displaystyle T_1 = \frac{TI_2-TI_1}{\ln\left(\frac{S_e-(-S_{IR1})}{S_e-S_{IR2}}\right)}\), where \(TI_2\) and \(TI_1\) are the inversion times for images 1 and 2, \(S_e\), \(S_{IR1}\), \(S_{IR2}\) are the signals for the spin echo image and the inversion recovery images, respectively. Produces a T1 map [ms] as output. Inputs SE Spin echo image. Type: Image4DFloat, Required, Single IR Inversion recovery images. Type: Image4DFloat, Required, Multiple Outputs T1 Map Resulting T1 map. Type: Image4DFloat References Jahng, L. Stables, A. Ebel, G. B. Matson, D. J. Meyerhoff, M. W. Weiner, and N. Schuff, “Sensitive and fast T1 mapping based on two inversion recovery images and a reference image,” Med. Phys., vol. 32, no. 6, pp. 1524–1528, May 2005. Keywords: T1, MRI, parametric, map, Schuff, longitudinal, relaxation ", "tags": "", "url": "nodes.image.mri.t1_map.schuff.html"},
{"title": "T2/T2* Map", "text": "T2/T2* Map Class: NodeT2Map Calculates a T2 or T2* map from spin echo or gradient echo data with multiple echo times. At least two images are required, however, more images are advised if a larger range of T2/T2* values are expected. Echo times (TE) are detected automatically and it is required that other parameters affecting the contrast must be the same for all images. An optional mask can also be provided to limit the calculations to a region.Produces a T2 / T2 * map[ms], and S0 which contains all weighting that is independent of T2/T2*. The parameter values are obtained by fitting the data to the signal equation \(S = S_0\exp(-T_E/T_2)\) in which T2 also can be T2*. Two algorithms can be applied. Either a nonlinear algorithm that performs a nonlinear least squares fit to the data, or a linear least squares fit which fits the linear model that results from taking the logarithm of the equation above. Inputs Echo Series Input image series with different echo times. Type: Image4DFloat, Required, Multiple Mask Input mask. Type: Image4DBool, Optional, Single Outputs T2 Resulting T2 map. Type: Image4DFloat Settings Method Selection Use the linearized or the nonlinear algorithm. Values: Linear, NonLinear References P.A. Boulby and F. Rugg-Gunn, “T2: the Transverse Relaxation Time,” in Quantitative MRI of the brain: Measuring changes caused by disease, P. S. Tofts, Ed. Wiley, 2003, pp. 143–201. Keywords: T2, T2*, T2star, star, transverse, relaxation, parameter, map, linear, nonlinear ", "tags": "", "url": "nodes.image.mri.t2t2_map.html"},
{"title": "Parker AIF", "text": "AIF Class: NodeParkerStandardAIF A population based standard AIF. The bolus arrival of the AIF is adjusted to the data labeled as &lsquo;Dynamic Series&rsquo;. The adjustment is made based on an average curve from the &quot;Dynamic Series''. The region in which the curve is averaged is: - The supplied mask or - The entire image if no mask is supplied.To find the best bolus arrival time (BAT) an extensive search is performed with a time step given in the UI of the node. The merit function on which the best arrival time is based on is a fit to the Kety/Extended Kety model. The fit is performed for a maximum duration after the bolus arrival as indicated in the settings.The node produces an AIF [mM] that is matched to the bolus arrival of the dynamic data. In addition, bolus arrival time and frame number are also accessible as outputs. These are useful when defining the baseline signal of a DCE-MRI scan. Inputs Dynamic Series Input dynamic series. Type: Image4DFloat, Required, Single Mask Input mask. This mask defines the region which is averaged to create the AIF. Type: Image4DBool, Optional, Single Outputs AIF Resulting AIF. Type: CurveCollection Start Time The bolus arrival time. Type: Double Start Frame The bolus arrival frame. Type: Double Settings AIF parameters Peak amplitude, A1, [mM] Number The amplitude of the main peak Peak width, Sigma1, [min] Number The width (standard deviation) of the main peak Peak time, T1, [min] Number The time at the center of the main peak Recirculation peak amplitude, A2, [mM] Number The amplitude of the recirculation peak Recirculation peak width, Sigma2, [mM] Number The width (standard deviation) of the recirculation peak Reciruclation peak time, T2, [min] Number The time at the center of the recirculation peak Tail amplitude, Alpha, [mM] Number The amplitude of the concentration in the tail. Tail drop-off, Beta, [min⁻¹] Number The rate with which the tail concentration drops of. Tail raise, s, [min⁻¹] Number The speed with which the tails raises at the arrival of the bolus. Tail delay time, tau, [min] Number The tail raise delay. Large vessel Hematocrit, Hct Number The Hematocrit. BAT parameters Search timestep [s] Number The BAT search time step. Duration of fit [min] Number The duration (after bolus arrival) during which the fit should be performed. Fitting model Selection The model used in the fitting. Values: Normal, Extended References Parker GJ, Roberts C, Macdonald A, et al. Experimentally-derived functional form for a population-averaged high-temporal-resolution arterial input function for dynamic contrast-enhanced MRI. Magn Reson Med 2006;56:993–1000. Murase K. Efficient method for calculating kinetic parameters using T1-weighted dynamic contrast-enhanced magnetic resonance imaging. Magn Reson Med 2004;51:858–862 Keywords: AIF, Kety, DCE, Parker, BAT, bolus, arrival ", "tags": "", "url": "nodes.image.mri.aif_generation.parker_aif.html"},
{"title": "CA Quantifier", "text": "CA Quantifier Class: NodeCAQuantifier Calculates contrast agent (CA) concentration map based on a \(T_1\) map [ms] a baseline signal (signal at zero Ca concentration) and dynamic data acquired during which CA is present in the imaged region. All images must correspond to the same region and Baseline and Dynamic Series must have the same settings. An optional mask can also be provided to limit the calculations to a region.The following signal models are supported: Spoiled gradient echo CA concentration is found from the ratio of the dynamic signal and the baseline signal by inverting the spoiled gradient echo equation(ignoring \(T_2^*\)-effects). Saturation Recovery CA concentration is found by using the signal equation \(S=S_0(1-\exp(-T_I/T_1))\) and a ratio between baseline (\(S_0\)) and dynamic signal (\(S\)). In the signal equation T1 is related to the contrast concentration \(C\) through \(T_1^{-1} = T_{10}^{-1} + r_1C\) In these two equations \(TI\) is the saturation delay (referred to as inversion time in the DICOM data) and \(T_{10}\) is the \(T_1\) without contrast agent.Outputs a CA concentration map [mM]. Inputs T1 Input T1 map. Type: Image4DFloat, Required, Single Baseline Input baseline image. Type: Image4DFloat, Required, Single Dynamic Series Input dynamic series. Type: Image4DFloat, Required, Single Mask Input mask. Type: Image4DBool, Optional, Single Outputs CA Resulting contrast agent concentration map. Type: Image4DFloat Settings Model Selection Signal model. Values: SPGR, SaturationRecovery R1 (mM¯¹s¯¹) Number T1 relaxivity of the CA. Set Undefined Numbers To Number Undefined values(failed fits) are set to this value. References Schabel and D. L. Parker, “Uncertainty and bias in contrast concentration measurements using spoiled gradient echo pulse sequences,” Phys. Med. Biol., vol. 53, no. 9, pp. 2345–2373, May 2008 Blüml Msc, Stefan &amp; R. Schad, Lothar &amp; Stepanow, Boris &amp; J. Lorenz, Walter. (1993). Spin-lattice relaxation time measurment by means of a TurboFLASH technique. Magnetic Resonance in Medicine. 30. 289 - 295. 10.1002/mrm.1910300304. Keywords: dce, dynamic, contrast, enhanced, t1, map ", "tags": "", "url": "nodes.image.mri.ca_quantifier.html"},
{"title": "Linear KETY Estimator", "text": "Kety Class: NodeLinearKetyEstimator Fit a contrast agent concentration (CA) curve to the Kety Model (also known as the Tofts model). Both 2 and 3 parameter models can be used. In the three parameter model CA residing in the vascular compartment is included in the model. To select model, use &lsquo;Normal&rsquo; or 'Extended' for the two and three parameter models, respectively.Three inputs can be used. An image with CA concentation (in milli molar) and an AIF is required. To speed up the calculations a mask can be used to reduce the region where the analysis is performed to a part of the image. A linear least squares method is used for the fitting. Inputs CA Input contrast agent concentration map. Type: Image4DFloat, Required, Single AIF Input arterial input function. Type: CurveCollection, Required, Single Mask Input mask which defines the region where the Kety estimator will be applied. Type: Image4DBool, Optional, Single Outputs Ktrans Ktrans map. A measure of capillary permeability in each voxel. Type: Image4DFloat ve Ve map. The fractional volume of the extravascular extracellular space. Type: Image4DFloat vp Vp map. The fractional plasma volume. Type: Image4DFloat Settings Kety Model Selection Use Normal for the two parameter model and Extended for the 3 parameter model. Values: Normal, Extended Set undefined values to Number Undefined values (failed fits) are set to this value. References 1. Murase K. Efficient method for calculating kinetic parameters using T1-weighted dynamic contrast-enhanced magnetic resonance imaging. Magn Reson Med 2004;51:858–862 See also Keywords: ", "tags": "", "url": "nodes.image.mri.linear_kety_estimator.html"},
{"title": "Brix", "text": "Brix Class: NodeBrix Calculates pharmacokinetic maps using a modified Brix model with the assumption that signal enhancement is linearly dependent on contrast agent (CA) concentration. The model is given by: \(\displaystyle \frac{S(t)}{S(0)} = 1+A \frac{kep}{kel-kep} \Big(\exp(-kep\cdot t)-\exp(-kel\cdot t)\Big)\) in which \(S(t)\) is the dynamic signal and \(S(0)\) is the baseline signal. Two imputs are required: A baseline signal and a dynamic signal.These must correspond to data acquisition sequences with identical settings(except number of frames). An optional mask can also be provided to limit the calculations to a region.Produces a pharmacokinetic maps A [arb. unit], kel [min \(^{-1}\)] and kep [min \(^{-1}\)]. Inputs Signal The dynamic image. Type: Image4DFloat, Required, Single Baseline The baseline image. Type: Image4DFloat, Required, Single Mask Input mask which defines the region where the calculations will be performed. Type: Image4DBool, Optional, Single Outputs A Amplitude parameter map. Type: Image4DFloat Kel The elimination constant parameter map. Type: Image4DFloat Kep The exchange rate constant from the EES to plasma. Type: Image4DFloat Residual Norm The residual norm. Type: Image4DFloat Settings Guess A per voxel Boolean Allow A to be a fitting parameter per voxel (TRUE) or assume a sptially constant A (FALSE). A Number Amplitude parameter. Kel (min¯¹) Number Contrast elimination rate. Kep (min¯¹) Number Contrast extraction rate. References Ma, J. F. Griffith, D. K. Yeung, and P. C. Leung, “Modified brix model analysis of bone perfusion in subjects of varying bone mineral density,” J. Magn. Reson. Imaging, vol. 31, no. 5, pp. 1169–1175, May 2010 Keywords: Brix, dynamic, contrast, dce, kep, kel ", "tags": "", "url": "nodes.image.mri.brix.html"},
{"title": "Area Under Curve", "text": "Area Under Curve Class: NodeAreaUnderCurve Calulate the area under the curve for each voxel in a dynamic series over a set timespan. If a baseline image is connected, values from this image will be subtracted from each voxel before it is added. If no baseline image is connected 0 will be used as baseline. Inputs Time Series Input dynamic series. Type: Image4DFloat, Required, Single Baseline Input baseline image. Type: Image4DFloat, Optional, Single Outputs Out Resulting parameter map. Type: Image4DFloat Settings Timespan(s) Number The number of seconds the algorithm should use to calculate the area. This value needs to be high enough to include at least two frames. Keywords: area, dce, mri, AUC, IAUC ", "tags": "", "url": "nodes.image.mri.area_under_curve.html"},
{"title": "B1 Correction Map", "text": "B1 Correction Map Class: NodeBOneCorrection Use the double angle method to compute a B1 correction map. Two images are required. Flip angles (FAs) are detected automatically and it is important that all other parameter affecting the contrast, e.g. TE, is the same for both angles.Produces a B1 - correction map.The map represents a scaling of flip angles, hence value 1 indicates that the nominal FA is achieved. Inputs Angle 1 Input image. Type: Image4DFloat, Required, Single Angle 2 Input image. Type: Image4DFloat, Required, Single Outputs B1 Map Resulting B1 map. Type: Image4DFloat References Wang, W. Mao, M. Qiu, M. B. Smith, and R. T. Constable, “Factors Influencing Flip Angle Mapping in MRI : RF Pulse and B 0 Inhomogeneities Measurement of Relative Flip Angles,” Magn. Reson. Med., vol. 56, no. 2, pp. 463–468, 2006 Keywords: B1, map, flip ", "tags": "", "url": "nodes.image.mri.b1_correction_map.html"},
{"title": "SUV", "text": "SUV Class: NodePETSUV Calculates the standardized uptake value (SUV) of a PET image. The SUV is a dimensionless, semiquantative measure of tracer uptake, i.e. it is the ratio of actavity in each voxel related to the injected activity. It is calculated as \[ \begin{equation} SUV = \frac{r}{(a'/w)} \label{eq:sample} \end{equation} \] where \(r\) is the radioactivity concentration measured by the PET scanner, \(a'\) is the decay corrected amount of injected tracer and \(w\) is the patient weight. Inputs PET Image A PET image. To calulcate SUV (without having to override the metadata and provide numbers manually), some metadata tags pertaining to half-life, patient weight, total administered dose and administration time are mandatory. Type: Image4DFloat, Required, Single Outputs Result The output SUV parameter map. Type: Image4DFloat Settings Override Patient Weight Boolean If set the specified patient weight will be used instead of the weight from metadata. Half Life Boolean If set the specified half life will be used instead of the half life from metadata. Total Dose Boolean If set the specified dose will be used instead of the dose from metadata. Administration Date/Time Boolean If set the specified date/time will be used instead of the date/time from metadata. Override Parameters Patient Weight(kg) Number Patient weight in kilograms. Half Life(s) Number The radionuclide half life, in seconds, that was used in the correction of this image. Total Dose(MBq) Number Total dose specified in MBq to use when &lsquo;Set Total Dose&rsquo; is selected. Administration(Date/Time) Date The actual time of radiopharmaceutical administration to the patient for imaging purposes. References SUV on Wikipedia See also Keywords: Standardized uptake value ", "tags": "", "url": "nodes.image.pet.suv.html"},
{"title": "Dose Volume Histogram", "text": "DVH Class: NodeDoseVolumeHistogram A dose-volume histogram relates the radiation dose to the tissue volume and summarizes a 3D dose distribution to a graphical 2D format. The node produces the cumulative dose-volume histogram for the supplied dose matrix and structure(s). The structures are supplied as images (i.e. Smooth masks) to ensure that the output values are accurate. Example workflows Dose-volume histogram example Inputs Dose An image containing the dose matrix to be evaluated. This image is normally produced by importing a DICOM RT DOSE, or RD file. Type: Image4DFloat, Required, Single Volume(s) One or multiple Smooth Mask(s), describing the structures for which the DVH should be produced. They must be of the same matrix size as the dose image. Type: Image4DFloat, Required, Multiple Outputs DVH Plot A plot contains the DVH. The DVH can be viewed in the Node Output panel, in the Plot pane. Type: CurveCollection DVH Data A table containing the DVH parameters. Basic parameters include image and structure information, such as names and volume. It also includes Dmin, Dmax and Dmean by defeault. It also includes other parameters that are specified in the Node Settings panel, for example D95. Type: DataCollection DVH Plot Data A table with the DVH plot data, so that the user can plot the DVHs using any other software. The first column lists the dose levels (x-axis) and each of the following columns contain the volume levels (y-axis) for a specific structure specified by the Smooth Mask(s). Type: DataCollection Settings Structures For detailed explanations on supersampling of structures, see Struct Processor. Render Structures Boolean Renders all structures available in a connected RT-Struct collection, instead of connecting multiple Smooth Masks, on the connected Dose input to produce DVH data. Maximum Volume Error(%) Number The tolerance of difference between the numeric volumes calculated directly from the RT-struct polygons and the rendered Smooth Mask. Maximum Iterations Integer Sets the maximum number of iterations of adaptive supersumpling to reach Maximum Volume Error (%) before breaking. Use Error Stopping Criteria Boolean If set, the automatic upsampling will stop if the volume error doesn't change between iteration. Error Stopping Criteria(%) Number If using error stopping criteria the automatic upsampling will stop if the absolute volume error doesn't change by at least this much compared to the error of the previous iteration. End Cap Thickness (mm) Number Sets the end cap thickness to use when rendering structures Histogram Title Text Title of the diagram. Minimum Dose(Gy) Number Minimum dose of the histogram. Maximum Dose(Gy) Number Maximum dose of the histogram. Bins Integer Number of bins in the histogram. Analysis Prescribed Dose(Gy) Number Set the prescribed dose. Used to calculate relative dose (needed in e.g. V90%). Dose Levels Text Set the dose levels of interest to be explicitly displayed in the DVH Data output. Supplied as a comma separated list, so if you want D2 and D98, write &ldquo;2, 98&rdquo;. Volume Levels(%) Text Set the volume levels of interest to be explicitly displayed in the DVH Data output. Supplied as a comma separated list, so if you want V10 and V60, write &ldquo;10, 60&rdquo;. Volume Levels(Gy) Text Set the volume levels of interest to be explicitly displayed in the DVH Data output. Supplied as a comma separated list, so if you want V5Gy and V10Gy, write &ldquo;5, 10&rdquo;. Output Absolute Volume Boolean Output volume in cc instead of %. References Dose-volume histogram on Wikipedia See also Keywords: DVH, Dose-volume histogram, Smooth Mask ", "tags": "", "url": "nodes.image.radiotherapy.dose_volume_histogram.html"},
{"title": "Gamma Index", "text": "Gamma Index Class: NodeDoseGammaIndex Calculates the gamma index, first introduced by Low et al, between a reference and an evaluation dose distribution in 3D with sub-voxel accuracy according to the algorithm described by Wendling et al. It will only calculate the gamma index for reference voxels &gt;0. Definition of the gamma index The gamma index combines the dose difference and the distance difference into a dimensionless metric. In principle, this metric should be calculated for each reference point against all points in the evaluated dose distribution. The gamma statistic is calculated as \[ \begin{equation} \Gamma(\textbf{r}_R,\textbf{r}_E) = \sqrt{\frac{\Delta r^2(\textbf{r}_R,\textbf{r}_E)}{\delta r^2} + \frac{\Delta D^2(\textbf{r}_R,\textbf{r}_E)}{\delta D^2}} \label{eq:sample} \end{equation} \] where \(\delta r\) is the distance criterion (distance to agreement or DTA) and \(\delta D\) is the dose difference criterion. The \(\gamma\) is then taken as the minimum \(\Gamma\) value over all evaluated points. If \(\gamma &lt; 1\), that point will pass. Standard values for \(\delta r\) is 3 mm and \(\delta D\) is 3%, and a standard value for accepting agreement between two distributions is usually that 97% of all evaluated points should pass. Example workflows Gamma index example Inputs Reference Dose An image containing the dose matrix to be used as reference. This image is normally produced by importing a DICOM RT DOSE, or RD file. Type: Image4DFloat, Required, Single Evaluated Dose An image containing the dose matrix to be evaluated. This image is normally produced by importing a DICOM RT DOSE, or RD file. It must have the same matrix size as the reference dose. Type: Image4DFloat, Required, Single Mask A mask which specifies in which area the gamma index should be evaluated. It only applies to points in the evaluated dose. It must have the same matrix size as the reference dose. Type: Image4DBool, Optional, Single Outputs Map A parameter map which contains the \(\gamma\) values. Type: Image4DFloat Fail Map A binary image which is True where \(\gamma &gt; 1\), i.e. failed points. Type: Image4DBool Evaluated Map A binary image which is True for points that have been included in the evaluation. Type: Image4DBool Gamma Index A table which contains information on the gamma evaluation, such as names of the evaluated distributions, the number of evaluated voxels and the gamma pass rate. Type: DataCollection Settings Sample Step Size(mm) Number Determines the resolution of the evaluation, i.e. the accuracy of the interpolation. Recommended step size is at most 1/3 of the distance to agreement (DTA) and a fraction of the resolution of the voxel size. As an example, for a 1 mm DTA and voxel size of 2 mm, a step size of 0.25 mm would be suitable. Increasing resolution increases computation time. Prescribed Dose(Gy) Number The dose to which the dose criteria is related to if the option Use Local Dose Reference is not selected. I.e. if a 3% dose criterion is chosen and the prescribed dose is 10 Gy, the absolute dose difference criteria in the gamma calculations will be 0.3 Gy. Use Local Dose Reference Boolean If comparing the gamma distribution on a local level, i.e. not normalized to the prescribed dose, this option should be activated. This will check the dose difference at each individual sample point and normalize it to the dose level in the current reference voxel. Dose Criteria(%) Number Sets the dose criteria. Distance Criteria(mm) Number Sets the distance criteria, or distance to agreement. Search Radius(mm) Number Sets the radius of the sphere around each evaluated voxel to evaluate the gamma index for. If the user desires a pass/fail gamma evaluation, the Search Radius can be set equal to Distance Criteria. If a more thorough evaluation is desired, set the Search Radius to at least 3 times the Distance Criteria. Increasing the search radius increases the computation time. References 1. Low D a, Harms WB, Mutic S, et al. A technique for the quantitative evaluation of dose distributions. Med. Phys. 1998;25:656–61. 2. Wendling M, Zijp LJ, McDermott LN, et al. A fast algorithm for gamma evaluation in 3D. Med. Phys. 2007;34:1647–54. See also Keywords: ", "tags": "", "url": "nodes.image.radiotherapy.gamma_index.html"},
{"title": "Equivalent Uniform Dose", "text": "EUD Class: NodeEquivalentUniformDose Calculates the equivalent uniform dose (EUD), tumor control probability (TCP) and normal tissue complication probability (NTCP) to volumes, which can be used for quantitatively comparing and reporting inhomogeneous dose distributions based on radiobiological effect. The EUD parameter summarizes the 3D dose distribution in a volume to a dose &ldquo;which, when distributed uniformely across the target volume, cases the survival of the same number of clonogens&rdquo;, as described by Niemierko. EUD is calculated as follows: \[ \begin{equation} EUD = \left(\sum_i{v_i D_i^a}\right)^{1/a} \label{eq:1} \end{equation} \] where \(v_i\) is the fractional organ volume recieving a dose \(D_i\) and \(a\) is a tissue specific parameter that describes the volume effect. TCP is calculated as \[ \begin{equation} TCP = \frac{1}{1 + \left(\frac{TCD_{50}}{EUD}\right)^{4\gamma50}} \label{eq:2} \end{equation} \] where \(\gamma_{50}\) describes the slope of the dose-response curve. \(TCD_{50}\) is the dose to control 50% of the tumors. NTCP is calculated as \[ \begin{equation} NTCP = \frac{1}{1 + \left(\frac{TD_{50}}{EUD}\right)^{4\gamma50}} \label{eq:3} \end{equation} \] where \(TD_{50}\) is the tissue tolerance dose, i.e. the dose that causes normal tissue complication in 50% of cases. Example workflows Equivalent uniform dose example Inputs Dose An image containing the dose matrix to be evaluated. This image is normally produced by importing a DICOM RT DOSE, or RD file. Type: Image4DFloat, Required, Single Volume(s) Mask(s) containing the structures for which to calculate the EUD. Must have the same matrix size as the dose. Type: Image4DBool, Required, Multiple Outputs EUD A table containing information on the dose and structures evaluated as well as the EUD, normal tissue complication probability (NTCP) and and tumor control probability (TCP). Type: DataCollection Settings The values of these settings can be found in literature, for example in this reference by Emami. EUD a Number Tissue specific parameter that describes volume effect. NTCP/TCP γ50 Number Slope of the dose-response curve. TD50 Number The tissue tolerance dose, i.e. the dose that causes normal tissue complication in 50% of cases. TCD50 Number The dose of radiation that locally controls 50% of tumors. References 1. %22Reporting and analyzing dose distributions: A concept of equivalent uniform dose%22, Medical Physics, 1996, Andrzej Niemierko. See also Keywords: EUD, TCP, NTCP, equivalent uniform dose, normal tissue complication probablity, tumor control ", "tags": "", "url": "nodes.image.radiotherapy.equivalent_uniform_dose.html"},
{"title": "Induced Susceptibility Effect", "text": "ISE Class: NodeInducedSusceptibilityEffect Produces the induced susceptibility effect for the supplied magnetic susceptibility map in form of the local B0-field, distorted image and distortion field. The input values are the image matrix together with the magnetic susceptibility map and patient mask. Inputs Image Missing description. Type: Image4DFloat, Required, Single Susceptibility Missing description. Type: Image4DFloat, Required, Single Mask Missing description. Type: Image4DBool, Required, Single Outputs Local B0 Missing description. Type: Image4DFloat Distorted Image Missing description. Type: Image4DFloat Distortion Field Missing description. Type: Image4DVector3 Distortion Field Shifted Missing description. Type: Image4DVector3 Settings B0 Number The field strength (T) of the B0-field Lorenz Correction Boolean Applies the Lorentz sphere correction Positive Shift X Boolean Sets the direction of the x-gradient in relation to the image matrix Positive Shift Y Boolean Sets the direction of the y-gradient in relation to the image matrix Positive Shift Z Boolean Sets the direction of the z-gradient in relation to the image matrix Bandwidth X (Hz/Voxel) Number The applied bandwidth (frequency encoding) in the X-direction given in Hz/Voxel Bandwidth Y (Hz/Voxel) Number The applied bandwidth (frequency encoding) in the Y-direction given in Hz/Voxel Bandwidth Z (Hz/Voxel) Number The applied bandwidth (read out) in the Z-direction given in Hz/Voxel Gyromagnetic Ratio (Hz/T) Number The gyromagnetic ratio to use. Typically this is the default value of 42.57e+6 Hz/T References J A Lundman, M Bylund, A Garpebring, C Thellenberg Karlsson, T Nyholm. Patient-induced susceptibility effects simulation in magnetic resonance imaging. Physics and Imaging in Radiation Oncology. (2017) DOI: 10.1016/j.phro.2017.02.004 &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.radiotherapy.induced_susceptibility_effect.html"},
{"title": "Susceptibility Map", "text": "Susceptibility Class: NodeSusceptibility Converts a CT-image to a magnetic susceptibility map. Inputs CT Image Input CT image. Type: Image4DFloat, Required, Single Mask Input mask. Type: Image4DBool, Optional, Single Outputs Susceptibility Resulting susceptibility map. Type: Image4DFloat References J A Lundman, M Bylund, A Garpebring, C Thellenberg Karlsson, T Nyholm. Patient-induced susceptibility effects simulation in magnetic resonance imaging. Physics and Imaging in Radiation Oncology. (2017) DOI: 10.1016/j.phro.2017.02.004 See also Keywords: susceptibility, map, magnetic, CT ", "tags": "", "url": "nodes.image.radiotherapy.susceptibility_map.html"},
{"title": "B0 Distortion", "text": "B0 Distortion Class: NodeB0Distortion Produces the distortions created by B0 inhomogeneities. The input values are the image matrix together with the delta B0 map and patient mask. Inputs Image Missing description. Type: Image4DFloat, Required, Single B0 Missing description. Type: Image4DFloat, Required, Single Mask Missing description. Type: Image4DBool, Required, Single Outputs Distorted Image Missing description. Type: Image4DFloat Distortion Field Missing description. Type: Image4DVector3 Distortion Field Shifted Missing description. Type: Image4DVector3 Settings Positive Shift X Boolean Sets the direction of the x-gradient in relation to the image matrix Positive Shift Y Boolean Sets the direction of the y-gradient in relation to the image matrix Positive Shift Z Boolean Sets the direction of the z-gradient in relation to the image matrix Bandwidth X (Hz/Voxel) Number The applied bandwidth (frequency encoding) in the X-direction given in Hz/Voxel Bandwidth Y (Hz/Voxel) Number The applied bandwidth (frequency encoding) in the Y-direction given in Hz/Voxel Bandwidth Z (Hz/Voxel) Number The applied bandwidth (read out) in the Z-direction given in Hz/Voxel Gyromagnetic Ratio (Hz/T) Number The gyromagnetic ratio to use. Typically this is the default value of 42.57e+6 Hz/T References J A Lundman, M Bylund, A Garpebring, C Thellenberg Karlsson, T Nyholm. Patient-induced susceptibility effects simulation in magnetic resonance imaging. Physics and Imaging in Radiation Oncology. (2017) DOI: 10.1016/j.phro.2017.02.004 &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.radiotherapy.b0_distortion.html"},
{"title": "Statistics", "text": "Statistics Class: NodeImageStatistics Calculate statistical properties of one or more images, or a region in the input image(s) defined by one or multiple masks. Example Workflows Statistics examples Inputs Input One or more images. Type: Image4DFloat, Required, Multiple Masks Binary mask(s) with the same matrix size as the input image(s). Type: Image4DBool, Optional, Multiple Outputs Output A Data table with the statistical properties of the image(s) or region(s). Type: DataCollection Settings Node Tag Text The name of the data table. If you export the data to .xls or .csv, this will be used as the file name. Statistics Mean Boolean Calculate the mean voxel value of the image, or region of the image defined by the mask. Max Boolean Calculate the maximum voxel value of the image, or region of the image defined by the mask. Min Boolean Calculate the minimum voxel value of the image, or region of the image defined by the mask. Standard Deviation Boolean Calculate the standard deviation of voxel values of the image, or region of the image defined by the mask. Volume Boolean Calculate the volume of the image, or region of the image defined by the mask. Median Boolean Calculate the median voxel value of the image, or region of the image defined by the mask. Kurtosis Boolean Calculate the kurtosis of voxel values of the image, or region of the image defined by the mask. Skewness Boolean Calculate the skewness of voxel values of the image, or region of the image defined by the mask. Calculate Percentiles Boolean Calculate the percentiles (defined below) of the image, or region of the image defined by the mask. Percentiles Text The percentiles to calculate if the &ldquo;Calculate percentiles&rdquo; option is true. See also Keywords: ", "tags": "", "url": "nodes.image.statistics.statistics.html"},
{"title": "Histogram", "text": "Histogram Class: NodeImageHistogram Creates histogram plots for connected images. Example Workflows Statistics examples Inputs Images One or more image(s). Type: Image4DFloat, Required, Multiple Outputs Out Histogram plots of the input image(s). Type: CurveCollection Settings Bins Integer Sets the number of bins for the histogram(s). Automatic Bounds Boolean If TRUE, the bounds for each histogram will be the lowest and highest voxel value in each image. Lower Bound Number If not using automatic bounds this value will be used as the lower bound for all histograms. Upper Bound Number If not using automatic bounds this value will be used as the upper bound for all histograms. Logarithmic Scale Boolean If TRUE the histogram will be presented in a logarithmic scale. See also Keywords: ", "tags": "", "url": "nodes.image.statistics.histogram.html"},
{"title": "Image Time Statistics", "text": "Time Statistics Class: NodeTimeImageStatistics Calculate statistical properties per voxel in a time series. This node generates 3D images where each voxel value reflects a statistical property in the temporal dimension. Example Workflows Statistics examples Inputs Input An image time series. Type: Image4DFloat, Required, Single Mask A 3D binary mask. Type: Image4DBool, Optional, Single Outputs Mean The mean value of each voxel in the temporal dimension. Type: Image4DFloat Max The maximum value of each voxel in the temporal dimension. Type: Image4DFloat Min The minimum value of each voxel in the temporal dimension. Type: Image4DFloat Standard Deviation The standard deviation of each voxel in the temporal dimension. Type: Image4DFloat Settings Node Set Undefined Numbers To Number Undefined values are set to this value. Statistics Mean Boolean Calculate the temporal mean of each voxel, or voxels defined by the mask. Max Boolean Calculate the temporal maximum of each voxel, or voxels defined by the mask. Min Boolean Calculate the temporal minimum of each voxel, or voxels defined by the mask. Standard Deviation Boolean Calculate the temporal standard deviation of each voxel, or voxels defined by the mask. Median Boolean Calculate the temporal median of each voxel, or voxels defined by the mask. Kurtosis Boolean Calculate the temporal kurtosis of each voxel, or voxels defined by the mask. Skewness Boolean Calculate the temporal skewness of each voxel, or voxels defined by the mask. Calculate Percentiles Boolean Calculate the temporal percentiles (defined below) of each voxel, or voxels defined by the mask Percentiles Text The percentiles to calculate if the &ldquo;Calculate percentiles&rdquo; option is true, separated by commas. See also Keywords: ", "tags": "", "url": "nodes.image.statistics.image_time_statistics.html"},
{"title": "Region Time Statistics", "text": "Time Statistics Class: NodeTimeStatisticsRegion Calculate statistics of a time series, frame-by-frame, in supplied regions. The output Data Table is similar to the Statistics node, but in this node statistical properties are calculated frame-by-frame. Example Workflows Statistics examples Inputs Time Series An image time series. Type: Image4DFloat, Required, Single Label Maps A Label map image where statistical properties should be calculated. Type: Image4DFloat, Required, Single Outputs Data A Data Table with the statistical properties of the image in the different labels. Type: DataCollection Mean A plot showing the mean value for each frame and label. Type: CurveCollection Min A plot showing the minimum value for each frame and label. Type: CurveCollection Max A plot showing the maximum value for each frame and label. Type: CurveCollection Sum A plot showing the sum for each frame and label. Type: CurveCollection SD A plot showing the standard deviation for each frame and label. Type: CurveCollection Settings Tag Text The name of the data. If you export the data to .xls or .csv, this will be used as the file name. See also Keywords: ", "tags": "", "url": "nodes.image.statistics.region_time_statistics.html"},
{"title": "DICOM .dcm", "text": "DICOM Class: NodeExportDICOM Convert and save connected images to DICOM files on disk. DICOM is a standardized image format for storing and sending medical images from many different modalities. With each image comes extensive metadata information regaring e.g. imaging modality, imaging settings, scan time and date, patient information etc. Many metadata tags are specific to one modality, which makes a function that fully adheres to the DICOM standard difficult to implement. This is important if images are imported in other software such as dose planning programs or sent to a DICOM node or PACS for storage. For this reason, MICE Toolkit supports three DICOM image export modalities; CT, MRI, and RTDOSE. Quantization errors in DICOM DICOM can only save pixel data in integer values between 0 and 65,535. To represent decimal values, a linear transformation is applied to the pixel data. The slope and intercept of this transformation is calculated so that the range of integer values in the dicom image covers the dynamic range of the values being stored. For large pixel ranges this method will lead to quantization error. To minimize the ammount of quantization, make sure you limit the range of values in the images. Voxels with extreme values outside the window of interest will lead to a large quantization error. This is illustrated in the figure below. The figure shows two image histograms after a linear transformation. The images are identical, except for a few outlier voxel values of 100 in the right image. In this toy example, there are 50 gray levels available. If the span of intensities is [0 - 15], the quantization error is quite small. However, if the span is [0 - 100], the quantization error is much larger. Example Workflows Export to DICOM examples Inputs In One or more images. Type: Image4DFloat, Required, Multiple Settings Export Modality Selection Defines what the resulting DICOM images modality should be. Values: MR, CT, RTDOSE Series Description Text Defines what the resulting DICOM images series description should be. Slicewise Slope/Intercept Boolean If TRUE, the intercept and slope will be recalculated for each slice, this might lead to a smaller quantization error. Force Integer Values Boolean If TRUE, the node will try to save voxel values as integer values (if modality is set to RTDOSE this setting will be ignored). The slope will always be 1, intercept will be adjusted. Voxel values will be rounded to the nearest integer value. If the total span of values in the image is more than 65535, values outside that span will be truncated.WARNING: Using this feature might drastically change your data and should only be used if you fully understand what it does. Protocol Name Text Name of the protocol if applicable. Set Image Name Boolean If TRUE, the specified image name will be used to name the image(s). If more than one image is connected, a counter will be added to the end of the name. Image Name Text The new image name, will be used to name the image if the &ldquo;Set Image Name&rdquo; option is selected. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Metadata Override Metadata Boolean If TRUE, the metadata for the exported files will be set to the fields in this category. The patient metadata from the input images will not be used if this is set. Patient ID Text Set the new patient ID. Patient Name Text Set the new patient name. Frame of Reference Text Set the new frame of reference. Study Date Date Set the new study date. DICOM Remote Send to remote storage Boolean If TRUE, the files will be sent to a remote DICOM storage instead of being saved to disk. Host Text The IP or hostname of the remote DICOM storage. AE Title Text The AE title of the remote DICOM storage. Port Integer Port to use when connecting to the remote dicom storage. See also DICOM Standard Browser for a complete list of all DICOM tags. Keywords: ", "tags": "", "url": "nodes.image.export.dicom_.dcm.html"},
{"title": "NIfTI .nii", "text": "NIfTI Class: NodeExportNIfTI Convert and export all connected images to NIfTI files. The NIfTI file format is much simpler than the DICOM format. Images are stored in one single file, and are not constrained to integer values. The default support for metadata is limited, and constrained to image properties such as position, orientation and resolution. Note: No DICOM metadata will be written to the file. Example Workflows Export image examples Inputs In One or more images. Type: Image4DFloat, Required, Multiple Settings Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). Compress Image Boolean Use lossless compression on the output image. Turn this off for faster exports. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. References WriteImage filter in SimpleITK Neuroimaging Informatics Technology Initiative The NIfTI file format See also Keywords: ", "tags": "", "url": "nodes.image.export.nifti_.nii.html"},
{"title": "Image .bmp, .jpg etc", "text": "Image Class: NodeExportBitmap Export images to a raster graphics image without metadata. Each slice is exported as a separate image. The following file formats are supported: bmp, gif, jpeg, png, tiff. Example Workflows Export image examples Inputs In One or more images to be exported. Type: Image4DFloat, Required, Multiple Settings Export Image Format Selection Format of the image(s). Values: Bmp, Gif, Jpeg, Png, Tiff Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). JPEG Quality % Integer Set the quality of the output JPEG. Single Slice Preview Boolean Export only the middle slice in the stack. Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Window Colormap Selection Select the colormap of the exported image. Values: BlackBody, Bone, Cividis, Cool, Copper, Dose, GE, Gray, InverseGray, Inferno, Jet, Magma, Moreland, Pink, Plasma, Sokoloff, Spring, Summer, Viridis, Winter Full Range Window Boolean If selected, the image intensity min and max bounds will be the min and max of the image. Window Min Number Set the intensity min (applies only if the Full range window option is false). Window Max Number Set the intensity max (applies only if the Full range window option is false). See also Keywords: ", "tags": "", "url": "nodes.image.export.image_.bmp,_.jpg_etc.html"},
{"title": "MetaIO .mhd", "text": "MHD Class: NodeExportMHDFloat Converts and exports all connected images to .mhd files. This file format is developed by the Insight Software Consortium, and a part of the Insight Segmentation and Registration Toolkit (ITK). Two files are written for each image: an .mhd file, which is a header file containing metadata describing image properties such as voxel size, matrix size, orientation and position, and a link to the binary image. This file can also contain limited metadata information. a .raw file, containing the binary image. The raw file can be compressed using gzip. Voxel values will be written as they are with no quantization. This might lead to very large files in some cases. Metadata can optionally be exported as an .xml file with the same basename as the exported image(s). Note: No DICOM metadata will be written to the .mhd file. Example Workflows Export image examples Inputs In One or more images to be exported. Type: Image4DFloat, Required, Multiple Settings Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). Compress Image Boolean Use lossless compression on the output .raw-file. Turn this off for faster exports. Export Metadata Boolean If TRUE, an XML file containing image metadata will be exported. Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Keywords: ", "tags": "", "url": "nodes.image.export.metaio_.mhd.html"},
{"title": "MATLAB .mat", "text": "MAT Class: NodeExportMATFloat Convert and export all connected images to MATLAB .mat files. Voxel values will be written as they are with no quantization, this might lead to very large files in some cases. Each .mat file will contain a structure array, with the following fields: Position: The position of the image Orientation: The orientation of the image VoxelSize: The voxel size of the image. Matrix: The image matrix. Version: The version of MICE Toolkit that was used to create the file. No DICOM metadata will be written to the MAT file. Inputs In One or more images to be exported. Type: Image4DFloat, Required, Multiple Settings Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Keywords: ", "tags": "", "url": "nodes.image.export.matlab_.mat.html"},
{"title": "CSV .csv", "text": "Image CSV Class: NodeExportImageCSV Convert and export all connected images to csv files. By default, the output will be a .csv text file with the following columns: Voxel Index X: The X index of the voxel. Voxel Index Y: The Y index of the voxel. Voxel Index Z: The Z index of the voxel. Voxel Index T: The T index of the voxel. Voxel Value: The value of the voxel. It is possible to export Voxel position and/or Patient Information for each voxel as well. The exact format of the output can be defined in the settings. This format is suited for exporting smaller regions of an image to be used for further processing, analysis or plotting in an external program. It is not intended for storing entire images, since this format is stored in text instead of binary which will lead to large file sizes. Inputs In One or more images to be exported. Type: Image4DFloat, Required, Multiple Mask A mask of the same dimensions as the input image(s), defining a region to be exported. Type: Image4DBool, Optional, Single Settings Export Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). Separator Text Set the separator between columns. Write Column Headers Boolean If TRUE, column headers will be written to the file. Single File Boolean Write all connected image values in the same file, in order for this to work all dimensions, positions and orientations needs to be exactly the same for all connected images.Note: If you don't need voxel center information only the matrix sizes need to be the same. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Image Information Patient Information Boolean if TRUE, the two first columns describe patient information. Patient ID and Patient Name will be written to each row. Voxel Index Boolean If TRUE, voxel indices will be written to each row. Voxel Center Boolean If TRUE, voxel positions will be written to each row. See also Keywords: ", "tags": "", "url": "nodes.image.export.csv_.csv.html"},
{"title": "Transformix .txt", "text": "TFX Class: NodeExportTFX Exports transformix parameters to one or more files. Inputs In One or more transforms from an Elastix node. Type: TransformixParameter, Required, Single Settings Filename Text Set the file name. Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Keywords: ", "tags": "", "url": "nodes.image.export.transformix_.txt.html"},
{"title": "Create New Image", "text": "Create Class: NodeImageCreate Creates a new image based on user settings. Outputs Out Resuling image. Type: Image4DFloat Settings Image Name Text Name of the image. Image Type Selection The type of image to create. Values: Mask, Image, Complex, Vector Clone Metadata Boolean Name of the image. Metadata Image Type Selection The type of image to create. Values: Mask, Image, Complex, Vector Size Matrix Size X Integer Number of pixels in x-direction Matrix Size Y Integer Number of pixels in y-direction Matrix Size Z Integer Number of pixels in z-direction Matrix Size T Integer Number of frames Position Position Offset X [mm] Number Offset in x-direction Position Offset Y [mm] Number Offset in y-direction Position Offset Z [mm] Number Offset in z-direction Resolution Resolution X [mm] Number Resolution in x-direction Resolution Y [mm] Number Resolution in y-direction Resolution Z [mm] Number Resolution in z-direction Resolution T [s] Number Time step between frames in seconds Rotation Rotation Axis X Number Rotation axis x-direction (not normalized) Rotation Axis Y Number Rotation axis y-direction (not normalized) Rotation Axis Z Number Rotation axis z-direction (not normalized) Rotation Angle [degrees] Number Rotation angle around the rotation axis in degrees Keywords: create, empty, image ", "tags": "", "url": "nodes.image.create_new_image.html"},
{"title": "AND", "text": "AND Class: NodeMaskAnd Performs a voxel-wise boolean AND operation in all supplied masks. If a voxels is TRUE in all masks, the resulting voxel in the output mask has is TRUE, otherwise it is FALSE. Inputs In At least two binary masks of the same dimensions. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Out A binary mask with the same spatial properties as the input masks. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.boolean_algebra.and.html"},
{"title": "NOT", "text": "NOT Class: NodeMaskNot Inverts a binary mask. For each voxel, the output is TRUE if input is FALSE and vice versa. Inputs In A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.boolean_algebra.not.html"},
{"title": "OR", "text": "OR Class: NodeMaskOr Performs a voxel-wise boolean OR operation in all supplied masks. If at least one input voxel is TRUE, the resulting voxel in the output mask is TRUE, otherwise it is FALSE. Inputs In At least two binary masks of the same dimensions. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Out A binary mask with the same spatial properties as the input masks. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.boolean_algebra.or.html"},
{"title": "XOR", "text": "XOR Class: NodeMaskXor Performs a voxel-wise boolean XOR operation in all supplied masks. If an odd number of input voxels are TRUE, the resulting voxel in the output mask is TRUE, otherwise it is FALSE. Inputs In At least two binary masks of the same dimensions. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Out A binary mask with the same spatial properties as the input masks. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.boolean_algebra.xor.html"},
{"title": "Erode", "text": "Erode Class: NodeMaskErode Erode a mask using binary morphology. Morphological erosion shrinks the boundary of a region of foreground pixels, i.e. pixels with value True, using a kernel. The resuling region is obtained by letting the kernel trace the boundary of the region, and removing voxels that cannot be reached by the center of the kernel. Fig. 1. The original mask (in gray) is eroded using a &ldquo;cross&rdquo; kernel, resulting in the white mask. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Erosion in SimpleITK Erosion on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.erode.html"},
{"title": "Dilate", "text": "Dilate Class: NodeMaskDilate Dilate a mask using binary morphology. Morphological dilation expands the boundary of a region of foreground pixels, i.e. pixels with value True, using a kernel. The resuling region is obtained by letting the kernel center trace the boundary of the region, and the resulting region includes all voxels that can be reached by the kernel. Fig. 1. The original mask (in gray) is dilated using a &ldquo;cross&rdquo; kernel, resulting in the white mask. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Dilation in SimpleITK Dilation on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.dilate.html"},
{"title": "Opening", "text": "Opening Class: NodeMaskOpening Apply the morphological opening operation on a binary mask. The morphological opening of a binary mask \(I\) is defined as the dilation of the erosion of the mask: \(\textrm{Opening}\left(I\right) = \textrm{Dilatation}\left(\textrm{Erosion}\left(I\right)\right)\). This filter removes small foreground structures in the mask. The size of the affected structures is controlled by the shape and size of the kernel. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Opening in SimpleITK Opening on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.opening.html"},
{"title": "Closing", "text": "Closing Class: NodeMaskClosing Apply the morphological closing operation on a binary mask. The morphological closing of a binary mask \(I\) is defined as the erosion of the silation of the mask: \(\textrm{Closing}\left(I\right) = \textrm{Erosion}\left(\textrm{Dilation}\left(I\right)\right)\). This filter removes small background structures such as holes in the mask. The size of the affected structures is controlled by the shape and size of the kernel. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. Safe Border Boolean A safe border is added to input image to avoid borders effects. It is removed after the closing operation is done. References Closing in SimpleITK Closing on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.closing.html"},
{"title": "Opening by Reconstruction", "text": "Opening by Reconstruction Class: NodeMaskOpeningByReconstruction This node preserves foreground regions that can completely contain the structuring element, and removes regions of foreground pixels that cannot contain the structuring element. Contrary to the morphological opening, the opening by reconstruction preserves the shape of the components that are not removed by erosion. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Opening by reconstruction in SimpleITK Opening by reconstruction on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.opening_by_reconstruction.html"},
{"title": "Closing by Reconstruction", "text": "Closing by Reconstruction Class: NodeMaskClosingByReconstruction This node removes holes in foreground components that will not completely fit the structuring element. Contrary to morphological closing, closing by reconstruction preserves the external shape of the foreground components. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Closing by reconstruction in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.closing_by_reconstruction.html"},
{"title": "Seed Reconstruction", "text": "Seed Reconstruction Class: NodeMaskSeedReconstruction Extracts connected regions in the input mask using seeds from the seed image. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Seed A binary mask with the same spatial properties as the input mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same dimensions as the input mask. Type: Image4DBool Settings Diagonal Connections Boolean If True, diagonal voxels will be considered when the regions are segmented. See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.seed_reconstruction.html"},
{"title": "Fill Hole", "text": "Fill Hole Class: NodeMaskFillHole Remove holes not connected to the boundary of the mask.Note: Geodesic morphology and the Fillhole algorithm is described in Chapter 6 of Pierre Soille's book &lsquo;Morphological Image Analysis: Principles and Applications&rsquo;, Second Edition, Springer, 2003. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Fully Connected Boolean Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. For objects that are 1 pixel wide, use FullyConnectedOn. Slicewise Boolean Perform the fill hole operation slice by slice. References 1.Fill hole in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.fill_hole.html"},
{"title": "Contour Interpolation", "text": "Interpolate mask Class: NodeMaskInterpolate Generates interpolated contours in empty slices in the specified slice orientation. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Result A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Orientation Selection Specifies the orientation of slices. E.g. if slice orientation is XY, slice interpolation will be in the z-direction. Values: XY, XZ, YZ See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.contour_interpolation.html"},
{"title": "Bounding Box", "text": "Bounding box Class: NodeMaskBounds Create a mask which defines the bounding box of the input mask. This bounding box is the smallest rectangular parallelepiped with sides parallel to the i, j and k axes that contains all TRUE voxels in the input mask. Inputs In A binary mask. Type: Image4DBool, Required, Multiple Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.bounding_box.html"},
{"title": "Contour", "text": "Contour Class: NodeMaskContour Creates contours of all connected regions in the input mask. Boundary voxels are kept TRUE, while the interior voxels are set to FALSE. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Fully Connected Boolean Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. For objects that are 1 pixel wide, use FullyConnectedOn. Slicewise Boolean Perform the morphological operation on a slice-by-slice basis. References BinaryContourImage in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.contour.html"},
{"title": "Thinning", "text": "Thinning Class: NodeMaskThinning This node will produce a skeleton of each foreground object in the mask. The algorithm corresponds with the 2D implementation described in:Rafael C.Gonzales and Richard E.Woods.Digital Image Processing.Addison Wesley, 491-494, (1993). Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool References Thinning filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.thinning.html"},
{"title": "Hausdorff Distance", "text": "Hausdorff Distance Class: NodeMaskHausdorff Computes the Hausdorff distance and average Hausdorff distance between the set of non-zero pixels of two images. The Hausdorff distance measures the degree of mismatch between two sets. The average Hausdorff distance is the Hausdorff distance averaged over all points in the two masks. To get the Hausdorff distance (HD), one first calculates the shortest distance from every point in one set to the other set, and find the maximum of all the shortest distances. This is called the one-sided HD (hd). This is done for both sets. The Hausdorff distance is the maximum of the one-sided HDs of the two sets. In essence, the HD is the is the longest distance one has to travel from a point in one of the two sets to its closest point in the other set. This measure is a good indication of the difference between two sets, such as e.g. a segmentation mismatch. If more than two images are supplied to the node, the Hausdorff distance will be calculated between all combinations of input masks. Example workflows Haussdorff Distance example Inputs Masks At least two binary masks of the same size. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Distances A Data table with four columns: Mask 1, Mask 2, Hausdorff Distance and Average Hausdorff distance Type: DataCollection References Hausdorff Distance in SimpleITK Hausdorff Distance on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.analysis.hausdorff_distance.html"},
{"title": "Maurer Distance", "text": "Maurer Distance Class: NodeMaskMaurerDistance This filter calculates the Euclidean distance transform of a binary image in linear time for arbitrary dimensions. Each voxel value in the resulting image represents the euclidian distance to the closest edge voxel in the mask. By default, voxels inside the TRUE values of a mask are the negative euclidian distance to the cloeset edge voxel. Inputs Image Input mask. Type: Image4DBool, Required, Single Outputs Output Resulting distance map. Type: Image4DFloat Settings Use Squared Distances Boolean Output the squared distance. Inside is Positive Boolean If TRUE, the inside distance of the mask is positive, and the outside distance from the mask is negative. Use Image Spacing Boolean If TRUE, the filter will use the spacing of the input image when calculating the distance map. References Maurer distance image filter in SimpleITK Keywords: Maurer, distance, euclidian, map, mask, binary. ", "tags": "", "url": "nodes.mask.analysis.maurer_distance.html"},
{"title": "Overlap Measures", "text": "Overlap Measures Class: NodeMaskOverlapMeasures Compute Jaccard overlap, Dice coefficient, volume similarity, false negative error and false positive error similarity of two or more binary masks. The measures are defined as follows: \(\textrm{Jaccard} = \displaystyle 2\frac{S \cap T}{S\cup T}\) \(\textrm{Dice} = \displaystyle 2\frac{S \cap T}{S + T} = \frac{2\times Jaccard}{1+Jaccard}\) \(\textrm{Volume Similarity} = 2 \displaystyle \frac{S-T}{S+T}\) \(\textrm{False Negative Error} = \displaystyle \frac{T \setminus \!\!S}{S}\) \(\textrm{False Positive Error} = \displaystyle \frac{S \setminus \!\!T}{T}\) Example Workflows Overlap measures example Inputs Masks At least two binary masks of the same size. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Measures A Data Table with seven columns: Mask 1, Mask 2, Dice, Jaccard, Volume Similarity, False Negative Error, False Positive Error Type: DataCollection Settings Slicewise Boolean Perform the analysis slice by slice. Each slice will result in one row in the output result data table. Slice Direction Selection If slicewise analysis is selected this specifies the orientation of slices. E.g. if slice orientation is XY, slice interpolation will be in the z-direction. Values: XY, XZ, YZ References Jaccard overlap on Wikipedia Dice coefficient on Wikipedia Tustison N., Gee J. Introducing Dice, Jaccard, and Other Label Overlap Measures To ITK. 2009 Dec. Overlap measures in SimpleITK See also Keywords: Jaccard overlap, Dice coefficient ", "tags": "", "url": "nodes.mask.analysis.overlap_measures.html"},
{"title": "STAPLE", "text": "STAPLE Class: NodeMaskStaple The STAPLE filter implements the Simultaneous Truth And Performance Level Estimation algorithm for generating ground truth volumes from a set of binary expert segmentations. The STAPLE algorithm treats segmentation as a pixelwise classification, which leads to an averaging scheme that accounts for systematic biases in the behavior of experts in order to generate a fuzzy ground truth volume and simultaneous accuracy assessment of each expert. The ground truth volumes produced by this filter are floating point volumes of values between zero and one that indicate the probability of each pixel being in the object targeted by the segmentation. Example Workflows STAPLE and voting workflow Inputs Masks At least two binary masks of the same size. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Probability An image with the same spatial properties as the input mask, with values between zero and one that indicate the probability of each pixel is a part of the object targeted by the segmentation. Type: Image4DFloat Fraction A Data Table that summarizes the Sensitivity and Specificity of each mask. Type: DataCollection Settings Confidence Weight Number The Confidence Weight parameter is a modifier for the prior probability that any pixel would be classified as inside the target object. This implementation of the STAPLE algorithm automatically calculates prior positive classification probability as the average fraction of the image volume filled by the target object in each input segmentation. The Confidence Weight parameter allows for scaling the of this default prior probability: if \(g_t\) is the prior probability that a pixel would be classified inside the target object, then \(g_t\) is set to \(g_t \times \textrm{ConfidenceWeight}\) before iterating on the solution. In general ConfidenceWeight should be left to the default of 1.0. Maximum Iterations Integer Set the maximum number of iterations. The STAPLE algorithm is an iterative E-M algorithm and will converge on a solution after some number of iterations that cannot be known a priori. If the maximum number of iterations is reached, the algorithm will stop iterating regardless of whether or not it has converged. This implementation of the STAPLE algorithm will find the solution to within seven digits of precision unless it is stopped early. References S Warfield, K. Zou, W. Wells, &ldquo;Validation of image segmentation and expert quality with an expectation - maximization algorithm&rdquo; in MICCAI 2002: Fifth International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer-Verlag, Heidelberg, Germany, 2002, pp. 298-306 STAPLE in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.analysis.staple.html"},
{"title": "Voting", "text": "Voting Class: NodeMaskVoting This node performs pixelwise voting among an arbitrary number of input binary images, where each image represents a segmentation of the same region in the same frame of reference. The majority value is selected for each pixel in the output mask. If a pixel has the same number of votes for TRUE and FALSE, it is set to TRUE. For two binary masks, the output is equivalent to the Boolean OR operation. Example workflows STAPLE and voting workflow Inputs Masks At least two binary images of the same size. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Vote A binary mask with the same spatial properties as the input binary mask. Type: Image4DBool References T. Rohlfing and C. R. Maurer, Jr., &ldquo;Multi - classifier framework for atlas - based image segmentation&rdquo; Pattern Recognition Letters, 2005. Voting in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.analysis.voting.html"},
{"title": "Shape Statistics", "text": "Shape Statistics Class: NodeMaskShapeStatistics Computes shape properties of a binary mask. The following properties are calculated: Property Description Elongation The ratio of the largest principal moment to the smallest principal moment. Its value is greater or equal to 1. Equivalent Ellipsoid Diameter The diameters of the ellipsoid with the same size and ratio of all the axes as the object. The value depends on the image spacing. Equivalent Spherical Perimeter The equivalent perimeter of a hypersphere with the same volume as the object. The value depends on the image spacing. Equivalent Spherical Radius The radius of a sphere with the same volume as the region. Feret Diameter The diameter of the sphere that inclues the region. Flatness Number of Pixels Number of pixels in the region Number of Pixels on Border Number of pixels adjacent to a pixel with value FALSE. Perimeter Perimeter on Border Perimeter on Border Ratio Physical Size The volume of the region in physical units Principal Axes The principal axes of the region Principal Moments The principal moments of the region Roundness The roundness of the object Example Workflows Shape Statistics workflow Inputs Masks One or more binary masks. Type: Image4DBool, Required, Multiple Outputs Shape A Data Table with the shape properties of each binary mask. Type: DataCollection References Lehmann G., Label object representation and manipulation with ITK, Insight Journal Label shape statistics image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.analysis.shape_statistics.html"},
{"title": "Image", "text": "Mask To Image Class: NodeMaskToImage Converts a binary mask to an image. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Image An image with the same size as the input binary mask. Type: Image4DFloat Settings True Value Number Set the output intensity of all TRUE values in the mask. False Value Number Set the output intensity of all FALSE values in the mask. See also Keywords: ", "tags": "", "url": "nodes.mask.convert_to.image.html"},
{"title": "Label Map (Regions)", "text": "Mask To Label Map Class: NodeMaskToRegionImage Converts a mask to an image where all connected components in the mask are assigned a unique intensity value. The object labels start with 1 and are consecutive. The background value is labelled 0. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Image A image with the same size as the input mask. Type: Image4DFloat Settings Diagonal Connections Boolean If TRUE, diagonal voxels will be considered neighbours when regions are segmented. See also Keywords: ", "tags": "", "url": "nodes.mask.convert_to.label_map_(regions).html"},
{"title": "Structure", "text": "Mask To Structure Class: NodeMaskToStruct Converts a mask to an RT-Struct. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out An RTStruct Type: RTStruct Settings Structure ROI Type Selection Set the ROI Type. Values: EXTERNAL, PTV, CTV, GTV, TREATED_VOLUME, IRRAD_VOLUME, BOLUS, AVOIDANCE, ORGAN, MARKER, REGISTRATION, ISOCENTER, CONTRAST_AGENT, CAVITY, BRACHY_CHANNEL, BRACHY_ACCESSORY, BRACHY_SRC_APP, BRACHY_CHNL_SHLD, SUPPORT, FIXATION, DOSE_REGION, CONTROL, NONE ROI Name Text Set the ROI Name. Decimation Decimate Boolean Reduces the number of points used to represent the structure.Note: If this option is used the resulting structure will not produce exactly the same mask if rendered again. Max Iterations Integer Set the maximum number of iterations for polygon reduction. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.mask.convert_to.structure.html"},
{"title": "Surface Estimation", "text": "Surface Estimation Class: NodeMaskToSurfaceEstimation This node executes a surface-fitting method for estimation of a surface from a binary volume. This process can be used to reduce aliasing artifacts which result in visualization of binary partitioned surfaces. This implementation uses a sparse field level set solver instead of the narrow band implementation described in the reference below, which may introduce some differences in how fast and how accurately (in terms of RMS error) the solution converges. Inputs Mask A binary image. Type: Image4DBool, Required, Single Outputs Output An image with the same size as the input binary image. Type: Image4DFloat Settings Maximum RMS Error Number Used to determine when the solution has converged. A lower value will result in a tighter-fitting solution, but will require more computations. Too low a value could put the solver into an infinite loop. Values should always be less than 1.0. A value of 0.07 is a good starting estimate. Iterations Integer Set the number of iterations. References Whitaker, Ross. &ldquo;Reducing Aliasing Artifacts In Iso - Surfaces of Binary Volumes&rdquo; IEEE Volume Visualization and Graphics Symposium, October 2000, pp.23-32. Antialias binary image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.convert_to.surface_estimation.html"},
{"title": "Custom Mask From Image", "text": "Generate Mask Class: NodeMaskCustom Generates an elliptical or box shaped mask of a specified size at a specified position in the image space defined by the reference image. Example Workflows Maurer Distance example Hausdorff Distance example Inputs Reference Image Type: Image4DFloat, Required, Single Outputs Result Binary mask with the same size as the input image. Type: Image4DBool Settings Shape Selection Select the shape of the mask. Values: Ellipsoid, Box Size X (mm) Number The size of the mask in mm in the X direction. Size Y (mm) Number The size of the mask in mm in the Y direction. Size Z (mm) Number The size of the mask in mm in the Z direction. Center X (mm) Number The position of the mask in the X direction. Center Y (mm) Number The position of the mask in the Y direction. Center Z (mm) Number The position of the mask in the Z direction. See also Keywords: Create mask, ", "tags": "", "url": "nodes.mask.generate.custom_mask_from_image.html"},
{"title": "Point Cloud", "text": "Point Cloud Class: NodeMaskPointCloud Generate regularly spaced foreground objects in a reference space. The shape, size and spacing of the objects can be defined in the settings. Inputs Reference Image Type: Image4DFloat, Required, Single Outputs Result Binary mask with the same spatial properties as the input image. Type: Image4DBool Settings Point Shape Selection The shape of each point. Values: Ellipsoid, Box Size X (mm) Number The size of the point in the X direction Size Y (mm) Number The size of the point in the Y direction Size Z (mm) Number The size of the point in the Z direction Offset X (mm) Number The offset of the first point in the X direction. Offset Y (mm) Number The offset of the first point in the Y direction. Offset Z (mm) Number The offset of the first point in the Z direction. Cloud Spacing X (mm) Number The spacing between points in X direction. Spacing Y (mm) Number The spacing between points in Y direction. Spacing Z (mm) Number The spacing between points in Z direction. See also Keywords: ", "tags": "", "url": "nodes.mask.generate.point_cloud.html"},
{"title": "Crop To Bounding Box", "text": "Crop To Bounds Class: NodeMaskCropToBounds Crop the output mask dimensions to the bounding box of the values that are TRUE in the mask. Inputs In A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.reshape.crop_to_bounding_box.html"},
{"title": "Pad", "text": "Pad Class: NodeMaskPad Increase the size of the binary mask by padding. Inputs In A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask. Type: Image4DBool Settings Pad Value Integer Set value of new voxels. X Lower Integer Set the number of voxels to expand the matrix with in the lower X direction. Y Lower Integer Set the number of voxels to expand the matrix with in the lower Y direction. Z Lower Integer Set the number of voxels to expand the matrix with in the lower Z direction. X Upper Integer Set the number of voxels to expand the matrix with in the upper X direction. Y Upper Integer Set the number of voxels to expand the matrix with in the upper Y direction. Z Upper Integer Set the number of voxels to expand the matrix with in the upper Z direction. References Constant Pad Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.reshape.pad.html"},
{"title": "MetaIO .mhd", "text": "MHD Class: NodeExportMHDBool Convert and export all connected binary images to MHD files. Inputs In Input binary masks. Type: Image4DBool, Required, Multiple Settings Image Prefix Text Set the image prefix. This string will be added to beginning of the filename. Compress Image Boolean Use lossless gzip compression on the raw data. Export Metadata Boolean Export metadata to an XML file. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, mask, mhd ", "tags": "", "url": "nodes.mask.export.metaio_.mhd.html"},
{"title": "MATLAB .mat", "text": "MAT Class: NodeExportMATBool Convert and export all connected binary images to a MATLAB .mat-file. file. Inputs In One or more binary masks. Type: Image4DBool, Required, Multiple Settings Image Prefix Text Sets the image prefix, this string will be added to beginning of the image name. Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Keywords: ", "tags": "", "url": "nodes.mask.export.matlab_.mat.html"},
{"title": "Apply To Image", "text": "Apply Mask Class: NodeMaskApply Apply a mask to an image. TRUE values in the mask will unaffected in the input image, FALSE values will be set to a specified value. Inputs Image Input image. Type: Image4DFloat, Required, Single Mask Input mask. Type: Image4DBool, Required, Single Outputs Result Resulting image. Type: Image4DFloat Settings Crop Image to Mask Bounds Boolean Crop the resulting image to the bounding box of the mask. Masked Voxel Value Number Voxels in the resulting image where the mask is FALSE will be set to this value. Keywords: apply, mask, image ", "tags": "", "url": "nodes.mask.apply_to_image.html"},
{"title": "Point Data", "text": "Point Data Class: NodeStructToData Convert connected structures into point data. RTStructs are defined as points forming a polygon on a plane. This node will export all points for all structures in the connected structure set. WARNING! The resulting data table can be very large! Consider extracting only relevant structs before applying this node. Inputs Structure Input structure. Type: RTStructCollection, Required, Single Outputs Points Resulting data table. Type: DataCollection Keywords: structure, rtstruct, data, table, point, csv ", "tags": "", "url": "nodes.structure.convert_to.point_data.html"},
{"title": "Point Data", "text": "Structure Class: NodeDataToStruct Convert connected structure point data into structures. Inputs Points Input data table. Type: DataCollection, Required, Single Outputs Structure Resulting RTStruct. Type: RTStructCollection Keywords: convert, points, structure, rtstruct ", "tags": "", "url": "nodes.structure.generate_from.point_data.html"},
{"title": "RTSTRUCT", "text": "RTSTRUCT Class: NodeExportRTSTRUCT Converts and exports all connected structures into one Dicom RS (RT Structure Set) file. Example workflows Export structure example Inputs Reference Image The reference image to the RT structure set. The FrameOfReference tag, as well as PatientID, Name, BirthDate, Sex and Weight are taken from this reference image. Note that the referenced SOP Instance UIDs that are written to the exported RT Struct does not come from this reference, but are randomly generated. Type: Image4DFloat, Required, Single Structures The input structures to be exported. Type: RTStruct, Required, Multiple Settings Label Text The structure set DICOM label, tag (3006,0002). Path Text Sets the output directory to where the file is exported. Note: This parameter will be overridden if you use this node for batch calculations. References RT Structure Set on dicom.nema.org See also Keywords: rs, rtstruct, structure set, ROI ", "tags": "", "url": "nodes.structure.export.rtstruct.html"},
{"title": "STL", "text": "STL Class: NodeExportStructSTL Converts structure(s) to mesh(es) and exports it as one or several STL-files. Example workflows Export structure example Inputs Structures The input structure(s) to be exported. Type: RTStruct, Required, Multiple Settings File prefix Text String which is added to the beginning of the filename. The last part of the filename is taken from the specific structure name. Path Text Sets the output directory to where the file(s) is exported. Note: This parameter will be overridden if you use this node for batch calculations. References STLWriter on vtk See also Keywords: mesh, structure set, ROI ", "tags": "", "url": "nodes.structure.export.stl.html"},
{"title": "Apply Transform", "text": "Transform Class: NodeStructApplyTransform Transforms structures with the connected transformix transform. Currently only linear transforms are supported (translation, rigid, affine). Inputs Transform The transformix parameters to be applied. Type: TransformixParameter, Required, Single Structure The structure(s) to apply the transform to. Type: RTStructCollection, Required, Single Outputs Structure The resulting transformed structure(s). Type: RTStructCollection Settings Fixed to Moving Boolean By default this node will transform the structure points from the moving image space to the fixed, set this to do the transformation from the fixed image space to the moving. References 1. S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, %22elastix: a toolbox for intensity based medical image registration%22, IEEE Transactions on Medical Imaging, vol. 29, no. 1, pp. 196 - 205, January 2010. 2. D.P. Shamonin, E.E. Bron, B.P.F. Lelieveldt, M. Smits, S. Klein and M. Staring, %22Fast Parallel Image Registration on CPU and GPU for Diagnostic Classification of Alzheimer’s Disease%22, Frontiers in Neuroinformatics, vol. 7, no. 50, pp. 1-15, January 2014. 3. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.structure.apply_transform.html"},
{"title": "Struct Processor", "text": "Struct Processor Class: NodeStructProcessor Selects and renders a structure to a binary mask from an RT-Struct Collection on a reference image. Example workflows Structure handling example Inputs Image The input image on which to render the structures. Type: Image4DFloat, Required, Single Structures The structure set to render. Type: RTStructCollection, Required, Single Outputs Mask The rendered mask. Type: Image4DBool Smooth Mask The rendered Smooth mask. Type: Image4DFloat Statistics Statistics regarding the mask and smooth mask, such as volumes and volume error. Volume error is the relative difference between the volume calculated directly from the polygon structure compared to the rendered binary and smooth mask. Type: DataCollection Settings Struct Selection Structure Name(s) Text Name of the structure to render, if you define several structures as a comma separated list it will render the first structure that matches. Condition Selection Condition to use when matching strings to find the structure. Values: Equals, Contains, NotEqual, DoesNotContain, Regex Case Sensitive Boolean When enabled a case sensitive string match will be used. Initial Supersampling Method Selection Sets the initial supersampling method. Values: None, Grid, Random Grid Divisions X Integer Sets the number of sub voxel divisions in the X-direction for grid supersampling. Grid Divisions Y Integer Sets the number of sub voxel divisions in the Y-direction for grid supersampling. Grid Divisions Z Integer Sets the number of sub voxel divisions in the Z-direction for grid supersampling. Number of Points Integer Sets the number of sub voxel points to generate for random supersampling. Adaptive Supersampling Adaptive Method Selection Sets the adaptive supersampling method. Can only be used if initial supersampling is used, it will resample any voxel that has a value &gt;0 and &lt;1 after the initial supersampling. Values: None, Grid, Random Adaptive Grid Divisions X Integer Sets the number of sub voxel divisions in the X-direction for grid supersampling. Adaptive Grid Divisions Y Integer Sets the number of sub voxel divisions in the Y-direction for grid supersampling. Adaptive Grid Divisions Z Integer Sets the number of sub voxel divisions in the Z-direction for grid supersampling. Adaptive Number of Points Integer Sets the number of sub voxel points to generate for random supersampling. Mask Generation Threshold(%) Number Sets how much of a single voxel that needs to be inside the structure for the voxel to be set to one in the mask. Threshold Type Selection The type of criteria used to set the resulting mask voxel to 1. Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals Structure Geometry End Cap Thickness (mm) Number Sets the end cap thickness of the structure. See also Keywords: ", "tags": "", "url": "nodes.structure.struct_processor.html"},
{"title": "Struct Filter", "text": "Struct Filter Class: NodeStructFilter This filter is used to filter struct collections by removing or keeping some structures depending on their name. Example workflows Structure handling example Inputs In The input RTStruct collection. Type: RTStructCollection, Required, Single Outputs Out The input RTStruct collection with some of the RTStructs removed. Type: RTStructCollection Settings Structure Name(s) Text A comma separated list of names to match. Condition Selection Condition to use when matching strings to find the structure(s). Values: Equals, Contains, NotEqual, DoesNotContain, Regex Action Selection What action should be taken when a structure matches the filter condition. Values: Discard, Keep Case Sensitive Boolean If TRUE, a case sensitive string match will be used. Keywords: RTStruct, collection, filter ", "tags": "", "url": "nodes.structure.struct_filter.html"},
{"title": "Struct Cleaner", "text": "Struct Cleaner Class: NodeStructCleaner Removes contours from structures depending on their area. Example workflows Structure handling example Inputs In The input structure collection to be cleaned. Type: RTStructCollection, Required, Single Outputs Out The cleaned output collection. Type: RTStructCollection Settings Area (mm²) Number Area condition for the contour filter. Condition Selection The type of criteria used to match the contours, if the filter finds a matching contour that contour will be removed. Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals See also Keywords: ", "tags": "", "url": "nodes.structure.struct_cleaner.html"},
{"title": "Struct Renamer", "text": "Rename Class: NodeStructRenamer Rename structures according to a set of rules defined by the user. Supports export and import of predefined sets of renaming rules. You can also use dictionaries of acceptable names to harmonize structure naming. Predefined naming rules can be supplied in a .txt or .dsv file the following format (the delimiter can be changed during the import): PATTERN;NEW NAME;CONDITION;CASE SENSITIVE where PATTERN is the character combination used to identify the structure from its original name and NEW NAME is the name that will be assigned to the structures that match the rule. CONDITION defines the condition that must be fulfilled when the pattern is compared to the old name which can be Contains; DoesNotContain; Equals; NotEqual; Regex. Most of these are self explanatory, while the term regex might not be familiar to all. It's short for regular expression, and is a sequence of characters that define a search pattern. To learn more on how to write regular expressions, this article on Wikipedia can be helpful. CASE SENSITIVE can be True;False and of course determines if the comparison between the pattern and the original name should be case sensitive. A naming convention or dictionary is simply a .txt file in the format StructureName;Description which is located in the MICE Toolkit program catalog under ...\External\Structure Naming Conventions. To add user defined naming conventions, copy the .txt file containing your naming convention to this path. The swedish naming convention published by the Swedish Radiation Safety Authority is supplied by default. Example workflows Structure handling example Inputs In The renamed struct collection. Type: RTStructCollection, Required, Single Outputs Out Resulting RTStruct collection. Type: RTStructCollection Settings Renaming Rules Text A list of rules to apply when renaming structures, the list is evaluated from top to bottom and the first matching rule will be applied. Default Action Selection This is the default action that will be applied if no rules on the list matches the structure. Values: Keep, Rename, Discard, Stop Default Name Text If the default action is &lsquo;Rename&rsquo; this is the name that non matching structures will be renamed to. Use $n to insert old structure name and $c to insert duplicate name counter. Keywords: rename, struct, rtstruct, dicom ", "tags": "", "url": "nodes.structure.struct_renamer.html"},
{"title": "Struct Renderer", "text": "Struct Renderer Class: NodeStructRenderer Renders a RT-Struct on a reference image. Example workflows Structure handling example Inputs Image Input reference image. Type: Image4DFloat, Required, Single Structs Input structs. Type: RTStruct, Required, Multiple Outputs Mask Resulting mask. Type: Image4DBool Smooth Mask Resulting fuzzy mask. Type: Image4DFloat Statistics Statistical properties of the resulting masks. Type: DataCollection Settings Initial Supersampling Method Selection Sets the initial supersampling method. Values: None, Grid, Random Grid Divisions X Integer Set the number of sub voxel divisions in the X-direction for grid supersampling. Grid Divisions Y Integer Set the number of sub voxel divisions in the Y-direction for grid supersampling. Grid Divisions Z Integer Set the number of sub voxel divisions in the Z-direction for grid supersampling. Number of Points Integer Set the number of sub voxel points to generate for random supersampling. Adaptive Supersampling Adaptive Method Selection Set the adaptive supersampling method. Can only be used if initial supersampling is used, it will resample any voxel that has a value &gt;0 and &lt;1 after the initial supersampling. Values: None, Grid, Random Adaptive Grid Divisions X Integer Set the number of sub voxel divisions in the X-direction for grid supersampling. Adaptive Grid Divisions Y Integer Set the number of sub voxel divisions in the Y-direction for grid supersampling. Adaptive Grid Divisions Z Integer Set the number of sub voxel divisions in the Z-direction for grid supersampling. Adaptive Number of Points Integer Set the number of sub voxel points to generate for random supersampling. Mask Generation Threshold(%) Number Set how much of a single voxel that needs to be inside the structure for the voxel to be set to one in the mask. Threshold Type Selection The type of criteria used to set the resulting mask voxel to 1. Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals Structure Geometry End Cap Thickness (mm) Number Sets the end cap thickness of the structure. Keywords: struct, mask, fuzzy, smooth, image ", "tags": "", "url": "nodes.structure.struct_renderer.html"},
{"title": "Struct Selector", "text": "Struct Selector Class: NodeStructSelector Selects an RT-Struct from an RT-Struct Collection. Example workflows Structure handling example Inputs Struct Collections The input struct collection from which to select a structure. Type: RTStructCollection, Required, Multiple Outputs Struct The selected structure. Type: RTStruct Settings Struct Selector Structure Name(s) Text Name of the structure to select, if you define several structures as a comma separated list it will select the first structure that matches. Case Sensitive Boolean When enabled a case sensitive string match will be used. Struct Selection Condition Selection Condition to use when matching strings to find the structure. Values: Equals, Contains, NotEqual, DoesNotContain, Regex See also Keywords: ", "tags": "", "url": "nodes.structure.struct_selector.html"},
{"title": "CSV", "text": "CSV Class: NodeExportCSV Export all connected data tables to .csv files. Inputs In Input data collection. Type: DataCollection, Required, Multiple Settings File Prefix Text Set the file prefix. This string will be added to beginning of the filename. File Suffix Text Set the file suffix. This string will be added to the end of the filename. Separator Text Define the separator character. Default value is a semicolon. (;). Write Column Headers Boolean Writes the column headers as the first line in the file, if Append to End of File setting is used this setting will be ignored. Append to End of File Boolean If set the node will append the data to the end of an existing .csv-file. Path Text Sets the output directory of the node. Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, data, csv ", "tags": "", "url": "nodes.data.export.csv.html"},
{"title": "Excel", "text": "Excel Class: NodeExportExcel Convert and export all connected data collections to excel files. Inputs In Input data table. Type: DataCollection, Required, Multiple Settings File Prefix Text Sets the file prefix, this string will be added to beginning of the filename. File Suffix Text Sets the file suffix, this string will be added to the end of the filename. Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords:Excel, export, data, write, disk ", "tags": "", "url": "nodes.data.export.excel.html"},
{"title": "Data Elements", "text": "Generate Data Class: NodeDataGenerateDataElements Create a new data collection with columns and values taken from the connected data elements. Inputs Column 1 Input data element. Type: DataElement, Required, Single Outputs Out Resulting data table. Type: DataCollection Settings Input Number of Columns Integer Set the number of columns in the output data table. Node Tag Text This is the name applied to the resulting data collection. See also Keywords: create, data, table, collection ", "tags": "", "url": "nodes.data.generate_from.data_elements.html"},
{"title": "Curves", "text": "Curve Data Class: NodeGenerateDataCurves Creates a new data collection with columns and values taken from the connected curves. Inputs Curves Input curve(s). Type: CurveCollection, Required, Multiple Outputs Out OUtput data table. Type: DataCollection Settings Data Name Text The name of the resulting data. Curve Description Text If not empty a column named description will be added with this information. Keywords: curve, data, table ", "tags": "", "url": "nodes.data.generate_from.curves.html"},
{"title": "Extract Data", "text": "Extract Class: NodeExtractData Extract a subset of a data collection. Inputs In Inptut RTStruct. Type: DataCollection, Required, Single Outputs Out Resulting data table. Type: DataCollection Settings Data Name Text Set the name of the resulting data collection. Column Selection Start Column Integer Set the first column to extract. Must be larger or equal to 1. Stop Column Integer Set the last column to extract. This value is ignored if &lsquo;Extract Remaining Columns&rsquo; is selected. Must be larger or equal to 1. Extract Remaining Columns Boolean If TRUE, the remaining columns after the start column will be extracted and the &lsquo;Stop Column&rsquo; value will be ignored. Row Selection Start Row Integer Set the first row to extract. Must be larger or equal to 1. Stop Row Integer Set the last row to extract. This value is ignored if &lsquo;Extract Remaining Rows&rsquo; is selected. Must be larger or equal to 1. Extract Remaining Rows Boolean If TRUE, the remaining rows after the start row will be extracted and the &lsquo;Stop Row&rsquo; value will be ignored. Keywords: data, table, subset, extract ", "tags": "", "url": "nodes.data.extract_data.html"},
{"title": "Merge Data", "text": "Merge Class: NodeMergeData Merges a number of data tables into one data table. You can merge the data horizontally (i.e. add columns) or vertically (add rows). If you wish to merge vertically, the input data tables must have the same columns in all input data. Inputs In Inpt data tables. Type: DataCollection, Required, Multiple Outputs Out Resulting data table. Type: DataCollection Settings Name Text This is the name the resulting data collection. Add Collection Column Boolean Adds a column with the name of the collection the row belongs to. Merge Direction Selection This is the direction the merge will be performed, a vertical merge will merge rows with the same column layout and a horizontal merge will add columns to the collection.Note: A vertical merge requires the connected data collections to have the same number of columns and a horizontal merge requires the same number of rows in each collection. Values: Vertical, Horizontal See also Keywords: ", "tags": "", "url": "nodes.data.merge_data.html"},
{"title": "Merge Curves", "text": "Merge Class: NodeMergeCurves Merges a number of curves into one curve collection. Inputs In Curves to merge. Type: CurveCollection, Required, Multiple Outputs Out Resulting curve collection. Type: CurveCollection Settings Title Text This is the title the resulting curve collection. X-Axis Title Text This is the title for the X axis in the resulting curve collection. Y-Axis Title Text This is the title for the Y axis in the resulting curve collection. See also Keywords: ", "tags": "", "url": "nodes.data.merge_curves.html"},
{"title": "AND", "text": "AND Class: NodeBoolAnd Output is TRUE if all inputs are TRUE. Inputs In Input booleans. Type: Boolean, Required, Multiple Outputs Value Resulting boolean. Type: Boolean Keywords: Bool, boolean, and ", "tags": "", "url": "nodes.values.bit.boolean_algebra.and.html"},
{"title": "NOT", "text": "NOT Class: NodeBoolNot Output is TRUE if input is FALSE. Inputs In Input mask. Type: Boolean, Required, Single Outputs Value Output mask. The inverted input mask. Type: Boolean Keywords: Not, invert ", "tags": "", "url": "nodes.values.bit.boolean_algebra.not.html"},
{"title": "OR", "text": "OR Class: NodeBoolOr Output is TRUE if any input is TRUE. Inputs In Input bit(s). Type: Boolean, Required, Multiple Outputs Value Output bit. Type: Boolean Keywords: Boolean operations ", "tags": "", "url": "nodes.values.bit.boolean_algebra.or.html"},
{"title": "XOR", "text": "XOR Class: NodeBoolXor Output is TRUE if an odd number of inputs are TRUE. Inputs In Input boolean values. Type: Boolean, Required, Multiple Outputs Value Resulting boolean value. Type: Boolean Keywords: xor, bit, boolean ", "tags": "", "url": "nodes.values.bit.boolean_algebra.xor.html"},
{"title": "Create Constant", "text": "Bit Class: NodeGenerateBool Create a bit (true/false) value. Outputs Value Resulting bit. Type: Boolean Settings Bit Value Boolean Bit value, (TRUE/FALSE). Variable Name Text Set the name of this value. If you are using this as a batch variable make sure it is uniqe for the process Show Name Boolean Should the name be shown. Enable Batching Boolean If true the variable will be available when batching. Keywords: Bit, value, boolean, logical ", "tags": "", "url": "nodes.values.bit.generate_from.create_constant.html"},
{"title": "Number", "text": "Number To Bit Class: NodeDoubleToBool Create bit (TRUE/FALSE) value from a number, using conditionals. Inputs Double Input number. Type: Double, Required, Single Outputs Value Output bit. Type: Boolean Settings Condition Value Number The conditional value. Condition Selection The condition for returning TRUE/FALSE Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals Show Condition Boolean Display condition in node. Keywords: double, number, float, integer, int, convert, bit, boolean, bool, condition ", "tags": "", "url": "nodes.values.bit.generate_from.number.html"},
{"title": "Text", "text": "Text To Bit Class: NodeStringToBool Create bit (TRUE/FALSE) value from a text string, using conditionals. Inputs String Input text string. Type: String, Required, Single Outputs Value Resulting bit. Type: Boolean Settings Bool Condition Value Text Conditional value. Bit Condition Selection The condition for returning TRUE/FALSE Values: Equals, Contains, NotEqual, DoesNotContain Case Sensitive Boolean Should the conditional be case sensitive. Show Condition Boolean Display condition in node. Keywords: string, text, convert, bit, boolean, bool, condition ", "tags": "", "url": "nodes.values.bit.generate_from.text.html"},
{"title": "Data Element", "text": "Number To Data Element Class: NodeBoolToDataElement Convert bit (true/false) value to a data element. Inputs Bool Input bit value. Type: Boolean, Required, Single Outputs Value Output data element. Type: DataElement Settings Column Name Text The name of the column where the bit is placed. Keywords: Bit, bool, data, element ", "tags": "", "url": "nodes.values.bit.convert_to.data_element.html"},
{"title": "Display Bit", "text": "Equals Class: NodeBoolDisplay Display the bit (true/false) value. Inputs In Bit to display. Type: Boolean, Required, Single Outputs Value Output bit, always the same as input bit. Type: Boolean ", "tags": "", "url": "nodes.values.bit.display_bit.html"},
{"title": "Add", "text": "Add Class: NodeDoubleAdd Add two or more numbers. Inputs In Input numbers to add. Type: Double, Required, Multiple Outputs Value Resulting number. Type: Double Keywords: add number, float, double, int ", "tags": "", "url": "nodes.values.number.math._operations.add.html"},
{"title": "Subtract", "text": "Subtract Class: NodeDoubleSubtract Subtract one or more numbers from a number. Inputs In Input value. Type: Double, Required, Single Sub Subtraction value. Type: Double, Required, Multiple Outputs Value Resulting value. Type: Double Keywords: subtract, value ", "tags": "", "url": "nodes.values.number.math._operations.subtract.html"},
{"title": "Multiply", "text": "Multiply Class: NodeDoubleMultiply Multiply two or more numbers. Inputs In Input number. Type: Double, Required, Multiple Outputs Value Resulting value. Type: Double See also Keywords: ", "tags": "", "url": "nodes.values.number.math._operations.multiply.html"},
{"title": "Divide", "text": "Divide Class: NodeDoubleDivide Divide one number with one or more numbers. Inputs In Input numerator. Type: Double, Required, Single Div Input denominator(s). Type: Double, Required, Multiple Outputs Value Resulting value. Type: Double See also Keywords: divide, division, number, double ", "tags": "", "url": "nodes.values.number.math._operations.divide.html"},
{"title": "Raise To Power", "text": "Raise To Power Class: NodeDoubleRaiseToPower Raise one number to the power of another number. Inputs In Input base. Type: Double, Required, Single Pow Input exponent. Type: Double, Required, Single Outputs Value Resulting value. Type: Double Keywords: power, base, exponent ", "tags": "", "url": "nodes.values.number.math._operations.raise_to_power.html"},
{"title": "Sqrt", "text": "Sqrt Class: NodeDoubleSqrt Get the square root of a number. Inputs In Input number. Type: Double, Required, Single Outputs Value Resulting value. Type: Double See also Keywords: ", "tags": "", "url": "nodes.values.number.math._operations.sqrt.html"},
{"title": "Sin", "text": "Sin Class: NodeDoubleSin Get the sine for a number. Inputs In Input number. Type: Double, Required, Single Outputs Value Resulting number. Type: Double Keywords: Math ", "tags": "", "url": "nodes.values.number.math._operations.sin.html"},
{"title": "Cos", "text": "Cos Class: NodeDoubleCos Get the cosine of a number. Inputs In Input value. Type: Double, Required, Single Outputs Value Output value. Type: Double Keywords: cos, cosine, value ", "tags": "", "url": "nodes.values.number.math._operations.cos.html"},
{"title": "Tan", "text": "Tan Class: NodeDoubleTan Get the tangent for a number. Inputs In Input value. Type: Double, Required, Single Outputs Value The tan of the input value. Type: Double Keywords: Tan ", "tags": "", "url": "nodes.values.number.math._operations.tan.html"},
{"title": "Log", "text": "Log Class: NodeDoubleLog Get the base e logarithm of a number. Inputs In input value. Type: Double, Required, Single Outputs Value Resulting value. Type: Double Keywords: natural, log, logarithm ", "tags": "", "url": "nodes.values.number.math._operations.log.html"},
{"title": "Log 10", "text": "Log 10 Class: NodeDoubleLogTen Get the base 10 logarithm of a number. Inputs In Input value. Type: Double, Required, Single Outputs Value Output value. Type: Double Keywords: log, logarithm, base, 10 ", "tags": "", "url": "nodes.values.number.math._operations.log_10.html"},
{"title": "Create Expression", "text": "Expression Class: NodeDoubleExpression Create a custom expression using the input values. The user can specify an arbitrary number of input values and bits, which are assigned a variable name, starting with \(a\). At least one value is mandatory. The variable names can then be used to create an expression to be calculated. As an example, to create a node that takes an input value \(a\), ads it to a second input value \(b\), and multiplies the result with \(e\) raised to the power of an input number \(c\), you would write: (a+b)*e^c Inputs a The default value input. Type: Double, Required, Single Outputs Result The resulting value. Type: Double Settings Display Show Expression Boolean If TRUE, the expression will be displayed beneath the node name in the process window. Node Name Text The display name of the node in the process window. Expression Expression Text The expression which should be calculated. Inputs Numbers Integer The number of input values. Bits Integer The number of input bits. Result Set Infinity To Number What value should Infity be set to. Set Undefined Numbers To Number What value should Undifined numbers be set to. Keywords: expression, math ", "tags": "", "url": "nodes.values.number.math._operations.create_expression.html"},
{"title": "Pi", "text": "Pi Class: NodeGenerateDoublePi Return the value of Pi. Outputs Value The value of Pi. Type: Double Keywords:value, pi ", "tags": "", "url": "nodes.values.number.constants.pi.html"},
{"title": "Create Constant", "text": "Number Class: NodeGenerateDouble Generate a constant number. Outputs Value Resulting number. Type: Double Settings Number Value Number Value of the output. Variable Name Text Set the name of this value. If you are using this as a batch variable make sure it is uniqe for the process. Show Name Boolean Should the name be shown. Enable Batching Boolean If true the variable will be available when batching. Keywords: Constant, create, double, float, number ", "tags": "", "url": "nodes.values.number.constants.create_constant.html"},
{"title": "Image", "text": "Numbers Class: NodeImageToDouble Extract mask properties such as size and position to values. Inputs Image Input image. Type: Image4DFloat, Required, Single Settings Position Position X Boolean The x position of the image. Position Y Boolean The y position of the image. Position Z Boolean The z position of the image. Center Position X Boolean The x position of the center of the image. Center Position Y Boolean The y position of the center of the image. Center Position Z Boolean The z position of the center of the image. Size Matrix Size X Boolean The number of voxels in the x direction. Matrix Size Y Boolean The number of voxels in the y direction. Matrix Size Z Boolean The number of voxels in the z direction. Matrix Size T Boolean The number of voxels in the t direction. Matrix Size X (mm) Boolean The physical size of the image in the x direction. Matrix Size Y (mm) Boolean The physical size of the image in the y direction. Matrix Size Z (mm) Boolean The physical size of the image in the z direction. Matrix Size T (s) Boolean The physical size of the image in the t direction. Voxel Size X Boolean The voxel size in the x direction. Voxel Size Y Boolean The voxel size in the y direction. Voxel Size Z Boolean The voxel size in the z direction. Statistics Mean Boolean The mean value of the image. Min Boolean The minimum value of the image. Max Boolean The maximum value of the image. Sum Boolean The sum of all voxel values. Standard Deviation Boolean The standard deviation of the image. Keywords: value, image, property ", "tags": "", "url": "nodes.values.number.generate_from.image.html"},
{"title": "Mask", "text": "Numbers Class: NodeMaskToDouble Extract mask properties such as size and position to values. Inputs Image Input mask. Type: Image4DBool, Required, Single Settings Position Position X Boolean The x position of the mask. Position Y Boolean The y position of the mask. Position Z Boolean The z position of the mask. Center Position X Boolean The x position of the center of the mask. Center Position Y Boolean The y position of the center of the mask. Center Position Z Boolean The z position of the center of the mask. Mass Center X Boolean The x position of the mass center of the mask. Mass Center Y Boolean The y position of the mass center of the mask. Mass Center Z Boolean The z position of the mass center of the mask. Size Matrix Size X Boolean The number of voxels in the x direction. Matrix Size Y Boolean The number of voxels in the y direction. Matrix Size Z Boolean The number of voxels in the z direction. Matrix Size T Boolean The number of voxels in the t direction. Matrix Size X (mm) Boolean The physical size of the mask in the x direction. Matrix Size Y (mm) Boolean The physical size of the mask in the y direction. Matrix Size Z (mm) Boolean The physical size of the mask in the z direction. Matrix Size T (s) Boolean The physical size of the mask in the t direction. Voxel Size X Boolean The voxel size in the x direction. Voxel Size Y Boolean The voxel size in the y direction. Voxel Size Z Boolean The voxel size in the z direction. Statistics Voxel Count Total Boolean The total number of voxels in the mask. Voxel Count True Boolean The number of TRUE voxels in the mask. Voxel Count False Boolean The number of FALSE voxels in the mask. Keywords: value, mask, property ", "tags": "", "url": "nodes.values.number.generate_from.mask.html"},
{"title": "Data", "text": "Data to Number Class: NodeDataToDouble Extract a number from a data table. Inputs Data Input Data table. Type: DataCollection, Required, Single Outputs Value Output number. Type: Double Settings Column Name Text The name of the column from where the number is extracted. Use Specific Column Number Boolean If checked the column name will be ignored and the value will be selected from a specific column number. Column Number Integer If &lsquo;Use Specific Column Number&rsquo; setting is checked the value will be selected from this column number. Row Number Integer The number will be selected from this row. Show Name Boolean If TRUE, the name of the column is displayed on the node. See also Keywords: Data, table, number ", "tags": "", "url": "nodes.values.number.generate_from.data.html"},
{"title": "Curve", "text": "Numbers Class: NodeCurveToDouble Calculate statistical properties of a curve/plot. Inputs Curve Input curve. Type: CurveCollection, Required, Single Settings Mean Boolean Calculate the mean value of the curve. Min Boolean Calculate the minimum value of the curve. Max Boolean Calculate the maximum value of the curve. Sum Boolean Calculate the sum of the curve. Standard Deviation Boolean Calculate the standard deviation of the curve. Full Width Half Maximum Boolean Try to find the full width half maximum value of the curve. Keywords: statistics, curve, numbers, mean, min, minimum, max, maximum, sum, std, standard, deviation, fwhm, full, width, half, maximum ", "tags": "", "url": "nodes.values.number.generate_from.curve.html"},
{"title": "Dicom Tag", "text": "Dicom Tag Class: NodeDicomTagToDouble Parses a DICOM tag into a number. Inputs Image Image containing the tag. Type: Image4DFloat, Required, Single Outputs Value The resulting number. Type: Double Settings Tag Text The tag to extract, private tags are defined like (gggg,eeee). Field Index Integer The index of the element to extract from the tag, if it is a single value set this to 1. Show Tag Boolean Should the tag be displayed in the node representation. See also Keywords: ", "tags": "", "url": "nodes.values.number.generate_from.dicom_tag.html"},
{"title": "Text", "text": "Number To Text Class: NodeDoubleToString Convert a number to text. Inputs Double Input number. Type: Double, Required, Single Outputs Value Resulting string. Type: String Keywords: Number, double, float, string, text, convert ", "tags": "", "url": "nodes.values.number.convert_to.text.html"},
{"title": "Data Element", "text": "Number To Data Element Class: NodeDoubleToDataElement Convert a number to a data element. Inputs Double Input number. Type: Double, Required, Single Outputs Value Output data element. Type: DataElement Settings Column Name Text The name of the column the data element should belong to. See also Keywords: double, number, data, table, element ", "tags": "", "url": "nodes.values.number.convert_to.data_element.html"},
{"title": "Display Number", "text": "Equals Class: NodeDoubleDisplay Display number value. Inputs In Input value. Type: Double, Required, Single Outputs Value Output value, identical to the input. Type: Double Keywords:display, number ", "tags": "", "url": "nodes.values.number.display_number.html"},
{"title": "Get Voxel Position", "text": "Voxel Position Class: NodeGetVoxelPosition Get the X, Y and Z center position of the specified voxel index in the attached image coordinate system. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs X The X position of the voxel. Type: Double Y The Y position of the voxel. Type: Double Z The Z position of the voxel. Type: Double Settings Voxel Index X Number Zero indexed voxel index in the X direction, fractions of voxels are supported Voxel Index Y Number Zero indexed voxel index in the Y direction, fractions of voxels are supported Voxel Index Z Number Zero indexed voxel index in the Z direction, fractions of voxels are supported Keywords: position, voxel, index ", "tags": "", "url": "nodes.values.number.get_voxel_position.html"},
{"title": "Get Voxel Index", "text": "Voxel Index Class: NodeGetVoxelIndex Gets the voxel index of the voxel at the specified position in the connected image coordinate system. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs X X component of voxel position. Type: Double Y Y component of voxel position. Type: Double Z Z component of voxel position. Type: Double Settings Position X Number X coordinate of the voxel. Position Y Number Y coordinate of the voxel. Position Z Number Z coordinate of the voxel. Keywords: Voxel, position, index ", "tags": "", "url": "nodes.values.number.get_voxel_index.html"},
{"title": "Create Constant", "text": "String Class: NodeGenerateString Create text string. Outputs Value Output text string. Type: String Settings String Value Text Text string value. Variable Name Text Set the name of this value. If you are using this as a batch variable make sure it is uniqe for the process. Show Name Boolean Should the name be shown. Enable Batching Boolean If true the variable will be available when batching. Keywords: text, string ", "tags": "", "url": "nodes.values.text.constants.create_constant.html"},
{"title": "Concatenate", "text": "Concatenate Class: NodeStringConcatenate Combine strings. Inputs S1 First string. Type: String, Required, Single S2 Second string. Type: String, Required, Single Outputs Value Resulting string. Type: String Settings Separator Text If not empty this text will be inserted between the strings. Keywords: concatenate, combine, string ", "tags": "", "url": "nodes.values.text.format.concatenate.html"},
{"title": "Extract Substring", "text": "Substring Class: NodeExtractSubstring Extracts a substring from a string. Inputs In Input string. Type: String, Required, Single Outputs Value Extracted string. Type: String Settings Start Index Integer Sets the start index of the substring. Length Integer Sets the length of the substring. Keywords: substring, extract, split, string ", "tags": "", "url": "nodes.values.text.format.extract_substring.html"},
{"title": "Dicom Tag", "text": "Dicom Tag Class: NodeDicomTagToString Missing description. Inputs Image Missing description. Type: Image4DFloat, Required, Single Outputs Value Missing description. Type: String Settings Tag Text Missing description. Field Index Integer Missing description. Show Tag Boolean Missing description. See also Keywords: ", "tags": "", "url": "nodes.values.text.generate_from.dicom_tag.html"},
{"title": "Data", "text": "Data to Text Class: NodeDataToString Extract text from a data table. Inputs Data Input data table. Type: DataCollection, Required, Single Outputs Value Extracted string. Type: String Settings Column Name Text Name of the column where the text is located. Use Specific Column Number Boolean If TRUE, the column name will be ignored and the value will be selected from a specific column number. Column Number Integer If &lsquo;Use Specific Column Number&rsquo; setting is checked the value will be selected from this column number. Row Number Integer The row number where the extracted text is placed. Show Name Boolean If TRUE, the column name will be shown in the node. Keywords: extract, get, string, text, data, table, ", "tags": "", "url": "nodes.values.text.generate_from.data.html"},
{"title": "Data Element", "text": "Number To Data Element Class: NodeStringToDataElement Convert a string to a data element. Inputs String Input string. Type: String, Required, Single Outputs Value Output data element. Type: DataElement Settings Column Name Text The name of the column where the string is placed. Keywords: String, data, element ", "tags": "", "url": "nodes.values.text.convert_to.data_element.html"},
{"title": "Display Text", "text": "Equals Class: NodeStringDisplay Display string in the worflow. Inputs In Input string. Type: String, Required, Single Outputs Value OUtput string, identical to the input. Type: String Keywords:string, show, display ", "tags": "", "url": "nodes.values.text.display_text.html"},
{"title": "Add Database Tag", "text": "TAG Class: NodeExportTagDB Add a tag to an object in a databse. Inputs Value Input value. Type: Double, Required, Single Reference Input reference object. Type: Image4DFloat, Optional, Single Settings Tag Tag Type Selection Set the type of tag to export. Values: Bit, Number, Text Tag Name Text Set the name of the tag. Software Text Set the software version of the tag. Update Boolean If TRUE, the tag will be updated if it is already present for this series. Database Series ID Integer The SeriesID of the object in the database. Database Text Database name. Reference Image Image Type Selection The type of image to get database information from. Values: Mask, Image, Complex, Vector Keywords:Tag, database, value ", "tags": "", "url": "nodes.values.add_database_tag.html"},
{"title": "Add", "text": "Add Class: NodeVectorAdd Add two vector fields. Inputs Add Input vector fields. Type: Image4DVector3, Required, Multiple Outputs Out Resulting vector field. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: add, vector, fields ", "tags": "", "url": "nodes.vector.math._operations.add.html"},
{"title": "Subtract", "text": "Subtract Class: NodeVectorSubtract Subtract two vector images. Inputs Image Input vector image. Type: Image4DVector3, Required, Single Subtract Subtraction input vector image. Type: Image4DVector3, Optional, Multiple Outputs Out Resulting Vector image. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: subtract, subtraction, minus, vector, field ", "tags": "", "url": "nodes.vector.math._operations.subtract.html"},
{"title": "Multiply", "text": "Multiply Class: NodeVectorMultiply Perform a scalar multiplication of each component of two or more vector images of the same size, or by a constant value defined in the settings. Inputs Multiply Images Input vector image(s). Type: Image4DVector3, Required, Multiple Outputs Out Resulting vector image. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: Vector, scalar, multiplication ", "tags": "", "url": "nodes.vector.math._operations.multiply.html"},
{"title": "Divide", "text": "Divide Class: NodeVectorDivide Perform a scalar division of each component of two or more vector images of the same size, or by a constant value defined in the settings. Inputs Image Numerator input vector image. Type: Image4DVector3, Required, Single Divide Images Denominator vector image(s). Type: Image4DVector3, Optional, Multiple Outputs Out Resulting vector image. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: vector, scalar, divide, division ", "tags": "", "url": "nodes.vector.math._operations.divide.html"},
{"title": "Ceiling", "text": "Ceiling Class: NodeVectorCeiling Perform the ceiling operation (rounding up to the closes upper integer value) on each component of the vector field. Inputs Image Input vector field. Type: Image4DVector3, Required, Single Outputs Out Resulting vector field. Type: Image4DVector3 Keywords: vector, ceiling, ceil ", "tags": "", "url": "nodes.vector.math._operations.ceiling.html"},
{"title": "Floor", "text": "Floor Class: NodeVectorFloor Perform the floor operation (rounding down to the closes lower integer value) on each component of the vector field. Inputs Image Input vector field. Type: Image4DVector3, Required, Single Outputs Result Resulting vector field. Type: Image4DVector3 See also Keywords: vector, floor ", "tags": "", "url": "nodes.vector.math._operations.floor.html"},
{"title": "Round", "text": "Round Class: NodeVectorRound Round to the closes intege value for each component of the vector field. Inputs Image Input vector image. Type: Image4DVector3, Required, Single Outputs Result Resulting vector image. Type: Image4DVector3 Keywords: round, vector, field, ", "tags": "", "url": "nodes.vector.math._operations.round.html"},
{"title": "Dot Product", "text": "Dot Product Class: NodeVectorDotProduct Calculate the dot product of two vector fields of the same size. Inputs v1 Input vector field. Type: Image4DVector3, Required, Single v2 Input vector field. Type: Image4DVector3, Optional, Single Outputs Out Resulting scalar field. Type: Image4DFloat Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: dot, product, vector, multiplication ", "tags": "", "url": "nodes.vector.math._operations.dot_product.html"},
{"title": "Cross Product", "text": "Cross Product Class: NodeVectorCrossProduct Calculate the cross product of two vector fields. Inputs v1 The first input vector field. Type: Image4DVector3, Required, Single v2 The second input vector field. Type: Image4DVector3, Optional, Single Outputs Out Resulting vector field. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: cross, product, vector, field ", "tags": "", "url": "nodes.vector.math._operations.cross_product.html"},
{"title": "Invert Displacement Field", "text": "Invert Class: NodeVectorInvertDisplacement Inverts a displacement field using a fixed-point approach. Inputs Image Input vector field. Type: Image4DVector3, Required, Single Outputs Output Resulting inverted vector field. Type: Image4DVector3 Settings Interpolator Selection Specifies which interpolation method should be used for the resampling. Default is Linear interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc Iterations Integer Set the number of iterations. References Chen, Mingli &amp; Lu, Weiguo &amp; Chen, Quan &amp; Ruchala, Kenneth &amp; H Olivera, Gustavo. (2008). A simple fixed-point approach to invert a deformation field. Medical physics. 35. 81-8. 10.1118/1.2816107. Inverse Displacement Field in SimpleITK Keywords: Invert, vector, field, displacement ", "tags": "", "url": "nodes.vector.math._operations.invert_displacement_field.html"},
{"title": "Principal Component Analysis", "text": "PCA Class: NodeVectorPCA Principal component analysis (PCA) is a method that is often used to reduce the dimensionality of data, by transforming a large set of variables into a smaller one that still contain most of the information contained in the full dataset. It can make data easier to explore and visualize. By expressing the dataset in terms of componenents (combination of variables) that contributes most to the variation in the data, the number of variables used to describe the dataset can be reduced. The cost is that some high-frequency information is lost (which can be used as a noise reduction technique). The figure shows PCA of a 2D dataset. After PCA, component 2 contains very little information and practically all of the variance in the dataset is described by component 1. The PCA in MICE is based on Extreme Optimization. Inputs Image The input image to be analyzed. Type: Image4DVector3, Required, Single Mask A mask defining which area should be included in the analysis. Must have the same matrix size as the input image. Type: Image4DBool, Optional, Single Outputs Components The components found using PCA. Will have have the same dimensionality as the input data, i.e. if you input 3 frames of a time series and perform PCA along the T dimension, the number of components will be 3. Type: Image4DVector3 Prediction The prediction of the input data using the Number of Components defined in the Node settings. Type: Image4DVector3 Data A table containing the eigen values and eigen vectors of the components. Type: DataCollection Settings Scaling Method Selection When the variables in a PCA analysis use very different scales, the principal components will give more weight to the variable with the larger values. To put all variables on an equal footing, the variables are often scaled. The ScalingMethod property determines if and how this transformation is performed. This value is of type ScalingMethod which can take on the following values: Property Description None No scaling is performed. UnitVariance The columns are scaled to have unit variance. This is the default. VectorNorm The columns are scaled to have unit norm. Pareto The columns are scaled by the square root of the standard deviation. Range The columns are scaled to have unit range (difference between largest and smallest value). Level The columns are scaled by the column mean. Values: None, UnitVariance, VectorNorm, Pareto, Range, Level Number of Components Integer The number of components that is used to recreate the prediction of the output data, given the input data. If the number of components is set to the same number as the dimensionality of the input data, the output will equal the input. If set to a lower value, it will contain less noise. Dimension Selection Along which image dimension should the PCA be performed. Values: X, Y, Z, T Zero Variance Compensation Number If value scaling is used this value will be added to one element of columns with no variance, otherwise the scaling will fail. References Principal component analysis on Wikipedia Principal component analysis on Extreme Optimization Keywords: Principal component analysis, dimensionality reduction, noise reduction, eigen values, eigen vectors ", "tags": "", "url": "nodes.vector.math._operations.principal_component_analysis.html"},
{"title": "Jacobian Determinant", "text": "Jacobian Determinant Class: NodeVectorJacobian Compute the jacobian determinant of a vector field. The jacobian determinant describes the deformation in each voxel; a value less than 1 implies a local compression, a value larger than 1 implies a local expansion. Inputs In Input vector image. Type: Image4DVector3, Required, Single Outputs Out Output jacobian determinant value map. Type: Image4DFloat References The Jacobian Determinant filter in SimpleITK Jacobian determinant information on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.vector.math._operations.jacobian_determinant.html"},
{"title": "Normalize", "text": "Normalize Class: NodeVectorNormalize Normalize an input image. The node rescales the voxel values to a new min and max value, which can be set in the settings. Inputs v Input image. Type: Image4DVector3, Required, Single Outputs Out Resulting rescaled image. Type: Image4DVector3 Keywords: Normalize, rescale ", "tags": "", "url": "nodes.vector.math._operations.normalize.html"},
{"title": "Image", "text": "Vector To Image Class: NodeVectorToImage Convert vector field properties or components to an image. Inputs v Input vector field. Type: Image4DVector3, Required, Single Outputs Image Output image. Type: Image4DFloat Settings Image Value Selection Select the output scalar property of the vector field. Values: Norm, NormSquared, NormX, NormY, NormZ, NormXY, NormXZ, NormYZ, ValueX, ValueY, ValueZ See also Keywords: vector, field, image, Norm, NormSquared, NormX, NormY, NormZ, NormXY, NormXZ, NormYZ, ValueX, ValueY, ValueZ ", "tags": "", "url": "nodes.vector.convert_to.image.html"},
{"title": "Transformix", "text": "Vector Field Class: NodeVectorGenerateTransformix Generate a vector field from a Transformix file. DEPRECATED! Please use the Deformation Analysis node instead. Inputs TFX Transformix transform file. Type: TransformixParameter, Required, Single Outputs Vector Field Output vector field. Type: Image4DVector3 Keywords: Transformix, Elastix, vector ", "tags": "", "url": "nodes.vector.create_from.transformix.html"},
{"title": "XYZ Images", "text": "Images To Vector Class: NodeVectorGenerateImages Create a vector field from three scalar images, defining the x, y and z components of the vector field. Inputs X X component of the vector field. Type: Image4DFloat, Required, Single Y Y component of the vector field. Type: Image4DFloat, Required, Single Z Z component of the vector field. Type: Image4DFloat, Required, Single Outputs Vector Field Resulting vector field. Type: Image4DVector3 Keywords: create, vector, field, component, image ", "tags": "", "url": "nodes.vector.create_from.xyz_images.html"},
{"title": "MetaIO .mhd", "text": "MHD Class: NodeExportMHDVector3 Export all connected vector images to MHD files. Voxel values will be written as they are with no quantization, this might lead to very large files in some cases. Inputs In Input vector image(s). Type: Image4DVector3, Required, Multiple Settings Image Prefix Text Set the image prefix. This string will be added to beginning of the image name. Compress Image Boolean Copress the output image without loss of data. Export Metadata Boolean If TRUE, an XML file containing image metadata will be exported. Path Text Set the output directory of the node. Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, vector, field, mhd ", "tags": "", "url": "nodes.vector.export.metaio_.mhd.html"},
{"title": "MATLAB .mat", "text": "MAT Class: NodeExportMATVector3 Export all connected images to Matlab MAT files. Voxel values will be written as they are with no quantization, this might lead to very large files in some cases. Inputs In Input vector images. Type: Image4DVector3, Required, Multiple Settings Image Prefix Text Set the image prefix. This string will be added to beginning of the image name. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, matlab, mat, .mat, vector ", "tags": "", "url": "nodes.vector.export.matlab_.mat.html"},
{"title": "Magnitude/Phase Images", "text": "Complex Class: NodeComplexToPMImage Calculate the magnitude and phase component images from a complex image. Inputs Image Input complex image. Type: Image4DComplex, Required, Single Outputs Magnitude Output magnitude image. Type: Image4DFloat Phase Output phase image. Type: Image4DFloat Keywords: Complex, phase, magnitude, convert ", "tags": "", "url": "nodes.complex.convert_to.magnitudephase_images.html"},
{"title": "Real/Imaginary Images", "text": "Complex Class: NodeComplexToImage Calculate the real and imaginary component images from a complex image. Inputs Image Input complex image. Type: Image4DComplex, Required, Single Outputs Real Output real component of the complex image. Type: Image4DFloat Imaginary Output imaginary component of the complex image. Type: Image4DFloat Keywords: complex, image, real, imaginary ", "tags": "", "url": "nodes.complex.convert_to.realimaginary_images.html"},
{"title": "Magnitude/Phase Images", "text": "Complex Class: NodeComplexGeneratePMImages Generate a complex image from magnitude and phase images. Inputs Magnitude Input magnitude image. Type: Image4DFloat, Required, Single Phase Input phase image. Type: Image4DFloat, Required, Single Outputs Image Resulting complex image. Type: Image4DComplex Keywords: complex, magnitude, phase ", "tags": "", "url": "nodes.complex.generate_from.magnitudephase_images.html"},
{"title": "Real/Imaginary Images", "text": "Complex Class: NodeComplexGenerateImages Generate a complex image from real and imaginary images. Inputs Real The real component of the complex image. Type: Image4DFloat, Required, Single Imaginary The imaginary component of the complex image. Type: Image4DFloat, Required, Single Outputs Image Resulting complex image. Type: Image4DComplex Keywords:Complex, image, real, imaginary ", "tags": "", "url": "nodes.complex.generate_from.realimaginary_images.html"},
{"title": "MetaIO .mhd", "text": "MHD Class: NodeExportMHDComplex Export all connected complex images to MHD files. Voxel values will be written with no quantization, this might lead to very large files in some cases. Inputs In Input complex images. Type: Image4DComplex, Required, Multiple Settings Image Prefix Text Set the image prefix. This string will be added to beginning of the image name. Compress Image Boolean Compress the output image without loss of data. Export Metadata Boolean If TRUE, an XML file containing image metadata will be exported. Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, mhd, complex ", "tags": "", "url": "nodes.complex.export.metaio_.mhd.html"},
{"title": "MATLAB .mat", "text": "MAT Class: NodeExportMATComplex Converts and exports all connected images to Matlab MAT files. Voxel values will be written as they are with no quantization, this might lead to very large files in some cases.Note: No DICOM metadata will be written to the MAT file. Inputs In Input complex image. Type: Image4DComplex, Required, Multiple Settings Image Prefix Text Sets the image prefix, this string will be added to beginning of the image name. Path Text Sets the output directory of the node. Keywords: Matlab, export, complex ", "tags": "", "url": "nodes.complex.export.matlab_.mat.html"},
{"title": "PDF", "text": "PDF Class: NodeExportPDF Generates a PDF report from the connected data. Inputs Images Optional input images. Type: Image4DFloat, Optional, Multiple Tables Optional input Data Tables. Type: DataCollection, Optional, Multiple Plots Optional input plots. Type: CurveCollection, Optional, Multiple Settings Export Filename Text Sets the file prefix, this string will be added to beginning of the filename. Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Report Report Title Text Sets the title of the report. Text Section Text Title Text Sets the title of the text section, if empty no title will be added. Text Text Sets the text of the text section. Image Section Image Title Text Sets the title of the image section, if empty no title will be added. Images Per Row Integer Sets the number of images per row in the image section. Font Size Number Sets the font size of the description below the image. Middle Slice Only Boolean Export only the middle slice in the stack. Colormap Selection Select the colormap to use for the images. Values: BlackBody, Bone, Cividis, Cool, Copper, Dose, GE, Gray, InverseGray, Inferno, Jet, Magma, Moreland, Pink, Plasma, Sokoloff, Spring, Summer, Viridis, Winter Full Range Window Boolean If selected, the image intensity min and max bounds will be the min and max of the image. Window Min Number Set the intensity min (applies only if the Full range window option is false). Window Max Number Set the intensity max (applies only if the Full range window option is false). Table Section Table Title Text Sets the title of the table section, if empty no title will be added. Max Columns Integer Sets the number of columns to include, if set to 0 all columns will be included. Round Numbers Boolean If set, the numeric values will be rounded to the number of decimals set. Decimals Integer Sets the number of decimals to round numbers to. Odd/Even Row Indication Boolean If set, a slightly darker background will be drawn for even rows. Font Size Number Sets the font size of the tables. Plot Section Plot Title Text Sets the title of the plot section, if empty no title will be added. Keywords: pdf, report, export, disk ", "tags": "", "url": "nodes.applications.reports.pdf.html"},
{"title": "Brainweb MR BETA", "text": "Brainweb MR Class: NodePhantomBrainwebMR This node is a tool for generating parameter maps relevant for magnetic resonance images, e.g. T1 and T2 maps. The node is based on the BrainWeb Phantom and two different brain datasets are available. Example Workflows Create T1, T2, T2* and PD maps Outputs PD [Optional output] Proton density map. Type: Image4DFloat T1 [Optional output] T1 map in units of seconds. Type: Image4DFloat T2 [Optional output] T2 map in units of seconds. Type: Image4DFloat T2* [Optional output] T2* map in units of seconds. Type: Image4DFloat X [Optional output] Magnetic susceptibility map. Type: Image4DFloat CSF [Optional output] Cerebrospinal fluid (CSF) map. Fraction of tissue in each pixel that is CSF. Type: Image4DFloat Skull [Optional output] Skull tissue map. Fraction of tissue in each pixel that is skull. Type: Image4DFloat Dura Mater [Optional output] Dura mater tissue map. Fraction of tissue in each pixel that is dura mater. Type: Image4DFloat Fat [Optional output] Fat tissue map. Fraction of tissue in each pixel that is fat. Type: Image4DFloat Connective [Optional output] Connective tissue map. Fraction of tissue in each pixel that is connective tissue. Type: Image4DFloat Bone Marrow [Optional output] Bone marrow tissue map. Fraction of tissue in each pixel that is bone marrow. Type: Image4DFloat Muscles [Optional output] Muscle tissue map. Fraction of tissue in each pixel that is muscle. Type: Image4DFloat Muscles Skin [Optional output] Muscles or skin tissue map. Fraction of tissue in each pixel that is muscle or skin and not counted as muscle. Type: Image4DFloat Gray Matter [Optional output] Gray matter map. Fraction of tissue in each pixel that is gray matter. Type: Image4DFloat White Matter [Optional output] White matter map. Fraction of tissue in each pixel that is white matter. Type: Image4DFloat Vessels [Optional output] Vessel map. Fraction of tissue in each pixel that are vessels. Type: Image4DFloat Background [Optional output] Map indicating if a pixel is background. Type: Image4DFloat Settings Phantom Subject Selection Select dataset from which the maps or masks should be generated. Values: Subject04, Subject05 Tissue Parameters Text Edit the tissue specific parameter values used in the image generation. Source Tissues Specify what tissues to be used when generating parameter maps. By default all tissues are selected. CSF Boolean Use CSF tissue for parameter maps generation. Skull Boolean Use skull tissue for parameter maps generation. Dura Mater Boolean Use dura mater tissue for parameter maps generation. Fat Boolean Use fat tissue for parameter maps generation. Connective Boolean Use connective tissue for parameter maps generation. Bone Marrow Boolean Use bone marrow tissue for parameter maps generation. Muscles Boolean Use muscle tissue for parameter maps generation. Muscles Skin Boolean Use muscle/skin tissue for parameter maps generation. Gray Matter Boolean Use gray matter for parameter maps generation. White Matter Boolean Use white matter for parameter maps generation. Vessels Boolean Use vessels for parameter maps generation. Output Maps Specify what type of parameter maps to generate. PD Boolean Enable proton density map output. T1 [ms] Boolean Enable T1 map output. T2 [ms] Boolean Enable T2 map output. T2* [ms] Boolean Enable T2* map output. X Boolean Enable susceptibility map output. Ktrans [min⁻¹] Boolean Enable Ktrans map output. ve Boolean Enable ve map output. vp Boolean Enable vp map output. Output Tissues Specify which tissue masks to generate. CSF Boolean Enable CSF tissue fraction map output. Skull Boolean Enable skull tissue fraction map output. Dura Mater Boolean Enable dura mater tissue fraction map output. Fat Boolean Enable fat fraction map output. Connective Boolean Enable connective tissue fraction map output. Bone Marrow Boolean Enable bone marrow tissue fraction map output. Muscles Boolean Enable muscles tissue fraction map output. Muscles Skin Boolean Enable muscles/skin tissue fraction map output. Gray Matter Boolean Enable gray matter fraction map output. White Matter Boolean Enable white matter fraction map output. Vessels Boolean Enable vessels fraction map output. Output Masks Background Boolean Enable background map output. Geometry Settings determining the geometry of the generated maps. Edit Boolean Enable modification of geometry. Note: If not set, all geometry settings will be ignored and a default image size will be created. Matrix X Integer Number of pixels in x-direction. Matrix Y Integer Number of pixels in y-direction. Matrix Z Integer Number of pixels in z-direction. Resolution X [mm] Number Resolution in x-direction, i.e. the size (in mm) of a pixel in the x-direction. Resolution Y [mm] Number Resolution in y-direction, i.e. the size (in mm) of a pixel in the y-direction. Resolution Z [mm] Number Resolution in z-direction, i.e. the size (in mm) of a pixel in the z-direction. Position offset RL [mm] Number Image offset in the x-direction. Position offset AP [mm] Number Image offset in the y-direction. Position offset SI [mm] Number Image offset in the y-direction. Rotation axis RL Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in RL-direction. The rotation vector does not need to be normalized. Rotation axis AP Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in AP-direction. The rotation vector does not need to be normalized. Rotation axis SI Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in SI-direction. The rotation vector does not need to be normalized. Rotation Angle [degrees] Number The angle to rotate the image around the rotation axis. See the setting: Rotation axis RL/AP/SI. Extrapolation value Number Value of voxels outside the phantom. Interpolator Selection Interpolator used when resampling data. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References 1. http://www.bic.mni.mcgill.ca/brainweb/ 2. C.A. Cocosco, V. Kollokian, R.K.-S. Kwan, A.C. Evans : %22BrainWeb: Online Interface to a 3D MRI Simulated Brain Database%22 NeuroImage, vol.5, no.4, part 2 / 4, S425, 1997-- Proceedings of 3 - rd International Conference on Functional Mapping of the Human Brain, Copenhagen, May 1997. 3. R.K.-S. Kwan, A.C. Evans, G.B. Pike : %22MRI simulation - based evaluation of image - processing and classification methods%22 IEEE Transactions on Medical Imaging. 18(11):1085 - 97, Nov 1999. 4. R.K.-S. Kwan, A.C. Evans, G.B. Pike : %22An Extensible MRI Simulator for Post - Processing Evaluation%22 Visualization in Biomedical Computing(VBC'96). Lecture Notes in Computer Science, vol. 1131. Springer-Verlag, 1996. 135-140. 5. D.L. Collins, A.P. Zijdenbos, V. Kollokian, J.G. Sled, N.J. Kabani, C.J. Holmes, A.C. Evans : %22Design and Construction of a Realistic Digital Brain Phantom%22 IEEE Transactions on Medical Imaging, vol.17, No.3, p.463--468, June 1998. 6. B. Aubert-Broche, D.L. Collins, A.C. Evans: %22A new improved version of the realistic digital brain phantom%22 NeuroImage, in review - 2006. 7. B. Aubert-Broche, M. Griffin, G.B. Pike, A.C. Evans and D.L. Collins: %2220 new digital brain phantoms for creation of validation image data bases%22 IEEE TMI, in review - 2006 See also MRI Emulator BETA, Gradient-echo contrast BETA, Spin-echo contrast BETA Keywords: BrainWeb, MRI parameter maps, Tissue maps ", "tags": "", "url": "nodes.applications.digital_phantoms.brainweb_mr_beta.html"},
{"title": "Spin-echo contrast BETA", "text": "Spin Echo Contrast Class: NodeSpinEchoContrast This node generates simulated MRI images of spin-echo type using proton density, T1 and T2 maps and signal equations. Generate a spin-echo image Inputs PD Proton density map. Type: Image4DFloat, Required, Single T1 T1 map in units of seconds. Type: Image4DFloat, Required, Single T2 T2 map in units of seconds. Type: Image4DFloat, Required, Single Outputs Signal The calculated image. Type: Image4DFloat Settings Contrast Selection Select type of contrast. For SpinEcho the signal is cacluated using: \[ \begin{equation} S = PD\cdot(1-2e^{-(TR-TE/2)/T_1}+e^{-TR/T_1})e^{-TE/T_2} \end{equation} \] For InversionRecovery the signal is cacluated using: \[ \begin{equation} S = PD\cdot(1-2e^{-TI/T_1}+e^{-TR/T_1})e^{-TE/T_2} \end{equation} \] Values: SpinEcho, InversionRecovery Repetition time [ms] Number The repetition time (TR). Echo time [ms] Number The repetition time (TE). Inversion time [ms] Number The repetition time (TI). See also Brainweb MR BETA, Gradient-echo contrast BETA Keywords: MRI, Spin-echo, Inversion recovery ", "tags": "", "url": "nodes.applications.digital_phantoms.spin-echo_contrast_beta.html"},
{"title": "Gradient-echo contrast BETA", "text": "Gradient Echo Contrast Class: NodeGradientEchoContrast This node generates simulated MRI images of gradient-echo type using proton density, T1 and T2* maps and signal equations. Example Workflows Generate a gradient-echo image Inputs PD Proton density map. Type: Image4DFloat, Required, Single T1 T1 map in units of seconds. Type: Image4DFloat, Required, Single T2* T2* map in units of seconds. Type: Image4DFloat, Required, Single Outputs Signal The calculated image. Type: Image4DFloat Settings Contrast Selection Select type of contrast. For SpoiledGradientEcho the signal is cacluated using: \[ \begin{equation} S = PD\frac{1-e^{-TR/T_1}}{1-\cos(FA) e^{-TR/T_1}} \sin(FA) e^{-TE/T_2^*} \end{equation} \] Values: SpoiledGradientEcho Repetition time [ms] Number The repetition time (TR). Echo time [ms] Number The echo time (TR). Flip angle [deg] Number Flip angle (FA) Inversion time [ms] Number Inversion/saturation time (TI) See also Brainweb MR BETA, Spin-echo contrast BETA Keywords: MRI, gradient-echo ", "tags": "", "url": "nodes.applications.digital_phantoms.gradient-echo_contrast_beta.html"},
{"title": "MRI Emulator BETA", "text": "MRI Emulator Class: NodeMRIEmulator This node is a tool for emulating magnetic resonance images for various imaging setting. It can generate contrast for spin-echo and gradient echo sequences, add realistic noise as well as simulate effects such as aliasing and fat-water-shift. Output is an image and an estimated imaging time. The node is based on the BrainWeb Phantom and two different brains datasets are available. Figure 1: Examples of some of the images that can be created using the node. Outputs MR Image Magnitude MR image. Type: Image4DFloat Imaging time An estimate of the imaging time. Type: String Settings Phantom Subject Selection Select dataset from which the MR images should be generated. Values: Subject04, Subject05 Tissue Parameters Text Edit the tissue specific parameter values used in the image generation. Geometry Settings determining the geometry of the generated image. Matrix X Integer Number of pixels in x-direction. Matrix Y Integer Number of pixels in y-direction. Matrix Z Integer Number of pixels in z-direction. Resolution X [mm] Number Resolution in x-direction, i.e. the size (in mm) of a pixel in the x-direction. Resolution Y [mm] Number Resolution in y-direction, i.e. the size (in mm) of a pixel in the y-direction. Resolution Z [mm] Number Resolution in z-direction, i.e. the size (in mm) of a pixel in the z-direction. Position offset RL [mm] Number Image offset in the x-direction. Position offset AP [mm] Number Image offset in the y-direction. Position offset SI [mm] Number Image offset in the y-direction. Rotation axis RL Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in RL-direction. The rotation vector does not need to be normalized. Rotation axis AP Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in AP-direction. The rotation vector does not need to be normalized. Rotation axis SI Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in SI-direction. The rotation vector does not need to be normalized. Rotation Angle [degrees] Number The angle to rotate the image around the rotation axis. See the setting: Rotation axis RL/AP/SI. System System related settings, such as field strength. Fieldstrength Selection Select field strength of the scanner. Note that this setting only affects the SNR. To change tissue parameters such as T1 and T2 use the Tissue Parameters setting. Values: B1_5T, B3T Imaging coil Selection Select imaging coil. This will impact the SNR. The IdealCoil value will produce an image with no noise. Values: BodyCoil, HeadCoil, IdealCoil, FlexCoil Maximum Gradient Strength [mT/m] Number Select maximum gradient strength of the scanner. Currently this setting has no effect. Sequence Sequence Name Selection Select sequence. Currently the Fast spin echo only differs from spin echo in terms of imaging time. Values: SPGR, SE, IRSE, FSE, IRFSE Sequence Type Selection Select type of imaging. Values: dim2D, dim3D Phase endocing direction Selection Select the phase encoding direction. Values: dirX, dirY Pixel bandwidth [Hz] Number Bandwidth per pixel in Hertz. Number of averages Number Number of images that are averaged. Parallel imaging factor Number Parallel imaging acceleration factor. Affects SNR. Use partial Fourier Boolean Use partial Fourier to accelerate the imaging (Partial Fourier factor = 5/8). Repetition time [ms] Number The repetition time. Echo time [ms] Number The echo time. 2D settings Slice gap [mm] Number Slice gap in z-direction. Will not affect the resolution or image coverage. Only SNR will be affected since the effective slice thickness is decreased. Inversion recovery settings Inversion time [ms] Number The inversion time. Real reconstruction Boolean Reconstruct real images SPGR settings Flip angle [deg] Number The exitation flip angle. References 1. http://www.bic.mni.mcgill.ca/brainweb/ 2. C.A. Cocosco, V. Kollokian, R.K.-S. Kwan, A.C. Evans : %22BrainWeb: Online Interface to a 3D MRI Simulated Brain Database%22 NeuroImage, vol.5, no.4, part 2 / 4, S425, 1997-- Proceedings of 3 - rd International Conference on Functional Mapping of the Human Brain, Copenhagen, May 1997. 3. R.K.-S. Kwan, A.C. Evans, G.B. Pike : %22MRI simulation - based evaluation of image - processing and classification methods%22 IEEE Transactions on Medical Imaging. 18(11):1085 - 97, Nov 1999. 4. R.K.-S. Kwan, A.C. Evans, G.B. Pike : %22An Extensible MRI Simulator for Post - Processing Evaluation%22 Visualization in Biomedical Computing(VBC'96). Lecture Notes in Computer Science, vol. 1131. Springer-Verlag, 1996. 135-140. 5. D.L. Collins, A.P. Zijdenbos, V. Kollokian, J.G. Sled, N.J. Kabani, C.J. Holmes, A.C. Evans : %22Design and Construction of a Realistic Digital Brain Phantom%22 IEEE Transactions on Medical Imaging, vol.17, No.3, p.463--468, June 1998. 6. B. Aubert-Broche, D.L. Collins, A.C. Evans: %22A new improved version of the realistic digital brain phantom%22 NeuroImage, in review - 2006. 7. B. Aubert-Broche, M. Griffin, G.B. Pike, A.C. Evans and D.L. Collins: %2220 new digital brain phantoms for creation of validation image data bases%22 IEEE TMI, in review - 2006 See also Brainweb MR BETA Keywords: Magnetic resonance imaging, Image generation ", "tags": "", "url": "nodes.applications.digital_phantoms.mri_emulator_beta.html"},
{"title": "Getting Started", "text": "Getting Started 1. Building your first workflow 2. Introduction to nodes 3. The Visualizer 4. Nodes and status lights 5. Introduction to group nodes 6. Repeaters 7. Working with image databases 8. Import DICOM data to workflow 9. Expose node settings as node inputs ", "tags": "", "url": "tutorials.videos.getting_started.html"},
{"title": "Masks", "text": "Masks 1. Drawing custom masks ", "tags": "", "url": "tutorials.videos.masks.html"},
{"title": "1.1.0", "text": "1.1.0 October 22, 2019 In this version support for the old licensing system has been removed and keys generated in the old system will not work. If you are using and old key you need to create a new license account here to get a new free lite license. If you have a premium license in the old licensing system please contact us to receive your new license key. Changes Improved reading performance for large structure sets. Changed the way the visualization image list is ordered, the most recently added item is now always at the bottom of the list. Changed the title of images in the visualizer to display the image name as title, the name of the output is now displayed below the title. Python plugin API changed, please see below. Added new metadata structure to images. Added passing of image metadata to plugin nodes. Added new image metadata viewer. Added functionality to connect several nodes to one input at the same time. Added NIfTI export. Added support for NIfTI metadata .json files. Added save warnings when closing the application or process tab. Added import of Open Slide images (microscopy). Added MR emulator. Added run button. Added save warnings when closing. Added simplified license sign-up. Added split panel between image sets and view-port items to improve scaling. Added create image node. Added new FFT nodes. Added basic support for reading &lsquo;Parametric Map&rsquo; type DICOM images containing float pixel data. Bug Fixes Fixed NIfTI import node not being able to parse certain orientations correctly. Fixed bug related to missing metadata in some images. Fixed license use for multiple users using the same machine. Fixed EUD normalization error. Fixed multiple inputs on plugin nodes. Fixed 2D/2D registration requiring 3D images. Fixed bug when batching MIQA database images with name &lsquo;No Description&rsquo;. Fixed saving bug in plugin editor where the asterisk indicating changes wasn't removed when saving. Fixed bool values in plugins to be either True or False, not 1 and 0. Fixed generation of the InputPaths variable in plugins. General Changes Updated SimpleITK to 1.2.0. Updated UI layout. Plugins We have made substantial changes to the Python plugin API, so if you want to use your old plugins you will probably have to update the code. We have also added import and export of image metadata to all images sent to and from python and MATLAB plugins. Python API Changes The code now adheres to PEP8, which means that many methods and property names have changed slightly. A new module has been added, mtk.utils, which contains many of the methods and functions previously found in Image4D. Class mtk.image.Image4D Changes Changed the constructor to only require shape and dtype parameters. All other parameters are optional. Changed shape, voxel_size and position are now given as a list or a tuple. Changed to_itk_image() to take one optional argument, frame, which selects the frame to send to SimpleITK. By default frame=0. Changed clone_empty() to take one optional argument dtype, which can be used to change the data type of the cloned image. Renamed method toItkImage() to to_itk_image(). Renamed method writemhd() to mtk.utils.write_mhd() and moved it to mtk.utils. Renamed readmhd() to tk.utils.read_mhd() and moved it to mtk.utils. Removed create(), create4d(), create3d(), create2d(). Please use the Image4D class constructor instead. Additions Added transpose(self, *axes). Returns a copy of the image with the axes transposed. Use this if you want to change the order of the image dimensions according to the optional input axes. Added method T(). This methods reverses the order of the axes. Support for metadata has been added. A metadata structure is exported to the python environment in a TypedList, where each element contains the metadata for each frame of the image. Class mtk.utils read_csv(filename, delimiter=&quot;;&quot;): Reads a csv file from disk. write_csv(data, filename, delimiter=&quot;;&quot;): Writes a csv file to disk. read_metadata(path): Read image metadata from an .xml file given in path. from_itk_image(itkimage): Convert a SimpleITK image to an Image4D class. valid_variable(variable_name): Checks if a variable name is valid in MICE/Python. valid_type(value): Checks if a variable has a valid type. TypedList(list): Creates a list datatype with strong typing. This datatype is used in the metadata representation. Struct(object): Creates a structure datatype from a dictionary. This datatype is used in the metadata representation. Code Example # Image4D constructor image = mtk.image.Image4D([10, 10, 10, 3], name='Empty', dtype='bool') # Show overview of image properties image print(image) # Get shape, voxel size and position of image image.shape image.voxel_size image.position # ITK conversion itk_image = image.to_itk_image() itk_image_frame = image.to_itk_image(frame=2) image_from_itk = mtk.utils.from_itk_image(itk_image_frame, dtype='float') ''' Create some metadata. A metadata structure, defined in mtk.utils.Struct is compatible with a DICOM struct, but more flexible. Structs can contain fields, Structs, and TypedLists. A TypedList is a list with strong typing, where each element in must be of the same type. The metadata structure is stored in a TypedList, where each frame has its own Struct. ''' # Create a metadata struct, with fields common to all frames metadata_struct = mtk.utils.Struct(dict(PatientID='10',PatientName='Dummy')) # Add a field to the metadata metadata_struct.Age = 77 # Clone metadata_struct in a TypedList metadata_list = mtk.utils.TypedList([metadata_struct]*3) # Create a tag called &quot;Frame&quot;, that is different in each frame for i, _ in enumerate(metadata_list): metadata_list[i].Frame = i # Store metadata in the Image4D object image.metadata = metadata_list # Cloning mask = image.clone_empty(dtype='bool') # Write to MHD. The metadata is written to an XML file. mtk.utils.write_mhd(&quot;c:\\temp\\mhdimage.mhd&quot;, image) mhd_image = mtk.utils.read_mhd(&quot;c:\\temp\\mhdimage.mhd&quot;) # Verify that the metadata is intact mhd_image.metadata[0].PatientName ", "tags": "", "url": "changelog.1.1.0.html"},
{"title": "1.1.2", "text": "1.1.2 April 12, 2020 New features Added matlab plugins. You can select the programming language you want to use when creating the node, or when editing the node. Please convert your old matlab nodes. Matlab is now started only once per session unless you are using interactive mode. Added search node function. Added a Demo database that is always included in MICE. The database contains two fictitious patients with CT and MR exams, and RTSTRUCTs and RTDOSE. Added &lsquo;Extract Data&rsquo; node, to create a data table from a subset of another data table. Added default voxel value setting to &lsquo;Resample to reference&rsquo; node. Added database connection information in database import nodes. Please note that workflows using this node will not work in older versions of MICE. Added support for multiple masks in &lsquo;Descriptive Statistics&rsquo; node. Added support for RTDOSE images with a negative GridFrameOffsetVector. Added &lsquo;Structure to Data&rsquo; node, to convert an RTSTRUCT to a table of point coordinates. Added &lsquo;Data to Structure&rsquo; node to convert a table of point coordinates to an RTSTRUCT. Added &lsquo;Inverse transform&rsquo; node for linear transformix transforms. Added &lsquo;Apply Transform&rsquo; node for structures, to apply a transformix transform to an RTSTRUCT. NOTE! Due to the way registrations and transforms work, the INVERSE transform must be applied to coordinates in the moving image to transform them to the fixed image frame of reference. Added mesh generation for structures. Changes Updated deformation analysis node to handle 2D images. Plugins can now have the same variable names in inputs, outputs and settings. Threshold filter and Otsu thresholding are separated into two nodes. Workflows with the old node will automatically change to the Otsu node if the filter uses Otsu thresholding. Regions are now called Label Maps in the Time Statistics node. Deformation analysis node can now be used without a reference image. Updated SimpleITK to 1.2.4. Updated Elastix to 5.0. Added a Windows service configuration panel to configure MICE Toolkit to run as a Windows service. Mask to struct node is no longer a micro node. Changed The &ldquo;Multiply&rdquo; title to &quot;Add&quot;, &ldquo;Divide&rdquo;, and &quot;Subtract&quot; in the settings for Add, Divide and Subtract nodes in Vector/Math. Operations. Python API changes: MHD images with gzip compression is now supported for both reading and writing. Large multi-frame images now export correctly with no line-break in the mhd header file. Time-stamps are automatically added when creating a time series. Image4D has new method: create_empty_metadata() to create an empty metadata dictionaty. Bug Fixes Time series now writes correctly from python Time stamps are automatically added when setting a new array in python. Fixed bug when using bool values in python plugins. Fixed 2D transformix to vector field. Fixed reading of dynamic series to sort frames by acquisition number. Viewport selection borders works again in the visualizer. ", "tags": "", "url": "changelog.1.1.2.html"},
{"title": "Image registration", "text": "Image registration with Elastix Image registration is an important part of medical image analysis, to align images taken with different modalities or at different times. The mathematical basis for image registration will not be covered in this article, which will focus on the practical aspects of image registration using elastix in MICE. If you want to know more about the mathematical foundation of image registration, please look in the excellent manual available at the elastix homepage. Some background on the image registration process is however necessary to review. The image registration process The basic image registration problem is based on two images, the fixed image and the moving image. The two images are defined in their own spatial domain, i.e. have their own coordinate systems, and the registration processes aims to find the displacement that spatially aligns the moving image to the fixed image. This is done by displacing the moving image using some transform, spatially mapping a point from the fixed image to the moving image and comparing the information in the two images at that point using some metric. By trying many different displacements using an optimizer, ideally the best alignment between the two images can be found, as illustrated below. In the following sections, the elastix parameter name highlighted as code. Registration components Metrics There are several similarity measures available in elastix, listed below with some pointers on their applicability: Mean squared difference (MSD): (AdvancedMeanSquares) This measure is simple, but only suitable for images with equal intensity distribution, i.e. mono-modal images. Normalised correlation coefficient (NCC): (AdvancedNormalizedCorrelation) The images to be registered must have a linear relationship between their intensity values, and is therefore less strict than MSD and can be used more often. Mutual information (MI): (AdvancedMattesMutualInformation) There must only be a relationship between the probability distributions of the intensity values, and is therefore more general than both MSD and NCC. It is the workhorse of image registration, and works well for both multi- and mono-modal image pairs. This is also the metric that works best in elastix performance wise. Normalized mutual information (NMI): (NormalizedMutualInformation) Similar to MI – there have been indications of better performance than MI in some cases. Kappa statistic (KS): (AdvancedKappaStatistic) Specific to registrations of binary images – measures overlap of segmentations. Transforms There are many transforms available in elastix with different degrees of freedom. Translation: (TranslationTransform) The moving image can only be translated to match the fixed image. Rigid: (EulerTransform) The moving image can be translated and rotated to match the fixed image. Similarity: (SimilarityTransform) The moving image can be translated, rotated and scaled isotropically. This is a quite uncommon transform. Affine: (AffineTransform) The moving image can be translated, rotated, scaled and sheared. B-splines: (BSplineTransform) A non-rigid transform which can model local deformations. The scale of the deformations is largely controlled by the control point spacing. Optimisers There are several different optimizers available in elastix - the most used ones are gradient descent (GD), Robbins-Monro (RM) and adaptive stochastic gradient descent (ASGD) (AdaptiveStochasticGradientDescent). The RM optimizer approximates the calculation of the derivative, making it faster to calculate, and is the recommended over GD in elastix. ASGD requires less parameters to be set and tends to be more robust than GD, and can be used as a default optimizer since it works well in most applications. There are many more optimizers available as well - we refer to the elastix manual for details on these. Other components There are other components necessary in the image registration scheme, such as the image sampler, interpolator and multi-resolution scheme. The image sampler defines the way the evaluated points are selected. In general, all of the points in the fixed image need not be evaluated in order to accomplish a good registration, a subset may suffice. The available choices are Full: (Full) The full sampler evaluates all point in the fixed image. Grid: (Grid) The grid sampler defines a regular grid on the fixed image with grid size defined by the user, effectively downsampling the image. Random: (Random) The random sampler randomly selects a user specified number of voxels from the fixed image. Every voxel has equal chance to be selected, and the same voxel can be selected several times. Random coordinate: (RandomCoordinate) Similar to the random sampler, but is not limited to voxel positions, i.e. points in between voxels can also be selected. The voxel values at these position must be obtained by interpolation. The interpolator is necessary since the optimization is evaluated at non-voxel positions (the moving image moves, rotates and deforms in physical space). There are several methods available with different quality and speed. The available interpolators are Nearest neighbour: (NearestNeighborInterpolator) Fast but course - the intensity of the voxel nearest in space is returned. Linear: (LinearInterpolator) The average of the nearest voxels, weighted by the distance to each voxels. This option usually gives good results during registration. N-th order B-spline: (BSplineInterpolator) The higher order, the better quality but requiring more computation time. The multi-resolution scheme is a way to increase the chance of successful registrations by starting the process with images of lower complexity. This is accomplished using image pyramids which can be smoothed, downsampled, or both, increasing the complexity (i.e. reducing the amount or smoothing and/or downsampling) as the registration process converges. This parameter should be specified for both the fixed and moving image as (Fixed______ImagePyramid) and (Moving______ImagePyramid) where the blank space indicates what kind of method is used. In elastix, the available choices are (parameters only given for the fixed image): Gaussian pyramid: (FixedRecursiveImagePyramid) Applies both smoothing and downsampling. Gaussian scale space: (FixedSmoothingImagePyramid) Applies only smoothing. Shrinking pyramid: (FixedShrinkingImagePyramid) Applies only downsampling. The elastix parameter file The registration components and their parameter values are defined in the elastix parameter file. The syntax is simple and is supplied as follows: (ParameterName &quot;value(s)&quot;) Below, a parameter file is supplied which specifies a 2D rigid registration without comments. The full parameter file with comments can be found here. Note that this is just one example - e.g. some parameters regarding the transform are only valid for the transform that is selected, so the parameter file can vary extensively. It is divided in sections. The first section defines the main settings of the registration - the most important setting for a MICE/elastix user is the image dimension settings, which must be changed between 2D and 3D depending on the application. // Main settings (FixedInternalImagePixelType &quot;float&quot;) (MovingInternalImagePixelType &quot;float&quot;) (FixedImageDimension 2) (MovingImageDimension 2) (UseDirectionCosines &quot;true&quot;) The second section defines the main components of the registration, many of which have been described in the above sections. Two of the components were not mentioned - the registration component connects all other components and implements the multi resolution aspect of the registration. It can also handle multi-metric registrations, which will be further described below in the examples. Also the re-sampler was not mentioned - it defines how to re-sample the final result. Is normally left unchanged. // **************** Main Components ************************** (Registration &quot;MultiResolutionRegistration&quot;) (Interpolator &quot;BSplineInterpolator&quot;) (ResampleInterpolator &quot;FinalBSplineInterpolator&quot;) (Resampler &quot;DefaultResampler&quot;) (FixedImagePyramid &quot;FixedRecursiveImagePyramid&quot;) (MovingImagePyramid &quot;MovingRecursiveImagePyramid&quot;) (Optimizer &quot;AdaptiveStochasticGradientDescent&quot;) (Transform &quot;EulerTransform&quot;) (Metric &quot;AdvancedMattesMutualInformation&quot;) The following section defines parameters pertaining to the transform - how to scale, combine and initialize them. // ***************** Transformation ************************** (AutomaticScalesEstimation &quot;true&quot;) (AutomaticTransformInitialization &quot;true&quot;) (HowToCombineTransforms &quot;Compose&quot;) This section specifies parameters regarding the metric. // ******************* Similarity measure ********************* (NumberOfHistogramBins 32) (ErodeMask &quot;false&quot;) Next, details regarding the multi-resolution scheme. // ******************** Multiresolution ********************** (NumberOfResolutions 4) (ImagePyramidSchedule 8 8 4 4 2 2 1 1 ) Details regarding the optimizer. // ******************* Optimizer **************************** (MaximumNumberOfIterations 250) This section defines how the image sampling should be done. // **************** Image sampling ********************** (NumberOfSpatialSamples 2048) (NewSamplesEveryIteration &quot;true&quot;) (ImageSampler &quot;Random&quot;) Finally, there is a section regarding details on how the interpolation and final re-sampling of the result should be done. // ************* Interpolation and Re-sampling **************** (BSplineInterpolationOrder 1) (FinalBSplineInterpolationOrder 3) (DefaultPixelValue 0) (WriteResultImage &quot;true&quot;) (ResultImagePixelType &quot;short&quot;) (ResultImageFormat &quot;mhd&quot;) There is detailed documentation on the available parameters on the elastix homepage, as well as several parameter file examples with references to literature, see below. In MICE, in the parameter file editor which you can access from the node settings panel or by double-clicking on the node itself in the Process pane, you can find some default parameter files in the PRESETS menu. Elastix parameter documentation Elastix parameter file database Examples in MICE Elastix is normally called via a command-line interpreter, using commands like this: elastix -f fixedImage.ext -m movingImage.ext -out outputDirectory -p parameterFile.txt MICE works like a wrapper to elastix, so you can use it in a graphical user interface. In the following section, examples are provided to demonstrate how to set up the elastix node in MICE to solve different registration tasks. To study the parameter file and node settings, open the example workflows. Rigid registration in 3D This is the simplest case, and it's only using the default settings of Elastix in MICE. Just connect the fixed and moving images and run the process. The parameter file is called Default rigid. Rigid 3D example Affine registration This example shows how to make an affine registration in 3D. The parameter file is called Default affine. The node looks exactly the same as in the rigid example, but the parameters are different. Affine 2D example Basic non-rigid registration in 3D This example shows how to make a basic non-rigid registration in 3D. Use the parameter-file Default non-rigid. The node has an extra input, Initial transform, which contains the initial rigid registration. You can either register the output image from the rigid registration without an initial transform, or the original moving image with an initial transform. It also has an extra output TFX1 which contains the transform parameters. This can be used to produce vector fields to analyze the deformation, apply it to other images, etc. Non-rigid 3D example Non-rigid registration with guiding structures in 2D This example is a little more involved than the previous ones. It is a deformable registration that simultaneously takes into account the image information create a global registration, as well as some guiding structures to guide the registration in a smaller section of the images. To create such a registration, you need to select Use Multiple Fixed Images and Multi Metric in the Node Settings pane. This will create inputs for two image pairs which will be registered simultaneously - note that this type of registration will register the images together, i.e. both image pairs will contribute to the loss function, but they will have the same transform. You will also need to toggle the 2D/2D Registration switch in the Node Settings pane. There are also some special parameter settings: (FixedImageDimension 2) (MovingImageDimension 2) (Registration &quot;MultiMetricMultiResolutionRegistration&quot;) (Interpolator &quot;LinearInterpolator&quot; &quot;LinearInterpolator&quot;) (ImageSampler &quot;RandomCoordinate&quot; &quot;RandomCoordinate&quot;) (FixedImagePyramid &quot;FixedSmoothingImagePyramid&quot; &quot;FixedSmoothingImagePyramid&quot;) (MovingImagePyramid &quot;MovingSmoothingImagePyramid&quot; &quot;MovingSmoothingImagePyramid&quot;) (Metric &quot;AdvancedMattesMutualInformation&quot; &quot;AdvancedMeanSquares&quot;) (Metric0Weight 0.3) (Metric1Weight 0.7) Several parameters need to be specified twice, as there are two simultaneous registrations running. In this registration, we also employ Fixed Masks. These are binary masks, specified in the fixed image space, which defines in what areas the image should be sampled. By using these, you can focus the registration on certain parts of the image. Non-rigid with guiding structures 2D example Partially rigid deformable registration in 2D This example shows how to use auxiliary images to guide the registration, here using an image specifying the rigidity of the image. Where the auxiliary image is 0, the moving image is deformable and where it is 1, the moving image is rigid. To use this type of registration, set the desired number of Auxiliary images to 1 in the Node Settings panel. There are some specific settings in the parameter file: (Registration &quot;MultiMetricMultiResolutionRegistration&quot;) (Metric &quot;AdvancedMattesMutualInformation&quot; &quot;TransformBendingEnergyPenalty&quot; &quot;TransformRigidityPenalty&quot;) (Metric0Weight 0.9) (Metric1Weight 0.1) (Metric2Weight 0.1 0.1 0.1 4) (MovingRigidityImageName AUX1) (DilateRigidityImages &quot;false&quot;) In this example, we change the metric weights depending on where in the multi-resolution scheme we are. In the final resolution, the rigidity penalty is dominant. Note that you call the auxiliary image using AUX1. For details regarding the use of partially rigid registrations and the specific parameters which can be user, we refer to the elastix homepage and the paper by Staring, Klein and Pluim. Non-rigid with guiding structures 2D example ", "tags": "", "url": "articles.image_registration.html"},
{"title": "Smooth masks", "text": "Smooth masks A smooth mask is a MICE specific concept which allows polygonal structures to be rendered on an image, allowing fractional values between 0 and 1. This makes it possible to improve the accuracy of the volume definition. If the polygon cuts a voxel precisely diagonally, the voxel value of the Smooth Mask at that voxel will be 0.5. When producing different statistics based on regions of interest, these can be weighted by the intensity of the Smooth Mask, greatly improving the accuracy especially for structures with small volumes. Note that the Smooth Mask is an ordinary Image and not a specific datatype, so the user must ensure that the input really is a Smooth Mask to avoid nonsense statistics. ", "tags": "", "url": "articles.smooth_masks.html"},
]};