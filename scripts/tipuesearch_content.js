var tipuesearch = {"pages": [
{"title": "Home", "text": "Welcome to MICE Toolkit! These pages will eventually contain all documentation for MICE Toolkit and will be updated regularly. Please check back soon for more information. MICE Toolkit (Medical Interactive Creative Environment) is a graphical programming user interface that is user friendly while still highly flexible. Complex image analysis processes can be constructed rapidly, and users can easily share workflows with the community in a standardized way, which makes it an ideal platform for research. The aim is to make advanced and complex image processing and analysis available to all professionals, including medical fields such as radiotherapy, radiology and pathology. MICE Toolkit provides advanced tools for complex processing and analysis which will simplify the work process and make it far less time consuming to generate results suited to the users particular needs – be it further analysis or formal presentation of your research. Downloading The latest stable release of MICE Toolkit is version 2021.1.0, you can download it here: Download Stable v2021.1.0 Installing Install the software by running the downloaded .exe file. The installation requires approximately 1.5GB of free space. License To run the software a license is needed. If you don't have a license you can register for a lite license HERE. In order to use all features you need a premium license. You can order one HERE. The license is verified against a license server when you run the software. If you have a premium license you need an internet connection to get access to all of the features in your license. Virtual Machines You can use a lite license on a virtual machine, however the premium license can only be run on physical machines. If you need to use your premium license on a virtual machine, please contact us. Remote Desktop If you want to run MICE Toolkit via windows built in remote desktop (RDP) you need to start MICE Toolkit locally on the machine before you connect. This is due to the way windows handle graphics in the remote desktop software. Other remote desktop software like VNC seems to work fine. Hardware Requirements OS We recommend using Windows 10 but it will run on Windows 7, 8 and 8.1 as well. CPU MICE Toolkit uses the CPU with multiple threads for most of the processing so a fast multi core CPU is preferred. Memory Image analysis is memory intense! We recommend at least 8GB of RAM for most applications. Graphics MICE Toolkit uses VTK to visualize images, so before deciding on a graphics card please read the following statement taken from the VTK/FAQ: Modern graphics cards that supports OpenGL 2.1 or better typically provide all the functionality that VTK needs. However, there is good deal of variability in results across OS platform and vendor's OpenGL implementation. NVidia cards and drivers work the best. Intel HD integrated graphics and ATI Radeon HD devices and drivers are known to have a few issues. Mesa3D OpenGL although claiming support for a wide range of devices is highly unstable and the overall buggy-ness of their implementation changes daily and by renderer. Mesa's llvmpipe drivers are expected to generally work well. Our experience tells us that cards from NVidia are the most compatible. Disk Space The installation requires approximately 1.5GB of free space. ", "tags": "", "url": "home.html"},
{"title": "Add", "text": "Add Class: NodeImageAdd Adds two or more images together element-wise, or a scalar to an image. If multiple images are added, matrix sizes must be equal. Example workflows Simple math operations example Inputs Add One or multiple images to be added. If multiple images are added, the matrix sizes must be equal. Type: Image4DFloat, Required, Multiple Outputs Out The resulting image. Type: Image4DFloat Settings Number Number The scalar to add to an image. Disregarded if more than one image is connected to the input. Keywords: Math ", "tags": "", "url": "nodes.image.math._operations.add.html"},
{"title": "Subtract", "text": "Subtract Class: NodeImageSubtract Subtracts two or more images from another element-wise, or a scalar from an image. If one or several images are subtracted from another, all matrix sizes must be equal. Example workflows Simple math operations example Inputs Image The image which is to be subtracted from. Type: Image4DFloat, Required, Single Subtract One or multiple images to be subtracted from the first input image. Must be of equal matrix size to the first input image. Type: Image4DFloat, Optional, Multiple Outputs Out The resulting image. Type: Image4DFloat Settings Number Number The scalar to subtract from an image. Disregarded if more than one image is connected to the inputs. Keywords: Math ", "tags": "", "url": "nodes.image.math._operations.subtract.html"},
{"title": "Multiply", "text": "Multiply Class: NodeImageMultiply Multiplies two or more images together element-wise, or an image with a scalar. If multiple images are multiplied, matrix sizes must be equal. Example workflows Simple math operations example Inputs Multiply Images One or multiple images to be multiplied. If a single image is connected, it will be multiplied with the scalar specified in the Node settings. Multiple images to be multiplied must be of equal matrix size. Type: Image4DFloat, Required, Multiple Outputs Out The resulting image. Type: Image4DFloat Settings Scalar Number The scalar to multiply with an image. Disregarded if more than one image is connected to the input. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.multiply.html"},
{"title": "Divide", "text": "Divide Class: NodeImageDivide Divides one image with one or multiple others element-wise, or an image by a scalar. If an image is divided by one or several others, all matrix sizes must be equal. Example workflows Simple math operations example Inputs Image The image which is to be divided. Type: Image4DFloat, Required, Single Divide Images One or multiple images to divide the first input image with. Must be of equal matrix size to the first input image. No elements in these images can be 0. Type: Image4DFloat, Optional, Multiple Outputs Out The resulting image. Type: Image4DFloat Settings Scalar Number Divide the input with this scalar. Disregarded if more than one image is connected to the inputs. Cannot be 0. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.divide.html"},
{"title": "Absolute Value", "text": "Absolute Value Class: NodeImageAbs Calculates the absolute value of each voxel in the image. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Out The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.absolute_value.html"},
{"title": "Ceiling", "text": "Ceiling Class: NodeImageCeiling Rounds each voxel value to the closest, larger integer. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Out The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.ceiling.html"},
{"title": "Floor", "text": "Floor Class: NodeImageFloor Rounds each voxel value to the closest, smaller integer. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Result The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.floor.html"},
{"title": "Round", "text": "Round Class: NodeImageRound Rounds each voxel value to the closest integer. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Result The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.round.html"},
{"title": "Raise To Power", "text": "Raise To Power Class: NodeImageRaiseToPower Raise each voxel \(A_i\) in the input image to the power of the voxel value in the secondary input image(s) \(B_{i,j}\), or by a scalar. \[ \begin{equation} R_i = A_i^{\sum_j{B_{i,j}}} \label{eq:sample} \end{equation} \] If multiple inputs are used, all matrix sizes must be equal. Example workflows Simple math operations example Inputs Image The input image. Type: Image4DFloat, Required, Single Raise to One or multiple images containing the values with which to raise the primary input image. Type: Image4DFloat, Optional, Single Outputs Out The resulting image. Type: Image4DFloat Settings Number Number Raise each voxel in the input image to the power of specified number. Disregarded if an image is connected to the secondary input. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.raise_to_power.html"},
{"title": "Square Root", "text": "Square Root Class: NodeImageSquareRoot Calculate the square root of each voxel in the input image. Example workflows Simple math operations example Inputs Image The input image. All elements must be \(&gt;0\). Type: Image4DFloat, Required, Single Outputs Result The resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.square_root.html"},
{"title": "Principal Component Analysis", "text": "PCA Class: NodeImagePCA Principal component analysis (PCA) is a method that is often used to reduce the dimensionality of data, by transforming a large set of variables into a smaller one that still contain most of the information contained in the full dataset. It can make data easier to explore and visualize. By expressing the dataset in terms of componenents (combination of variables) that contributes most to the variation in the data, the number of variables used to describe the dataset can be reduced. The cost is that some high-frequency information is lost (which can be used as a noise reduction technique). The figure shows PCA of a 2D dataset. After PCA, component 2 contains very little information and practically all of the variance in the dataset is described by component 1. The PCA in MICE is based on Extreme Optimization. Example workflows Noise reduction with PCA example Inputs Image The input image to be analyzed. Type: Image4DFloat, Required, Single Mask A mask defining which area should be included in the analysis. Must have the same matrix size as the input image. Type: Image4DBool, Optional, Single Outputs Components The components found using PCA. Will have have the same dimensionality as the input data, i.e. if you input 3 frames of a time series and perform PCA along the T dimension, the number of components will be 3. Type: Image4DFloat Prediction The prediction of the input data using the Number of Components defined in the Node settings. Type: Image4DFloat Data A table containing the eigen values and eigen vectors of the components. Type: DataCollection Settings Scaling Method Selection When the variables in a PCA analysis use very different scales, the principal components will give more weight to the variable with the larger values. To put all variables on an equal footing, the variables are often scaled. The ScalingMethod property determines if and how this transformation is performed. This value is of type ScalingMethod which can take on the following values: Property Description None No scaling is performed. UnitVariance The columns are scaled to have unit variance. This is the default. VectorNorm The columns are scaled to have unit norm. Pareto The columns are scaled by the square root of the standard deviation. Range The columns are scaled to have unit range (difference between largest and smallest value). Level The columns are scaled by the column mean. Values: None, UnitVariance, VectorNorm, Pareto, Range, Level Number of Components Integer The number of components that is used to recreate the prediction of the output data, given the input data. If the number of components is set to the same number as the dimensionality of the input data, the output will equal the input. If set to a lower value, it will contain less noise. Dimension Selection Along which image dimension should the PCA be performed. Values: X, Y, Z, T Zero Variance Compensation Number If value scaling is used this value will be added to one element of columns with no variance, otherwise the scaling will fail. References Principal component analysis on Wikipedia Principal component analysis on Extreme Optimization Keywords: Principal component analysis, dimensionality reduction, noise reduction, eigen values, eigen vectors ", "tags": "", "url": "nodes.image.math._operations.principal_component_analysis.html"},
{"title": "Convolution", "text": "Convolution Class: NodeImageConvolution Convolve a given image with an arbitrary image kernel. Inputs Image Input image. Type: Image4DFloat, Required, Single Kernel Image to use as convolution kernel. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Normalize Boolean Normalize the output image by the sum of the kernel components. Boundary Condition Selection Set the boundary condition. Values: ZeroPad, ZeroFluxNeumannPad, PeriodicPad Output Region Mode Selection Sets the output region mode. If set to SAME, the output region will be the same as the input region, and regions of the image near the boundaries will contain contributions from outside the input image as determined by the boundary condition. If set to VALID, the output region consists of pixels computed only from pixels in the input image (no extrapolated contributions from the boundary condition are needed). The output is therefore smaller than the input region. Values: Same, Valid References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.convolution.html"},
{"title": "Forward FFT", "text": "Forward FFT Class: NodeFlexibleForwardFFT Calculates the forward FFT. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DComplex Settings Input &amp; Output Input Type Selection Select the type of input the node should accept. Can be real or complex images. Values: Real, Complex Output Type Selection Select if imaginary part of the output should be supressed or not. Values: Real, Complex Configurations Transform X-dimension Boolean Perform the FFT operation for the X-dimension. Transform Y-dimension Boolean Perform the FFT operation for the Y-dimension. Transform Z-dimension Boolean Perform the FFT operation for the Z-dimension. Transform T-dimension Boolean Perform the FFT operation for the T-dimension. Centered FFT Boolean Put the zero-frequency at the image center. Normalization Type Selection Select how the FFT should be normalized. Can be orthonormal or none. Values: Orthonormal, None See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.forward_fft.html"},
{"title": "Inverse FFT", "text": "Inverse FFT Class: NodeFlexibleInverseFFT Calculates the inverse FFT. Inputs Image Input image. Type: Image4DComplex, Required, Single Outputs Output Resulting image. Type: Image4DComplex Settings Input &amp; Output Input Type Selection Select the type of input the node should accept. Can be real or complex images. Values: Real, Complex Output Type Selection Select if imaginary part of the output should be supressed or not. Values: Real, Complex Configurations Transform X-dimension Boolean Perform the FFT operation for the X-dimension. Transform Y-dimension Boolean Perform the FFT operation for the Y-dimension. Transform Z-dimension Boolean Perform the FFT operation for the Z-dimension. Transform T-dimension Boolean Perform the FFT operation for the T-dimension. Centered FFT Boolean Put the zero-frequency at the image center. Normalization Type Selection Select how the FFT should be normalized. Can be orthonormal or none. Values: Orthonormal, None See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.inverse_fft.html"},
{"title": "FFT Shift", "text": "FFT Shift Class: NodeForwardFFTShift Perform FFT shift along selected dimensions. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Input &amp; Output Input Type Selection Select the type of input the node should accept. Can be real or complex images. Values: Real, Complex Configurations Shift X-dimension Boolean Perform the FFT shift operation for the X-dimension. Shift Y-dimension Boolean Perform the FFT shift operation for the Y-dimension. Shift Z-dimension Boolean Perform the FFT shift operation for the Z-dimension. Shift T-dimension Boolean Perform the FFT shift operation for the T-dimension. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.fft_shift.html"},
{"title": "Inverse FFT Shift", "text": "Inverse FFT Shift Class: NodeInverseFFTShift Perform inverse FFT shift along selected dimensions. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Input &amp; Output Input Type Selection Select the type of input the node should accept. Can be real or complex images. Values: Real, Complex Configurations Shift X-dimension Boolean Perform the FFT shift operation for the X-dimension. Shift Y-dimension Boolean Perform the FFT shift operation for the Y-dimension. Shift Z-dimension Boolean Perform the FFT shift operation for the Z-dimension. Shift T-dimension Boolean Perform the FFT shift operation for the T-dimension. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.inverse_fft_shift.html"},
{"title": "FFT Convolution", "text": "FFT Convolution Class: NodeImageFFTConvolution Convolve a given image with an arbitrary image kernel using multiplication in the Fourier domain. Inputs Image Input image. Type: Image4DFloat, Required, Single Kernel Image to use as kernel. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.fft_convolution.html"},
{"title": "Create Expression", "text": "Expression Class: NodeImageExpression Create a custom expression which applies to the elements of the input image. The user can specify an arbitrary number of input images, numbers and bits which are assigned a variable name, starting with \(a\). Atleast one image is mandatory. The variable names can then be used to create an expression to be calculated. As an example, to create a node that takes an input image \(a\), ads it to a second input image \(b\), and multiplies the result with \(e\) raised to the power of an input number \(c\), you would write: (a+b)*e^c Conditional statements are also possible. To replace all voxels values in input image \(a\) above the input value \(b\) or less than \(\displaystyle 0\) with \(b\), the following expression woule be used: if(a&gt;b or a&lt;0, b, a) Special Variables: e: The natural logarithmic base. pi: The ratio of the circumference of a circle to its diameter. vpx, vpy, vpz: The x, y, and z coordinate of the current voxel. vix, viy, viz: The x, y, and z index of the current voxel. vsx, vsy, vsz: The x, y, and z size of one voxel. vcx, vcy, vcz: The x, y, and z voxel count of the image. ipx, ipy, ipz: The x, y, and z position of the image. Conditional statements and logical expressions: if(expression, true, false): if statement with a conditional expression, and the returned value when this expression is true and false, respectively. =, &lt;&gt;, &lt;, &gt;, ⇐, &gt;=: Comparison operators. and: Logical and. or: Logical or. xor: Logical exclusive or. not: Logical not. Some Functions: abs(x), acos(x), asin(x), atan(x), atan2(x, y), ceiling(x), cos(x), cosh(x), floor(x), log(x), log(x, b), log10(x), max(x, y), min(x, y), rand(x), rande(x), randg(o, s), randn(m, sd), round(x), sign(x), sin(x), sinh(x), sqrt(x), tan(x), tanh(x), truncate(x) Example workflows Custom expressions example Hausdorff and Maurer distance example Advanced use of custom expressions Inputs a The default image input. Type: Image4DFloat, Required, Single Outputs Result The resulting image. Type: Image4DFloat Settings Display Show Expression Boolean If checked, the expression will be displayed beneath the node name in the process window. Node Name Text The display name of the node in the process window. Expression Expression Text The expression which should be calculated. Inputs Images Integer The number of input images. Numbers Integer The number of input numbers. Bits Integer The number of input bits. Result Set Infinity To Number What value should Infity be set to. Set Undefined Numbers To Number What value should Undifined numbers be set to. Resulting Image Name Text The name of the resulting image. See also Keywords: ", "tags": "", "url": "nodes.image.math._operations.create_expression.html"},
{"title": "Normal (Gaussian)", "text": "Normal Noise Class: NodeImageNormalNoise Alter an image with normally distributed noise. Example workflows Add noise example workflow Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Normal Distribution Mean Number Mean value of the noise. Standard Deviation Number Standard deviation of the added noise. Value As Mean Boolean Use each voxel value as mean for the distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.normal_(gaussian).html"},
{"title": "Gamma", "text": "Gamma Noise Class: NodeImageGammaNoise Alter an image with gamma distributed noise. Example workflows Add noise example workflow Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Gamma Distribution Shape Number Shape parameter of the gamma distribution. Rate Number Rate parameter of the gamma distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.gamma.html"},
{"title": "Log-Normal", "text": "Log Normal Noise Class: NodeImageLogNormalNoise Alter an image with lognormal distributed noise. Example workflows Add noise example workflow Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Log-Normal Distribution Mean Number Mean value of the noise. Standard Deviation Number Standard deviation of the added noise. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.log-normal.html"},
{"title": "Poission", "text": "Poisson Noise Class: NodeImagePoissonNoise Alter an image with poisson distributed noise. Example workflows Add noise example workflow Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Poisson Distribution Lambda Number Lambda parameter of the poisson distribution. Value As Lambda Boolean Use each voxel value as lambda for the distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.poission.html"},
{"title": "Laplace", "text": "Laplace Noise Class: NodeImageLaplaceNoise Alter an image with laplace distributed noise. Example workflows Add noise example workflow Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Laplace Distribution Location Number Location parameter of the laplace distribution. Laplace Scale Number Scale parameter of the laplace distribution. Value As Location Boolean Use each voxel value as location for the distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.laplace.html"},
{"title": "Beta", "text": "Beta Noise Class: NodeImageBetaNoise Alter an image with beta distributed noise. Example workflows Add noise example workflow Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Beta Distribution Shape A Number Shape parameter A of the beta distribution. Shape B Number Shape parameter B of the beta distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.beta.html"},
{"title": "Chi", "text": "Chi Noise Class: NodeImageChiNoise Alter an image with chi distributed noise. Example workflows Add noise example workflow Inputs Image Image to apply the noise on. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Chi Distribution Degrees of Freedom Integer Degrees of freedom parameter of the chi distribution. See also Keywords: ", "tags": "", "url": "nodes.image.filters.noise.chi.html"},
{"title": "Rician", "text": "Rician Noise Class: NodeImageRicianNoise Alter an image with rician distributed noise. Inputs Image Image to apply the noise to. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Type Selection Sets the way the noise is applied to the image. Values: Add, Multiply, Replace Scale Number The scale of the noise, the noise is multiplied by this factor. Rician Distribution v Number Distance between the reference point and the center of the bivariate distribution. Sigma Number Scale. Value As v Boolean Use each voxel value as v for the distribution. Keywords: Noise ", "tags": "", "url": "nodes.image.filters.noise.rician.html"},
{"title": "Gaussian Blur", "text": "Gaussian Blur Class: NodeSimpleGaussian Computes the smoothing of an image by convolution with a Gaussian kernel. This node uses two ITK filters depending on the selected algorithm: SmoothingRecursive or Discrete. If any dimension of the input matrix is &lt;4, the Discrete algorithm must used. Example workflows Denoising filters example workflow Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Algorithm Selection Sets the algorithm to use for the filter. Values: SmoothingRecursive, Discrete Sigma Number Set Sigma value. Sigma is measured in the units of image spacing. References SmoothingRecursiveGaussianImageFilter in SimpleITK DiscreteGaussianImageFilter in SimpleITK Gaussian Blur on Wikipedia ", "tags": "", "url": "nodes.image.filters.denoise.gaussian_blur.html"},
{"title": "Median", "text": "Median Class: NodeImageMedianFilter Applies a median filter to an image.Computes an image where a given pixel is the median value of the the pixels in a neighborhood about the corresponding input pixel. A median filter is one of the family of nonlinear filters. It is used to smooth an image without being biased by outliers or shot noise. Example workflows Denoising filters example workflow Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Radius X Integer Radius in the X-direction of the kernel in voxels. Radius Y Integer Radius in the Y-direction of the kernel in voxels. Radius Z Integer Radius in the Z-direction of the kernel in voxels. References MedianImageFilter in SimpleITK ", "tags": "", "url": "nodes.image.filters.denoise.median.html"},
{"title": "Box Mean", "text": "Box Mean Class: NodeBoxMeanFilter Applies a box mean filter to an image.Computes an image where a given pixel is the mean value of the the pixels in a neighborhood about the corresponding input pixel. Example workflows Denoising filters example workflow Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Radius X Integer Radius in the X-direction of the kernel in voxels. Radius Y Integer Radius in the Y-direction of the kernel in voxels. Radius Z Integer Radius in the Z-direction of the kernel in voxels. References BoxMeanImageFilter in SimpleITK ", "tags": "", "url": "nodes.image.filters.denoise.box_mean.html"},
{"title": "Curvature Flow", "text": "Curvature Flow Class: NodeImageCurvatureFlowFilter Curvature driven image denoising algorithm. Iso-brightness contours in the grayscale input image are viewed as a level set. The level set is then evolved using a curvature-based speed function. The advantage of this approach is that sharp boundaries are preserved with smoothing occurring only within a region. However, it should be noted that continuous application of this scheme will result in the eventual removal of all information as each contour shrinks to zero and disappear. This filter has two parameters: the number of update iterations to be performed and the timestep between each update. The timestep should be &ldquo;small enough&rdquo; to ensure numerical stability. Stability is guaranteed when the timestep meets the CFL (Courant-Friedrichs-Levy) condition. Broadly speaking, this condition ensures that each contour does not move more than one grid position at each timestep. In the literature, the timestep is typically user specified and have to manually tuned to the application. Example workflows Denoising filters example workflow Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Time Step Number Set the timestep parameter. Iterations Integer Set the number of iterations. References CurvatureFlowImageFilter in SimpleITK ", "tags": "", "url": "nodes.image.filters.denoise.curvature_flow.html"},
{"title": "Min/Max Curvature Flow", "text": "Min/Max Curvature Flow Class: NodeImageMinMaxCurvatureFlowFilter Curvature driven image denoising algorithm. Iso-brightness contours in the grayscale input image are viewed as a level set. The level set is then evolved using a curvature-based speed function.In min/max curvature flow, movement is turned on or off depending on the scale of the noise one wants to remove. Switching depends on the average image value of a region, the stencil radius, governs the scale of the noise to be removed. Example workflows Denoising filters example workflow Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Time Step Number Set the timestep parameter. Iterations Integer Set the number of iterations. Stencil Radius Integer The scale of the noise to be removed. References MinMaxCurvatureFlowImageFilter in SimpleITK ", "tags": "", "url": "nodes.image.filters.denoise.minmax_curvature_flow.html"},
{"title": "Bilateral", "text": "Bilateral Denoising Class: NodeImageBilateralFilter The bilateral filter blurs an image while preserving edges. This filter uses bilateral filtering to blur an image using both domain and range &ldquo;neighborhoods&rdquo;. Pixels that are close to a pixel in the image domain and similar to a pixel in the image range are used to calculate the filtered value. Two gaussian kernels (one in the image domain and one in the image range) are used to smooth the image. The result is an image that is smoothed in homogeneous regions yet has edges preserved. The result is similar to anisotropic diffusion but the implementation in non-iterative. Bilateral filtering is capable of reducing the noise in an image by an order of magnitude while maintaining edges. The bilateral operator used here was described by Tomasi and Manduchi. Example workflows Denoising filters example workflow Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Output The denoised image. Type: Image4DFloat Settings Domain Sigma Number The standard deviation of the gaussian blurring kernel in mm. Range Sigma Number The standard deviation of the gaussian blurring kernel in the image range in intensity units. Number of Gaussian Samples Integer The number of samples in the approximation of the Gaussian used for the range smoothing. References 1. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.filters.denoise.bilateral.html"},
{"title": "Curvature Anisotropic Diffusion", "text": "CAD Class: NodeCurvatureDiffusion This filter performs anisotropic diffusion on a scalar image using the modified curvature diffusion equation (MCDE). Example workflows Denoising filters example workflow Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Conductance Number The conductance parameter controls the sensitivity of the conductance term in the basic anisotropic diffusion equation. It affect the conductance term in different ways depending on the particular variation on the basic equation. As a general rule, the lower the value, the more strongly the diffusion equation preserves image features (such as high gradients or curvature). A high value for conductance will cause the filter to diffuse image features more readily. Typical values range from 0.5 to 2.0 for data like the Visible Human color data, but the correct value for your application is wholly dependent on the results you want from a specific data set and the number or iterations you perform. Scaling Update Interval Integer Set the interval at which a new scaling for the conductance term is calculated. Time Step Number Sets the time step to be used for each iteration (update). The time step is constrained at run-time to keep the solution stable. In general, the time step should be at or below (PixelSpacing)/2^(N+1), where N is the dimensionality of the image. Iterations Integer Set the number of iterations. References CurvatureAnisotropicDiffusionImageFilter in SimpleITK ", "tags": "", "url": "nodes.image.filters.denoise.curvature_anisotropic_diffusion.html"},
{"title": "Laplacian", "text": "Sharpen Class: NodeImageLaplacianSharpening This filter sharpens an image using a Laplacian that highlights regions of rapid intensity change and therefore highlights or enhances the edges. The result is an image that appears more in focus. Example workflows Sharpening examples Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. An image of the same size as the input image. Type: Image4DFloat Settings Use Image Spacing Boolean Set whether or not the filter will use the spacing of the input image in its calculations. References Laplacian sharpening image filter in SimpleITK Keywords: Laplacian, sharpening, SimpleITK ", "tags": "", "url": "nodes.image.filters.sharpen.laplacian.html"},
{"title": "Unsharp masking", "text": "Sharpen Class: NodeImageUnsharpMask This filter subtracts a smoothed version of the input image from itself, which achieves the edge enhancing effect. The formula used is Sharpened = Original + [ abs(Original - Blurred) - Threshold] * Amount Example workflows Sharpening examples Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Output The sharpened image. Type: Image4DFloat Settings Amount Number The weight of the subtracted smoothed image. Radius Number The radius affects the size of the edges to be enhanced. Threshold Number Controls the minimum brightness change that will be sharpened. References 1. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.filters.sharpen.unsharp_masking.html"},
{"title": "Adaptive Histogram Equalization", "text": "AHE Class: NodeAdaptiveHistogramEqualization Histogram equalization modifies the contrast in an image. By modifying parameters (alpha, beta, and radius), the filter can produce an adaptively equalized histogram or a version of unsharp mask (local mean subtraction). Instead of applying a strict histogram equalization in a window about a pixel, this filter prescribes a mapping function (power law) controlled by the parameters alpha and beta. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Adaptive Histogram Equalization Alpha Number Controls how much the filter acts like the classical histogram equalization method (alpha=0) to how much the filter acts like an unsharp mask (alpha=1). Beta Number Controls how much the filter acts like an unsharp mask (beta=0) to much the filter acts like pass through (beta=1, with alpha=1). Region Radius X Integer Size of the region over which local statistics are calculated in the X direction, specified in voxels. Radius Y Integer Size of the region over which local statistics are calculated in the Y direction, specified in voxels. Radius Z Integer Size of the region over which local statistics are calculated in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.adaptive_histogram_equalization.html"},
{"title": "Normalize", "text": "Normalize Class: NodeNormalize Normalizes an image to a specified intensity range. Inputs In Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings New Min Number New minimum intensity value. New Max Number New maximum intensity value. Silcewise Boolean Perform the normalization on a slice-by-slice basis. ", "tags": "", "url": "nodes.image.filters.normalize.html"},
{"title": "Truncate", "text": "Truncate Class: NodeImageTruncate Truncates the intensity range of the input to a specified range, i.e. all values larger than the specified max value will be set to the max value, and conversely for the set min value. Inputs In Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting truncated image. Type: Image4DFloat Settings Min Level Number All voxel values below this value will be set to this value. Max Level Number All voxel values above this value will be set to this value. Keywords: Truncate ", "tags": "", "url": "nodes.image.filters.truncate.html"},
{"title": "Sigmoid", "text": "Sigmoid Class: NodeSigmoidFilter Computes the sigmoid function pixel-wise. A linear transformation is applied first on the argument of the sigmoid function. The resulting total transform is given by \(f(x) = (Max-Min) * \dfrac{1}{1+e^{-(x - \beta) / \alpha }} + Min\) Every output pixel is equal to f(x). Where x is the intensity of the homologous input pixel, and alpha and beta are user-provided constants. The \(\beta\) value can be thought of the offset on the pixel value that you are trying to isolate. E.g., if the object you are trying to isolate is at a pixel intensity above 150, you would choose a \(\beta\) value that is around that value. The \(\alpha\) value can be thought of as the scaling or variance of the sigmoid. Lower \(\alpha\) values will make the pixel range of your intensity sharper. Your \(\alpha\) value would decide how much of the noise you would want to include in your transformation. Smaller \(\alpha\) values (0.25, 0.5) would zero out most of the noise, but it might make your actual signal thicker and not specific enough. Conversely, larger alpha values (e.g. 3+) might have a smoother signal but might include more noise. Negative alpha values can be thought of as using a positive alpha value and then inverting the image. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Alpha Number Alpha parameter. Low values cancel noise, but makes signal thicker. Negative values inverts image. Beta Number Beta parameter. Set to ~the pixel value you want to isolate. Output Maximum Number Output max value. Output Minimum Number Output min value. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.filters.sigmoid.html"},
{"title": "Erode", "text": "Erode Class: NodeImageErode Erode an image using grayscale morphology. Erosion takes the minimum of all the pixels identified by the structuring element (kernel) defined in the options. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.erode.html"},
{"title": "Dilate", "text": "Dilate Class: NodeImageDilate Dilate an image using grayscale morphology. Dilate takes the maximum of all the pixels identified by the structuring element (kernel) defined in the options. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.dilate.html"},
{"title": "Opening", "text": "Opening Class: NodeImageOpening Removes small (i.e., smaller than the structuring element) structures in the interior or at the boundaries of the image.The morphological opening of an image &ldquo;f&rdquo; is defined as: Opening(f) = Dilatation(Erosion(f)). Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.opening.html"},
{"title": "Closing", "text": "Closing Class: NodeImageClosing This filter removes small (i.e., smaller than the structuring element) holes and tube like structures in the interior or at the boundaries of the image.The morphological closing of an image &ldquo;f&rdquo; is defined as: Closing(f) = Erosion(Dilation(f)). Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.closing.html"},
{"title": "Opening by Reconstruction", "text": "Reconstruction Class: NodeImageOpeningByReconstruction This filter preserves regions, in the foreground, that can completely contain the structuring element. At the same time, this filter eliminates all other regions of foreground pixels. Contrary to the morphological opening, the opening by reconstruction preserves the shape of the components that are not removed by erosion. The opening by reconstruction of an image &ldquo;f&rdquo; is defined as:OpeningByReconstruction(f) = DilationByRecontruction(f, Erosion(f)).Opening by reconstruction not only removes structures destroyed by the erosion, but also levels down the contrast of the brightest regions. If PreserveIntensities is on, a subsequent reconstruction by dilation using a marker image that is the original image for all unaffected pixels.Opening by reconstruction is described in Chapter 6.3.9 of Pierre Soille's book &quot;Morphological Image Analysis: Principles and Applications&quot;, Second Edition, Springer, 2003. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.opening_by_reconstruction.html"},
{"title": "Closing by Reconstruction", "text": "Reconstruction Class: NodeImageClosingByReconstruction This filter is similar to the morphological closing, but contrary to the morphological closing, the closing by reconstruction preserves the shape of the components. The closing by reconstruction of an image &ldquo;f&rdquo; is defined as:ClosingByReconstruction(f) = ErosionByReconstruction(f, Dilation(f)).Closing by reconstruction not only preserves structures preserved by the dilation, but also levels raises the contrast of the darkest regions. If PreserveIntensities is on, a subsequent reconstruction by dilation using a marker image that is the original image for all unaffected pixels.Closing by reconstruction is described in Chapter 6.3.9 of Pierre Soille's book &quot;Morphological Image Analysis: Principles and Applications&quot;, Second Edition, Springer, 2003. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.closing_by_reconstruction.html"},
{"title": "Fill Hole", "text": "Fill Hole Class: NodeImageFillHole Fills holes in a grayscale image. Holes are local minima in the grayscale topography that are not connected to boundaries of the image. Gray level values adjacent to a hole are extrapolated across the hole.Note: Geodesic morphology and the Fillhole algorithm is described in Chapter 6 of Pierre Soille's book &lsquo;Morphological Image Analysis: Principles and Applications&rsquo;, Second Edition, Springer, 2003. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Out Resulting image. Type: Image4DFloat Settings Fully Connected Boolean Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. For objects that are 1 pixel wide, use On. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.morphology.fill_hole.html"},
{"title": "From Four Images", "text": "Select Class: NodeImageSelectFour Selects an output image from four input images using two bits. The first bit is the least significant, i.e. 00 = 0, 10 = 1, 01 = 2 and 11 = 3. Inputs 0 Input image 1. Type: Image4DFloat, Required, Single 1 Input image 2. Type: Image4DFloat, Required, Single 2 Input image 3. Type: Image4DFloat, Required, Single 3 Input image 4. Type: Image4DFloat, Required, Single Bit 0 First bit. Type: Boolean, Required, Single Bit 1 Second bit. Type: Boolean, Required, Single Outputs Out Resulting image. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.flow_control.select.from_four_images.html"},
{"title": "From Two Images", "text": "Select Class: NodeImageSelectTwo Selects an output image from four input images using one bit. Inputs 0 Input image 1. Type: Image4DFloat, Required, Single 1 Input image 2. Type: Image4DFloat, Required, Single Bit Selection bit. Type: Boolean, Required, Single Outputs Out Resulting image. Type: Image4DFloat ", "tags": "", "url": "nodes.image.flow_control.select.from_two_images.html"},
{"title": "Texture Analysis", "text": "Texture Class: NodeTextureAnalyzeGLCM Calculate Haralick Texture Features from a Gray level co-occurrence matrix (GLCM). Inputs GLCM Inputs One or more GLCMs. Type: Image4DFloat, Required, Multiple Outputs Result A data Table containing the resulting texture values. Type: DataCollection Settings Node Dataset Name Text The name or title of the data set. Gray Level Invariant Features Boolean Select if the resulting Haralick texture feature values should be invariant to the number of gray levels in the image. This is described in reference 4. Features Contrast Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Inverse Difference Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Energy Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Entropy Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Maximum Probability Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Correlation Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Sum of Squares: Variance Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Homogeneity Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Dissimilarity Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Sum Average Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Sum Variance Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Sum Entropy Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Difference Variance Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Difference Entropy Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Information Measure of Correlation 1 Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Information Measure of Correlation 2 Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Autoorrelation Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Cluster Shade Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Cluster Prominence Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. Difference Average Boolean If TRUE, this feature is calculated and presented in the resulting Data Table. References Haralick, R. M., Shanmugam, K. &amp; Dinstein, I. Textural Features for Image Classification. IEEE Trans. Syst. Man. Cybern. 3, 610–621 (1973). Soh, L., Tsatsoulis, C. &amp; Member, S. Texture Analysis of SAR Sea Ice Imagery Using Gray Level Co-Occurence Matrices. IEEE Trans. Geosci. Remote Sens. 37, 780–795 (1999). Clausi, D. a. An analysis of co-occurrence texture statistics as a function of grey level quantization. Can. J. Remote Sens. 28, 45–62 (2002). Löfstedt, T., Brynolfsson, P., Asklund, T., Nyholm, T., &amp; Garpebring, A. Gray-level invariant Haralick texture features. PLOS ONE, 14(2) (2019). Keywords: Haralick, texture ", "tags": "", "url": "nodes.image.texture.texture_analysis.html"},
{"title": "Texture GLCM", "text": "Texture GLCM Class: NodeTextureGLCM Generates a 2D gray-level co-occurrence matrix for each direction in one slice orientation of the 3D image. Inputs Input An image. Type: Image4DFloat, Required, Single Mask A mask with the same size as the image, which defines the region in which the GLCMs are calculated. Type: Image4DBool, Optional, Single Outputs Horizontal The resulting GLCM with horizontal neighbors. Type: Image4DFloat Vertical The resulting GLCM with vertical neighbors. Type: Image4DFloat Diagonal Left The resulting GLCM with diagonal left neighbors. Type: Image4DFloat Diagonal Right The resulting GLCM with diagonal right neighbors. Type: Image4DFloat Quantized Image The input image quantized to the number of gray levels. Type: Image4DFloat Settings Node Orientation Selection The orientation of the planes on which the GLCMs are created. X,Y,Z are the first, second and third dimensions of the image matrix volume, and not the physical coordinate directions. Values: XY, XZ, YZ Quantization Bins Integer The number of gray levels in the quantized image, which determines the size of the GLCM. Slicewise max-min Boolean Quantize the image slice by slice, using the min and max in each slice. Use Fixed Window Boolean Use a global min and max value when quantizing the image. Ignore Voxels Outside Window Boolean Ignore Voxels that are smaller or larger than the quantization limits. If this is unchecked, they will be set to the quantization limits. Fixed Window Min Number The lower quantization limit. Fixed Window Max Number The upper quantization limit. References Haralick, R. M., Shanmugam, K. &amp; Dinstein, I. Textural Features for Image Classification. IEEE Trans. Syst. Man. Cybern. 3, 610–621 (1973). See also Keywords: ", "tags": "", "url": "nodes.image.texture.texture_glcm.html"},
{"title": "Texture LBP", "text": "Texture Class: NodeTextureLBP Calculates the 8 bit local binary patterns (LBP) texture measure using the closest 8 neighbors to each pixel. Inputs Input An image. Type: Image4DFloat, Required, Single Mask A mask with the same size as the image, which defines the region where the local binary pattern is calculated. Type: Image4DBool, Optional, Single Outputs LBP Image The LBP image. Type: Image4DFloat Settings Orientation Selection The orientation of the planes on which the LBP are created. X,Y,Z are the first, second and third dimensions of the image matrix volume, and not the physical coordinate directions. Values: XY, XZ, YZ Rotation Invariant Boolean Makes the LBP rotation invariant, by shifting each pattern in steps of one, a full rotation around the ceter voxel. This reduces the number of unique patterns from 256 to 36. Method Selection &ldquo;Less is more&rdquo; sets a bit in the resulting number to 1 if the value of the current neighbour is larger than the voxel value. &quot;More is more&quot; sets a bit in the resulting number to 1 if the value of the current neighbour is smaller than the voxel value. Values: LessIsMore, MoreIsMore References 1. Ojala, T., Pietikainen, M. & Harwood, D. Performance evaluation of texture measures with classification based on Kullback discrimination of distributions. Pattern Recognition, 1994. Vol. 1 - Conf. A Comput. Vis. amp; Image Process. Proc. 12th IAPR Int. Conf. 1, 582–585 vol.1 (1994). See also Keywords: ", "tags": "", "url": "nodes.image.texture.texture_lbp.html"},
{"title": "Noise Image", "text": "Noise Image Class: NodeNoiseImageFilter Calculate the local noise in an image. Computes an image where a given pixel is the standard deviation of the pixels in a neighborhood about the corresponding input pixel. This serves as an estimate of the local noise (or texture) in an image. Currently, this noise estimate assume a piecewise constant image. Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Output The resulting noise image. Type: Image4DFloat Settings Radius Integer The distance from the center where pixels are included when calculating the standard deviation. References Noise image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.texture.noise_image.html"},
{"title": "Grid", "text": "Grid Class: NodeImageToGrid Generates a grid in the attached image space. This can be useful to evaluate registrations and deformation, or to illustrate scale. Example workflows Grid example Inputs Image An image which serves as a reference space for the grid. Type: Image4DFloat, Required, Single Outputs Grid The grid image. Type: Image4DFloat Settings Sigma Number The standard deviation of the low pass filter applied to the grid. Must be larger than 0. Value Number The voxel value in spaces between grid lines. The value in the grid lines is always 0. Offset X (mm) Number Offset in mm of the first grid line in X-direction. Offset can be negative, but the grid is not generated further than the extent of the original image so this is not recommended. Offset Y (mm) Number Offset in mm of the first grid line in Y-direction. Offset can be negative, but the grid is not generated further than the extent of the original image so this is not recommended. Offset Z (mm) Number Offset in mm of the first grid line in Y-direction. Offset can be negative, but the grid is not generated further than the extent of the original image so this is not recommended. Spacing X (mm) Number Spacing in mm between center of grid lines in X-direction. Spacing Y (mm) Number Spacing in mm between center of grid lines in Y-direction. Spacing Z (mm) Number Spacing in mm between center of grid lines in Z-direction. References [GridImageSource on sitk]https://simpleitk.org/doxygen/v2_0/html/classitk_1_1simple_1_1GridImageSource.html) See also Keywords: ", "tags": "", "url": "nodes.image.convert_to.grid.html"},
{"title": "Label Map (Region) Mask", "text": "Label Map To Mask Class: NodeRegionShapeKeep Converts a label map image (i.e. an image with different segmentations, each having a specific intensity) to a Mask by analyzing the shape of each label. A label map can be produced by Label Map (Regions) from a mask. 0 is considered as background. Example workflows Label map example Inputs Label Map The input label image, i.e. an image containing different regions with specific intensities. Type: Image4DFloat, Required, Single Outputs Mask The output mask created by keeping one or several specified label(s). Type: Image4DBool Kept Labels A label map containing only the kept labels. Type: Image4DFloat Settings Number of labels to keep Integer How many labels to keep. Sort By Selection Sets the property to sort the labels by. Values: Elongation, FeretDiameter, Flatness, NumberOfPixels, NumberOfPixelsOnBorder, Perimeter, PerimeterOnBorder, PerimeterOnBorderRatio, PhysicalSize, Roundness Reverse Order Boolean Reverse the sorting order. References LabelIntensityStatisticsImageFilter on sitk See also Keywords: regions, shape ", "tags": "", "url": "nodes.image.convert_to.label_map_(region)_mask.html"},
{"title": "Line Profile", "text": "Line Profile Class: NodeImageLineProfile Extracts a line profile from one dimension in an image. Example workflows Line profile example Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Profile The output plot. Type: CurveCollection Settings Profile Dimension Selection Sets the dimension to create the profile from. Values: X, Y, Z, T Voxel Index X Integer X-Index of the voxel to create the profile from. Y Integer Y-Index of the voxel to create the profile from. Z Integer Z-Index of the voxel to create the profile from. Keywords: plot ", "tags": "", "url": "nodes.image.convert_to.line_profile.html"},
{"title": "Threshold", "text": "Threshold Class: NodeImageToMask Converts an image to a binary Mask using thresholding. Inputs Image The input image. Type: Image4DFloat, Required, Single Outputs Mask The resulting mask. A binary mask with the same size as the input image. Type: Image4DBool Settings Division Level Number This value is used to divide the image into two bins. Depending on what division type you select voxel values above and below this value will be converted into 1 or 0 in the resulting mask. Division Type Selection The type of criteria used to set the resulting mask voxel to 1. Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals See also Keywords: Threshold, Thresholding ", "tags": "", "url": "nodes.image.segmentation.thresholding.threshold.html"},
{"title": "Adaptive Threshold", "text": "Adaptive Threshold Class: NodeImageAdaptiveThreshold Threshold an image using adaptive thresholding. This node calculates a median or mean value in the neighbourhood of each voxel as defined by the kernel radius. The value is multiplied with a threshold criteria and compared with the value of the active voxel, if the voxel value is above or below (depending on polarity) the neighbourhood value of the resulting voxel will be set to TRUE. Example Workflows Adaptive Threshold workflow Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Output A binary mask. Type: Image4DBool Settings Kernel Radius X Integer Radius in the X-direction of the kernel in voxels. Radius Y Integer Radius in the Y-direction of the kernel in voxels. Radius Z Integer Radius in the Z-direction of the kernel in voxels. Threshold Value Type Selection Sets the type of value to be calculated for the kernel. Values: Mean, Median Threshold Criteria Number Sets the relative thershold between the mean/median value of the kernel and the active voxel for it to be set to true. If this value is set to 1.1 the voxel will be true if the voxel value is equal or higher/lower (depending on polarity) than 1.1 times the median/mean value of the kernel voxels. Switch Polarity Boolean If set to true the resulting voxel will be set to true if the voxel value is less or equal to (Criteria * median/mean) value. See also Keywords: ", "tags": "", "url": "nodes.image.segmentation.thresholding.adaptive_threshold.html"},
{"title": "Connected Threshold", "text": "Connected Threshold Class: NodeImageConnectedThreshold Finds voxels that are connected to a seed voxel and lie within a range of values. Two voxels are connected if they share a face, or alternatively an edge or a vertex. A voxel has 6 neighbors with which it shares a face, and 26 neighbors with which it shares a face, an edge or a vertex. Example Workflows Connected threshold Inputs Image The image you wish to apply the threshold to. Type: Image4DFloat, Required, Single Outputs Out The resulting binary mask. Type: Image4DBool Settings Connected Threshold Connectivity Selection Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. Values: Full, Face Seed Seed I Integer X index of the seed voxel. Seed J Integer Y index of the seed voxel. Seed K Integer Z index of the seed voxel. Threshold Lower Threshold Number Lower threshold value. Upper Threshold Number Upper threshold value. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.segmentation.thresholding.connected_threshold.html"},
{"title": "Otsu  Thresholding", "text": "Otsu Class: NodeOtsuThreshold Converts an image to a binary Mask using otsu thresholding. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Mask The resulting mask. A binary mask with the same size as the input image. Type: Image4DBool References Otsu thresholding in SimpleITK See also Keywords: Threshold, Thresholding, Otsu ", "tags": "", "url": "nodes.image.segmentation.thresholding.otsu__thresholding.html"},
{"title": "Otsu Multi Thresholding", "text": "Otsu Multi Class: NodeOtsuMulti Threshold an image using multiple Otsu Thresholds. This node creates a label map that separates the input image a set number of classes. The number of histogram bins and number of thresholds can be defined in the node settings. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Output label map. Type: Image4DFloat Thresholds Output resulting thresholds in a data table. Type: DataCollection Settings Number of Thresholds Integer Set the number of thresholds. Number of Bins Integer Set the number of histogram bins. Label Offset Integer Set the offset which labels start from. References Otsu multiple threshold in SimpleITK Description of Otsu's method on Wikipedia Keywords: ", "tags": "", "url": "nodes.image.segmentation.thresholding.otsu_multi_thresholding.html"},
{"title": "Gradient Magnitude", "text": "Gradient Magnitude Class: NodeGradientMagnitude Computes the gradient magnitude of an image region at each pixel. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Use Image Spacing Boolean Set whether or not the filter will use the spacing of the input image in its calculations. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.segmentation.edge_detection.gradient_magnitude.html"},
{"title": "Gradient Magnitude Recursive Gaussian", "text": "Gradient Magnitude Class: NodeGradientMagnitudeRecursiveGaussian Computes the magnitude of the gradient of an image by convolution with the first derivative of a Gaussian. Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Output An image with the same size as the input image, where the voxel values represent the gaussian gradient magnitude. Type: Image4DFloat Settings Sigma Number Set Sigma value. Sigma is measured in the units of image spacing. References Gradient-magnitude recursive gaussian image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.segmentation.edge_detection.gradient_magnitude_recursive_gaussian.html"},
{"title": "Canny Edge Detection", "text": "Edge Detection Class: NodeCannyFilter Based on John Canny's paper &ldquo;A Computational Approach to Edge Detection&rdquo;(IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. PAMI-8, No.6, November 1986), there are four major steps used in the edge-detection scheme: (1) Smooth the input image with Gaussian filter. (2) Calculate the second directional derivatives of the smoothed image. (3) Non-Maximum Suppression: the zero-crossings of 2nd derivative are found, and the sign of third derivative is used to find the correct extrema. (4) The hysteresis thresholding is applied to the gradient magnitude (multiplied with zero-crossings) of the smoothed image to find and link edges. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Lower Threshold Number Define the lower threshold for detection edges. Upper Threshold Number Define the upper threshold for detection edges. Variance Number Set the variance of the Gaussian smoothing filter. Maximum Error Number Set the MaximumError parameter used by the Gaussian smoothing filter in this algorithm. References Canny edge detection in SimpleITK Keywords: Canny, edge, edge-detection ", "tags": "", "url": "nodes.image.segmentation.edge_detection.canny_edge_detection.html"},
{"title": "Sobel", "text": "Sobel Class: NodeSobelFilter Edge detection using the Sobel operator. This filter uses the Sobel operator to calculate the image gradient and then finds the magnitude of this gradient vector. The Sobel gradient magnitude (square-root sum of squares) is an indication of edge strength. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.segmentation.edge_detection.sobel.html"},
{"title": "Geodesic Active Contour Level Set", "text": "Geodesic Segmentation Class: NodeImageGeodesicSegmentation Segments structures in images based on a user supplied edge potential map. An initial contour is propagated outwards (or inwards) until it &ldquo;sticks&rdquo; to the shape boundaries. This is done by using a level set speed function based on a user supplied edge potential map.This filter requires two inputs. The first input is a initial level set. The initial level set is a real image which contains the initial contour/surface as the zero level set. For example, a signed distance function from the initial contour/surface is typically used (see e.g. Maurer Distance). The initial contour does not have to lie wholly within the shape to be segmented. The initial contour is allow to overlap the shape boundary. The extra advection term in the update equation behaves like a doublet and attracts the contour to the boundary. This approach for segmentation follows that of Caselles et al. The second input is the feature image. For this filter, this is the edge potential map. General characteristics of an edge potential map is that it has values close to zero in regions near the edges and values close to one inside the shape itself. Typically, the edge potential map is computed from the image gradient. Example Workflows Geodesic segmentation example Inputs Initial Level Set The initial level set. Type: Image4DFloat, Required, Single Edge Potential Edge potential map. Edges should be ~0 and ~1 elsewhere. Type: Image4DFloat, Required, Single Outputs Output Output map. To produce a segmentation, this map needs to be thresholded. Negative values in the output image represent the inside of the segmented region and positive values in the image represent the outside of the segmented region. The zero crossings of the image correspond to the position of the propagating front. Type: Image4DFloat Settings Advection Scaling Number An advection term \(\mathbf{A}(\mathbf{x})\) is constructed from the negative gradient of the edge potential image. \(\mathbf{A}(\mathbf{x}) = -\nabla g(\mathbf{x})\) This term behaves like a doublet attracting the contour to the edges. Curvature Scaling Number In general, the larger the curvature scaling, the smoother the resulting contour. Propagation Scaling Number Sets the inflation force, i.e. higher value gives faster propagation. Maximum RMS Error Number This parameter is used to determine when the solution has converged. A lower value will result in a tighter-fitting solution, but will require more computations. Too low a value could put the solver into an infinite loop unless a reasonable NumberOfIterations parameter is set. Values should always be greater than 0.0 and less than 1.0. Reverse Expansion Direction Boolean Reverses from expansion to contraction, or vice versa. Iterations Integer Set the number of iterations. References &ldquo;Geodesic Active Contours&rdquo;, V. Caselles, R. Kimmel and G. Sapiro. International Journal on Computer Vision, Vol 22, No. 1, pp 61-97, 1997 &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: segmentation, active contours, snakes ", "tags": "", "url": "nodes.image.segmentation.level_set.geodesic_active_contour_level_set.html"},
{"title": "Scalar Chan Vese Dense Level Set", "text": "Chan &amp; Vese Class: NodeChanVeseSegmentation The Chan-Vese segmentation algorithm is designed to segment objects without clearly defined boundaries. This algorithm is based on level sets that are evolved iteratively to minimize an energy, which is defined by weighted values corresponding to the sum of differences intensity from the average value outside the segmented region, the sum of differences from the average value inside the segmented region, and a term which is dependent on the length of the boundary of the segmented region. Typical values for \(\lambda_1\) and \(\lambda_2\) are 1. If the ‘background’ is very different from the segmented object in terms of distribution (for example, a uniform black image with figures of varying intensity), then these values should be different from each other. This algorithm was first proposed by Tony Chan and Luminita Vese, in a publication entitled “An Active Contour Model Without Edges”, see 1. Example Workflows Chan Vese segmentation example Inputs Initial Level Set The initial level set from which to start. Type: Image4DFloat, Required, Single Image The image to be segmented. Type: Image4DFloat, Required, Single Outputs Output The segmented image. Type: Image4DFloat Settings Area Weight Number Area regularization values. Curvature Weight Number Scales all curvature weight values. Epsilon Number Width of regularization of Heaviside function. Lambda 1 Number Internal intensity difference weight. Lambda 2 Number External intensity difference weight. Reinitialization Smoothing Weight Number Weight of the laplacian smoothing term. Volume Number Volume. Volume Matching Weight Number Volume matching weight. Use Image Spacing Boolean Set whether or not the filter will use the spacing of the input image in its calculations. Maximum RMS Error Number Value of RMS change below which the filter should stop. This is a convergence criterion. Iterations Integer Set the number of iterations. References 1. %22An active contour model without edges%22 T.Chan and L.Vese.In Scale - Space Theories in Computer Vision, pages 141 - 151, 1999. 2. %22Cell Tracking using Coupled Active Surfaces for Nuclei and Membranes%22 http://www.insight-journal.org/browse/publication/642 https://hdl.handle.net/10380/3055 3. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.segmentation.level_set.scalar_chan_vese_dense_level_set.html"},
{"title": "Fast Marching", "text": "Fast Marching# Fast Marching Class: NodeFastMarching The fast marching method is a simple form of level-set evolution where only a positive speed term is used to govern the differential equation. The resulting level-set contour only grows over time. Practically, this algorithm can be used as an advanced region growing segmentation which is controlled by a speed image. A good propagation speed image for segmentation is close to zero near object boundaries and relatively high in between. The fast marching filter is initiated with an seed point or mask, which generates trial points. The trial points are the starting location of the level-set. The output of the fast marching filter is a time-crossing map that indicate the time of arrival of the propagated level-set front. Example Workflows Fast Marching example Inputs Speed Image The speed image should have values ~0 close to edges and relativly high inbetween. Usually a gradient magnitude filter followed by a sigmoid filter are appropriate. Type: Image4DFloat, Required, Single Seed Mask The seed mask describes the initial level set. Type: Image4DBool, Optional, Single Outputs Output The time crossing map produced by the fast marching filter. By thresholding the time-crossing map, different segmentations can be produced. Type: Image4DFloat Settings Settings Stopping Value Number The algorithm can be terminated early by setting an appropriate stopping value. The algorithm terminates when the current arrival time being processed is greater than the stopping value. Seed Seed Voxel X Integer Seed voxel X position. Seed Voxel Y Integer Seed voxel Y position. Seed Voxel Z Integer Seed voxel Z position. Result Set Infinity To Number If the algorithm is stopped early, voxels which have not been reached by the fast marching front will have value Inf. This can be difficult to visualise, therefore choose an appropriate value to be assigned to Inf voxels. References 1. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.segmentation.level_set.fast_marching.html"},
{"title": "Watershed", "text": "Watershed Class: NodeImageWatershedSegmentation Watershed segmentation implementation with morphogical operators. Intuitively, watershed segmentation views the image as a landscape, where each pixel value defines the &ldquo;height&rdquo; of the ground at that point. The watershed segmentation fills the lanscape with water, and each pool or basin gets its own label. As the water rises, the entire image is divided into a number of pools. The figure illustrates the intuitive concept of how the watershed algorithm works in a line profile of an image. Initial pools are created at the staring level of the water, and new pools are created as the water rises. Example Workflows Watershed example Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Out A labelmap, where each intensity label represent one pool. Type: Image4DFloat Settings Fully Connected Boolean Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. For objects that are 1 pixel wide, use FullyConnectedOn. Level Number Set the starting level of the segmentation. Lines Enabled Boolean Sets whether the watershed pixel must be marked or not. Default is true. Set it to false do not only avoid writing watershed pixels, it also decrease algorithm complexity. References Morphological watershed in SimpleITK Chapter 9.2 in &ldquo;Morphological Image Analysis: Principles and Applications&rdquo;, Second Edition, Springer, 2003, Pierre Soille The watershed transform in ITK - discussion and new developments ", "tags": "", "url": "nodes.image.segmentation.watershed.html"},
{"title": "K-Means", "text": "K-Means Class: NodeKMeansFilter Classify the intensity values using the K-Means algorithm. This method assigns each voxel a cluster (i.e. label) such that the within-label variance is minimized. This node is useful when the number of clusters are known beforehand, such as classifying CT intensities to Air, Tissue and Bone. Example Workflows K-Means clustering Inputs Image Image to be segmented. Type: Image4DFloat, Required, Single Outputs Output Label map of the same size as the input image. Type: Image4DFloat Settings Use Non Contiguous Labels Boolean When set to FALSE, the labels are numbered contiguously: {0,1,2..N}. When set to TRUE, the labels are selected in order to span the dynamic range of the output image. Classes Text Initial mean of each class, specified as a comma separated list of numbers. References ScalarImageKmeansImageFilter in SimpleITK K-means clustering on Wikipedia ", "tags": "", "url": "nodes.image.segmentation.k-means.html"},
{"title": "Elastix Registration", "text": "Elastix Class: NodeElastixProcessor Uses elastix to register images using specified parameters. It requires at least one fixed and one moving image as input, and will output the moving image registered and resampled to the fixed image coordinate system.The default registration method is rigid multimodal registration using mutual information. To change it, click the Edit Parameters button in the node settings panel. The parameters are saved with the Registration (Elastix) node in the workflow (.ice-file). Parameters can also be imported from a .txt file from within the Parameter editor.For more information about elastix, visit their homepage at http://elastix.isi.uu.nl. Example workflows Elastix rigid registration Elastix affine registration Elastix deformable registration Elastix deformable registration with guiding structures Elastix partially rigid registration Inputs Fixed The fixed input image to register to. Type: Image4DFloat, Required, Single Moving 1 The moving input image that will be registered. Type: Image4DFloat, Required, Single Outputs Out 1 The registered moving image. Type: Image4DFloat Settings Input Number of Moving Images Integer Specifies the number of moving images to be registered to one or more fixed images. Use Initial Transform Boolean Input an initial transform (Transformix Parameter data type) that is applied to the moving image before registration starts. Use Fixed Masks Boolean Creates input(s) for fixed mask(s). If used, the sampler draws the required number of samples from within the valid region of the fixed image. Use Moving Masks Boolean Creates input(s) for moving mask(s). If used, the sampler will discard any samples drawn from outside the valid region of the moving image. Use Multiple Fixed Images Boolean Register all moving images to separate fixed images. Number of Auxiliary Images Integer Sets the number of auxiliary images. To use them enter the name of the auxiliary image into your parameters file. Output Multi Metric Boolean Use this option to register a set of moving and fixed images using different metrics simultaneously. A metric need to be specified for each set of images. Transformix Transforms Boolean Creates an output for the Transformix Parameters of the resulting registration. Output Affine Transforms Boolean Creates an output for affine transforms. This is a Data data type output, which gives the augmented affine transformation matrix, as well as the Euler angles. Time Series Registration Fixed Image Type Selection &ldquo;TimeSeries&rdquo; will register each time frame of the moving images to the corresponding frame of the fixed images, while &quot;FixedFrame&quot; will only register to the first frame of the fixed images. Values: TimeSeries, FixedFrame Frame to Register Integer For registration type &ldquo;TimeSeries&rdquo; select the frame to register to. Starts with 1. Parameters Use Parameter File Text Input the path of the parameter file to use. Parameters Text Parameters for the registration. Processing 2D/2D Registration Boolean If set the images will be treated as having two dimensions. This is uesful when trying to register single slice images.Note: For this to work you need to change FixedImageDimension and MovingImageDimension to 2 in your parameters. Z position and rotation of all images will be discarded. Single Thread Boolean If selected only one instance of elastix will be used by this node. References 1. S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, %22elastix: a toolbox for intensity based medical image registration%22, IEEE Transactions on Medical Imaging, vol. 29, no. 1, pp. 196 - 205, January 2010. 2. D.P. Shamonin, E.E. Bron, B.P.F. Lelieveldt, M. Smits, S. Klein and M. Staring, %22Fast Parallel Image Registration on CPU and GPU for Diagnostic Classification of Alzheimer’s Disease%22, Frontiers in Neuroinformatics, vol. 7, no. 50, pp. 1-15, January 2014. See also Keywords: ", "tags": "", "url": "nodes.image.registration.register.elastix_registration.html"},
{"title": "Demons Registration", "text": "Demons Registration Class: NodeRegistrationDemons The classic demons algorithm will register two images by computing the displacement field which will map a moving image onto a fixed image. It is quite fast, but only works for mono-modal images. For details regarding the itkDemons filter, look at the sitk class and their use example. You can also review the paper by Pennec et al. Example workflows Demons registration example Inputs Fixed The fixed image. Type: Image4DFloat, Required, Single Moving The image to be registered. Should have the same intensity distribution as the fixed, i.e. the same modality. If there are differences in intensity distribution, pre-processing by histogram matching can be helpful in some cases. Type: Image4DFloat, Required, Single Outputs Out The displacement field which aligns the moving image to the fixed. Type: Image4DVector3 Settings Intensity Difference Threshold Number Set the threshold below which the absolute difference of intensity yields a match. When the intensities match between a moving and fixed image pixel, the update vector (for that iteration) will be the zero vector. Maximum Error Number Set the desired maximum error of the Guassian kernel approximate. Maximum RMS Error Number The Root Mean Square of the levelset upon termination. Maximum Kernel Width Integer Set the desired limits of the Gaussian kernel width. Standard Deviation X Number Set the Gaussian smoothing standard deviation in X-direction for the displacement field. The values are set with respect to pixel coordinates. Standard Deviation Y Number Set the Gaussian smoothing standard deviation in Y-direction for the displacement field. The values are set with respect to pixel coordinates. Standard Deviation Z Number Set the Gaussian smoothing standard deviation in Z-direction for the displacement field. The values are set with respect to pixel coordinates. Update Field Standard Deviation X Number Set the Gaussian smoothing standard deviation in X-direction for the update field. The values are set with respect to pixel coordinates. Update Field Standard Deviation Y Number Set the Gaussian smoothing standard deviation in Y-direction for the update field. The values are set with respect to pixel coordinates. Update Field Standard Deviation Z Number Set the Gaussian smoothing standard deviation in Z-direction for the update field. The values are set with respect to pixel coordinates. Use Image Spacing Boolean Set the value of UseImageSpacing to true or false respectfully. Use Moving Image Gradient Boolean Switch between using the fixed image and moving image gradient for computing the displacement field updates. Smooth Displacement Field Boolean Set whether the displacement field is smoothed (regularized). Smoothing the displacement yields a solution elastic in nature. If Smooth Displacement Field is on, then the displacement field is smoothed with a Gaussian whose standard deviations are specified with Standard Deviation X, Y, Z Smooth Update Field Boolean Set whether the update field is smoothed (regularized). Smoothing the update field yields a solution viscous in nature. If Smooth Update Field is on, then the update field is smoothed with a Gaussian whose standard deviations are specified with Update Field Standard Deviation X, Y, Z. Number of Iterations Integer Number of iterations run. References DemonsRegistrationFilter on sitk Use example on sitk Paper by Pennec et al See also Keywords: Deformable, non-rigid, mono-modal ", "tags": "", "url": "nodes.image.registration.register.demons_registration.html"},
{"title": "Optical Flow Registration", "text": "Optical Flow Class: NodeImageOpticalFlow Registers two images from the same modality, i.e. their intensity distributions need to be similar. Images need to lie in the same coordinate system and be of the same size. Moving input image can be a time series in which case each consecutive image is individually registered against the fixed image. Since optical flow only handles small movements a pyramid approach is implemented for handling large motions. The user specifies the downsampling steps, i.e. the number of pyramid levels, and a joint downsampling factor. Gaussian smoothing is also applied for each downsampling step as well as median filtering of the displacement between each step. The user can choose to stop the registration at the next highest resolution level, both to save time and possibly to avoid inaccuracies due to noise in the images. Alpha is the factor controlling the smoothness of the registration. A higher alpha value gives a smoother displacement, its square should be set roughly to the noise level in the images. Since the images are not normalized in the process the alpha is with respect to voxelvalues in the images. Output is the resulting images and the displacement fields. Example workflows Optical flow registration example Inputs Fixed The fixed image. Type: Image4DFloat, Required, Single Moving The moving image to be registered. Must be in the same coordinate system and of the same size as the fixed image, i.e. perform a rigid registration first if necessary. Type: Image4DFloat, Required, Single Outputs Deformation The deformation field. Type: Image4DVector3 Result The registered moving image. Type: Image4DFloat Settings Alpha Number Alpha value in registration that controls the smoothness. Iterations Integer Set number of iterations to run. Downsampling Steps Integer Set number of downsampling steps. Downsampling Factor Number Set downsampling factor. Stop at Next Highest Resolution Level Boolean Set stop at next highest resolution level. References Horn, B., Schunck, B. (1981). “Determining optical flow.” Sun, D. (2010). “Secrets of Optical Flow Estimation and Their Principles.” See also Keywords: deformable, non-rigid ", "tags": "", "url": "nodes.image.registration.register.optical_flow_registration.html"},
{"title": "Apply Elastix Transform", "text": "Transformix Class: NodeTransformixProcessor Uses Transformix to transform the input image(s) according to the parameters supplied in the Transformix Parameters data type input. For more information about elastix and transformix, see the elastix manual. Example workflows Transformix example Inputs Transformix The transformix parameters to be applied. Type: TransformixParameter, Required, Single Image 1 The image to be transformed. Type: Image4DFloat, Required, Single Outputs Out 1 The transformed image. Type: Image4DFloat Settings Input Number of Moving Images Integer Specifies the number of images to be transformed. Number of Transforms Integer Specifies the number of transforms applied starting from Transformix 1. Use Resample Reference Boolean Resample the output data to a different coordinate system than supplied in the Transformix Parameter file. Transformix Ignore Existing Initial Transform Boolean Ignores the initial transform specified in the parameters file. Time Series Registration Per Frame Transform Boolean If set the node will use one transformix per frame if available, by default only the first transformix frame will be used. If there is not enough transformix frames to match the moving data the last transformix will be used for the last frames. Custom Settings Use Custom Settings Boolean Select to apply custom settings to the transform. Default Pixel Value Number Set the default pixel value. Final B-Spline Interpolation Order Integer Set the order of the b-spline interpolation of the image. References S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, 2010. &ldquo;elastix: a toolbox for intensity based medical image registration&rdquo; See also Keywords: registration ", "tags": "", "url": "nodes.image.registration.transform.apply_elastix_transform.html"},
{"title": "Apply DICOM Transform (DICOM REG)", "text": "Apply Registration Class: NodeRegistrationPreDefined Applies the transform specified in a DICOM REG file. It can only be applied between the two Frame of reference UIDs specified in the file. It requires one fixed, one moving image and a Registration data type input, and will output the moving image registered and resampled to the fixed image coordinate system. Inputs Fixed Image The fixed image. Type: Image4DFloat, Required, Single Moving Image The moving image to be registered. Type: Image4DFloat, Required, Single Registration The DICOM registration. Type: RegistrationCollection, Required, Single Outputs Out The registered image. Type: Image4DFloat Settings Interpolator Selection Specifies which interpolator should be used to resample the moving image. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc Matrix Type Selection Specifies the matrix type of the registration to use, can be RIGID, RIGID_SCALE or AFFINE. Values: RIGID, RIGID_SCALE, AFFINE Matrix Type Code Selection Selects which registration should be applied based on the DICOM-tag (0008,0104) CodeMeaning. Values: ImageContentBased, Fiducial, Visual, AcquisitionEquipment, FrameOfReferenceIdentity, Unknown Set new frame of reference Boolean Changes the MICE specific Frame of reference tag of the input image to that of the reference image. This is the default setting and is recommended in most applications. Default Voxel Value Number Value assigned to extrapolated voxels. See also Keywords: ", "tags": "", "url": "nodes.image.registration.transform.apply_dicom_transform_(dicom_reg).html"},
{"title": "Invert Elastix Transform", "text": "Inverse Class: NodeInverseTransform Calculates the inverse transform of the connected transformix transform. Currently only linear transforms are supported (translation, rigid, affine). To specify the new image space a reference image must be used. Inputs Transform The transformix parameters to be applied. Type: TransformixParameter, Required, Single Reference Reference image to use when setting the new image space. If this is not used the resulting images will use the image space of the original transform. Type: Image4DFloat, Optional, Single Outputs Inverse The inverse transformix transform. Type: TransformixParameter References S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, 2010. &ldquo;elastix: a toolbox for intensity based medical image registration&rdquo; &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.registration.transform.invert_elastix_transform.html"},
{"title": "Set Position", "text": "Position Class: NodeImagePosition Change the position of the input image, either to a manually defined position or to the position of a reference image. It will not affect the pixel data of the image, only the metadata of the image object. Example Workflows Transformation examples Inputs Image 1 An image. Type: Image4DFloat, Required, Single Outputs Out 1 The same image with a new position. Type: Image4DFloat Settings Input Number of Images Integer Specifies the number of input images to change position on. Use Reference Image Boolean Adds an input for a reference image. The position of the reference image will be copied to all input images. Manual Position Position X (mm) Number Defines the physical coordinate of the center of the top left voxel in the image stack in the x-direction. Position Y (mm) Number Defines the physical coordinate of the center of the top left voxel in the image stack in the y-direction. Position Z (mm) Number Defines the physical coordinate of the center of the top left voxel in the image stack in the z-direction. See also Keywords: ", "tags": "", "url": "nodes.image.transform.set_position.html"},
{"title": "Set Voxel Size", "text": "Voxel Size Class: NodeImageVoxelSize Change the voxel size of the input image in the metadata of the image object, either to a manually defined voxel size or to the voxel size of a reference image. This will not affect the pixel data of the image. Example Workflows Transformation examples Inputs Image 1 An image. Type: Image4DFloat, Required, Single Outputs Out 1 The same image with a new voxel size. Type: Image4DFloat Settings Input Number of Images Integer Specifies the number of input images to change voxel size on. Use Reference Image Boolean Adds an input for a reference image. The voxel size of the reference image will be copied to all input images. Voxel Size Voxel Size X Number Defines the physical voxel size in the x-direction. Voxel Size Y Number Defines the physical voxel size in the y-direction. Voxel Size Z Number Defines the physical voxel size in the z-direction. See also Keywords: ", "tags": "", "url": "nodes.image.transform.set_voxel_size.html"},
{"title": "Set Orientation", "text": "Orientation Class: NodeImageOrientation Change the orientation (i.e. the rotation matrix) of the input image to that of a reference image. This will not affect the pixel data of the image. Example Workflows Transformation examples Inputs Reference An image from where the rotation matrix is copied. Type: Image4DFloat, Required, Single Image The image where the rotation matrix will be changed. Type: Image4DFloat, Required, Single Outputs Out The same image with a new rotation matrix. Type: Image4DFloat See also Keywords: ", "tags": "", "url": "nodes.image.transform.set_orientation.html"},
{"title": "Translate", "text": "Translate Class: NodeImageTranslate Translate the input image by either a specified distance or to a position relative to a reference image. This will not affect the pixel data of the image. Example Workflows Transformation examples Inputs Image 1 An image. Type: Image4DFloat, Required, Single Outputs Out 1 The same image with a new position. Type: Image4DFloat Settings Input Number of Images Integer Specifies the number of input images to change position on. Use Reference Image Boolean If set the image will be translated to a position relative to a reference image Reference Translate Type Selection &ldquo;Origin To Origin&rdquo; will move the input image origin (top left voxel) to the origin of the reference image. &quot;Center To Center&quot; will move the input image center to the center of the reference image. Values: OriginToOrigin, CenterToCenter Manual Translation Translate X (mm) Number Size of translation in the x-direction. Translate Y (mm) Number Size of translation in the y-direction. Translate Z (mm) Number Size of translation in the z-direction. See also Keywords: ", "tags": "", "url": "nodes.image.transform.translate.html"},
{"title": "Resample To Reference", "text": "Resample Class: NodeResampleImageFilter Resample the image data from an input image to the coordinates, resolution and orientation of a reference image. This will affect the pixel data of the input image. Example Workflows Transformation examples Inputs Reference The image frame of reference to be used. Type: Image4DFloat, Required, Single Input An image. Type: Image4DFloat, Required, Single Outputs Output An image with the same position, voxel size and orientation as the reference, with the resampled pixel data from the input image. Type: Image4DFloat Settings Interpolator Selection Specifies which interpolation method should be used for the resampling. The default interpolator is the Linear interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc Set new frame of reference Boolean Changes the MICE specific Frame of reference tag of the input image to that of the reference image. This is the default setting and is recommended in most applications. Default Voxel Value Number Value assigned to extrapolated voxels, i.e. voxels not present in the input image. References Resample image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.transform.resample_to_reference.html"},
{"title": "Change Voxel Size", "text": "Resolution Class: NodeResampleImageResolution Resample the input image to a new resolution, using a user specified voxel size. This will affect the pixel data of the input image. Example Workflows Transformation examples Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Out The resampled input image with a new resolution. Type: Image4DFloat Settings Voxel Size New Voxel Size X (mm) Number Defines the physical voxel size in the x-direction. New Voxel Size Y (mm) Number Defines the physical voxel size in the y-direction. New Voxel Size Z (mm) Number Defines the physical voxel size in the z-direction. Node Interpolator Selection Specifies which interpolation method should be used for the resampling. Default is Linear interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References Resample image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.transform.change_voxel_size.html"},
{"title": "Change Matrix Size", "text": "Matrix Class: NodeResampleMatrix Change matrix size will resample the input image to a new, user specified matrix size. It will affect the pixel data of the input image. Inputs Image An image. Type: Image4DFloat, Required, Single Outputs Out The resampled input image with a new matrix size. Type: Image4DFloat Settings Matrix Size New Matrix Size X Integer Defines the number of voxels in the x-direction. New Matrix Size Y Integer Defines the number of voxels in the y-direction. New Matrix Size Z Integer Defines the number of voxels in the z-direction. Node Interpolator Selection Specifies which interpolation method should be used for the resampling. Default is Linear interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References 1. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.transform.change_matrix_size.html"},
{"title": "Deform Using Vector Field", "text": "Deform Class: NodeImageDeformVectorField Deform an image using a supplied vector field. A vector field is an image with three components, which describes the displacement of each point in x, y and z directions. Each vector represent the distance between a geometric point in the input image and the corresponding point in the output image. The resulting image is created using inverse mapping; the pixels in the output image are mapped back onto the input image. This means a displacement of e.g. 10 mm in the x direction of the deformation vector field results in a shift of -10 mm of the output image for that position. Like other medical images, vector fields have a resolution, orientation and a position in space. A vector field does NOT have to have the same matrix size, position, orientation or resolution as the input image, the positions of the vectors and image voxels are interpolated when the deformation occurs. Where the vector field is not defined, no deformation occurs. This is illustrated in the figures below. The left figure shows a vector field, which displaces points diagonally with varying magnitude. The right figure shows the result of applying this deformation vector field on an image. The outline of the vector field is also shown. These images are the result of the first example workflow. Example Workflows Create and apply a deformation vector field Advanced application of deformation vector field Inputs Image An image. Type: Image4DFloat, Required, Single Vector A vector field. Type: Image4DVector3, Required, Single Outputs Output An image with the same size as the input image. Type: Image4DFloat Settings Interpolator Selection Specifies which interpolation method should be used for the resampling. Default is BSpline interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References Warp Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.transform.deform_using_vector_field.html"},
{"title": "Extract Frames", "text": "Extract Frames Class: NodeExtractFrames Extracts frames from a time series to create a shorter time series or a single time frame (3D image). Example Workflows Reshape examples Inputs Time Series An image with at least two frames. Type: Image4DFloat, Required, Single Outputs Out An image with the user defined frames remaining. Type: Image4DFloat Settings Data Image Type Selection The type of image to visualize. Values: Mask, Image, Complex Extract Frames Start Frame Integer Selects the first time frame to be included in the output. Must be larger than zero and smaller than or equal to the end frame End Frame Integer Selects the final time frame to be included in the output. Must be larger or equal to the start frame. If its larger than the size of the time series, end frame will be set to the final frame of the input time series. See also Keywords: ", "tags": "", "url": "nodes.image.reshape.extract_frames.html"},
{"title": "Extract Slices", "text": "Extract Slices Class: NodeExtractSlices Extracts slices from an image to create an image with fewer slices. Example Workflows Reshape examples Inputs In An image with at least two slices. Type: Image4DFloat, Required, Single Outputs Out An image with a subset of slices from the input image. Type: Image4DFloat Settings Data Image Type Selection The type of image to extract slices from. Values: Mask, Image, Complex Extract Slices Orientation Selection Specifies the orientation of slices. E.g. if slice orientation is XY, slice extraction will be in the z-direction. Values: XY, XZ, YZ End Slice Integer Selects the last slice to be included in the output. If the start slice is larger than the end slice the end slice will be used as start slice. If its larger than the size of stack it will be set to the final slice of the input stack. Start Slice Integer Selects the first slice to be included in the output. If the start slice is larger than the end slice the end slice will be used as start slice. If its larger than the size of stack it will be set to the final slice of the input stack. See also Keywords: ", "tags": "", "url": "nodes.image.reshape.extract_slices.html"},
{"title": "Merge Frames", "text": "Merge Frames Class: NodeTimeMean Merge a time series into a single 3D image by averaging over time, maximum intensity projection of minimum intensity projection. Example Workflows Reshape examples Inputs Time Series An image with at least two frames. Type: Image4DFloat, Required, Single Outputs Mean An image with one frame, where intensity in each voxel is the average value of that voxel in the time series. Type: Image4DFloat MIP An image with one frame, where intensity in each voxel is maximum value of that voxel in the time series. Type: Image4DFloat MinIP An image with one frame, where intensity in each voxel is minimum value of that voxel in the time series. Type: Image4DFloat Settings Image Type Selection The type of input image. Values: Mask, Image, Complex See also Keywords: ", "tags": "", "url": "nodes.image.reshape.merge_frames.html"},
{"title": "Projection", "text": "Projection Class: NodeProjectionParallel Orthogonally projects a slice stack into a single slice in the x, y and z-directions. The resulting images are the average, minimum or maximum of all voxel in the specified direction. Example Workflows Reshape examples Inputs Image An image. Type: Image4DFloat, Required, Single Outputs X A projected single slice in the YZ plane. Type: Image4DFloat Y A projected single slice in the XZ plane. Type: Image4DFloat Z A projected single slice in the XY plane. Type: Image4DFloat Settings Data Image Type Selection The type of image to visualize. Values: Mask, Image, Complex Projection Projection Method Selection Specifies the projection method, either average, maximum or minimum intensity projection. Values: Min, Max, Average See also Keywords: ", "tags": "", "url": "nodes.image.reshape.projection.html"},
{"title": "Image Paste", "text": "Image Paste Class: NodeImagePaste Paste multiple images into a single image. The output image covers the bounding box of all input images combined, with the resolution of the first input image. All images will be resampled to the output matrix space using linear interpolation. Example Workflows Reshape examples Inputs Paste At least two input images, to be pasted. Type: Image4DFloat, Required, Multiple Outputs Out An image covering the extent of all input images, with the resolution of the first connected input image. Type: Image4DFloat Settings Data Image Type Selection The type of image to paste. Values: Image, Complex Paste Use Overlap Average Boolean In case of overlapping information in two or more image stacks, this option specifies if the information should be averaged instead of added. Overlap Norm Threshold Number This option specifies what should constitute information content in images. The maximum pixel value in an image series is 1 and the minimum is 0, and averaging overlapping information will only be performed over this threshold. See also Keywords: ", "tags": "", "url": "nodes.image.reshape.image_paste.html"},
{"title": "Pad", "text": "Pad Class: NodeImagePad Increase the matrix size of the input image be a specified amount. Example Workflows Reshape examples Inputs In The input image. Type: Image4DFloat, Required, Single Outputs Out The padded image. Type: Image4DFloat Settings Data Image Type Selection The type of image to pad. Values: Mask, Image, Complex Pad Padding Type Selection The type of padding to use. Wrap and Mirror increases the image size by padding with replicants of the input image value. Wrap by repeating the opposide side of the image, and Mirror by repeating the same side of the image. Values: Constant, Mirror, Wrap Pad Value Number If constant: the pixel value assigned to the padding. X Lower Integer Number of voxels that will be added before current lower bound in x-direction. Y Lower Integer Number of voxels that will be added before current lower bound in y-direction. Z Lower Integer Number of voxels that will be added before current lower bound in z-direction. X Upper Integer Number of voxels that will be added after current upper bound in x-direction. Y Upper Integer Number of voxels that will be added after current upper bound in y-direction. Z Upper Integer Number of voxels that will be added after current upper bound in z-direction. References 1. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.reshape.pad.html"},
{"title": "Flip Axes", "text": "Flip Class: NodeImageFlip Flip an image across user specified axes. Example Workflows Reshape examples Inputs In An image. Type: Image4DFloat, Required, Single Outputs Out The image with flipped a image matrix in the specified directions. Type: Image4DFloat Settings Data Image Type Selection The type of image to flip. Values: Mask, Image, Complex Flip Flip About Origin Boolean Controls how the output origin is computed. If set the flip will occur about the origin of the axis, otherwise, the flip will occur about the center of the axis. Flip X-Axis Boolean Flips the X-Axis. Flip Y-Axis Boolean Flips the Y-Axis. Flip Z-Axis Boolean Flips the Z-Axis. References Flip Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.reshape.flip_axes.html"},
{"title": "Permute Axes", "text": "Permute Axes Class: NodePermuteAxes Permutes the image axes according to a user specified order. The output image information (spacing, orientation) is computed by permuting the corresponding input meta information. Example Workflows Reshape examples Inputs In An image. Type: Image4DFloat, Required, Single Outputs Out The input image with permutet axes. Type: Image4DFloat Settings Data Image Type Selection The type of input image. Values: Mask, Image, Complex New First Axis Integer Sets the new first axis. New Second Axis Integer Sets the new second axis. New Third Axis Integer Sets the new third axis. References Permute Axes Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.image.reshape.permute_axes.html"},
{"title": "Create Stack", "text": "Create Stack Class: NodeImageCreateStack Stack multiple images in the slice direction. Example Workflows Reshape examples Inputs Slice 1 The first image in the stack. Type: Image4DFloat, Required, Single Outputs Stack All images, stacked in the z direction. Type: Image4DFloat Settings Data Image Type Selection The type of input image. Values: Mask, Image, Complex Input Number of Images Integer Specifies the number of input images to create stack from. Slice Thickness Slice Thickness Number Specifies the thickness of the slices in the stack. Use First Slice Thickness Boolean If selected, slice thickness will be set to the thickness of the first slice (input Slice 1). See also Keywords: ", "tags": "", "url": "nodes.image.reshape.create_stack.html"},
{"title": "Create Time Series", "text": "Create Time Series Class: NodeImageCreateTimeSeries Creates a time series from multiple images with the same matrix size. Position, orientation and voxel size is copied from the first frame. Example Workflows Reshape examples Inputs Frame 1 The first frame in the time series. Type: Image4DFloat, Required, Single Outputs Time Series A time series. Type: Image4DFloat Settings Data Image Type Selection The type of input image. Values: Mask, Image, Complex Input Number of Frames Integer Specifies the number of input stacks to construct time series from. Time Series Timestep Between Frames(s) Number Specifies the timestep between each frame in output timeseries. See also Keywords: ", "tags": "", "url": "nodes.image.reshape.create_time_series.html"},
{"title": "Inversion Recovery", "text": "T1 IR Class: NodeT1IR Calculates a T1 map using spin echo inversion recovery (IR) data. Atleast two images are required, however, more images are advised if a larger range of T1 values are expected. Inversion times, inversion flip angle (FA) and repetition time (TR) are detected automatically and it is required that the FA and TR is the same in all images. An optional mask can also be provided to limit the calculations to a region of interest. Produces a T1 map in the same units as TR, and \(\text{S}_0\) which is a proton and T2 weighted image. The parameter values are obtained by fitting the data to the signal equation: \[ \begin{equation} S_i = S_0(1–(1-\cos(FA))e^{-T1/TI_i}+e^{-TR/T1}),~~~~i = 1, 2, ..., n \tag{1} \end{equation} \] where \(n\) is the number of images used. Example Workflows IR example <!--- FA tag is missing from IRSE data of the emulator. So this example is currently not working! --> Inputs Dataset A set IR images with equal TR, flip angle and varying inversion time (at least 2 diffrent inversion times). Note that TE should be the same for all images too. MetaData: The fields RepetitionTime, FlipAngle and InversionTime must be present in the metadata for all images. The flip angle must be given in degrees. Type: Image4DFloat, Required, Multiple (Minimum = 2) Mask An (optional mask) that specifies which pixels to analyse. Type: Image4DBool, Optional, Single Outputs T1 A T1 map calculated for the voxels specified by the mask or in all voxels if no mask is provided. The T1 map has the same unit as the TR, TIs, typically given in ms. Type: Image4DFloat S0 A proton and T2 weighted image. Type: Image4DFloat Settings Model Selection Selects the model to use. Values: Real, Magnitude References Gowland and V. L. Stevenson, “T1: the longitudinal relaxation time,” in Quantitative MRI of the brain: Measuring changes caused by disease, P. S. Tofts, Ed. Chichester: Wiley, 2003, pp. 111–41. 1. P. A. Gowland and V. L. Stevenson, “T1: the longitudinal relaxation time,” in Quantitative MRI of the brain: Measuring changes caused by disease, P. S. Tofts, Ed. Chichester: Wiley, 2003, pp. 111–41. Keywords: T1 estimation, inversion recovery, T1 map ", "tags": "", "url": "nodes.image.mri.relaxation_mapping.t1_map.inversion_recovery.html"},
{"title": "Variable Flip Angles", "text": "T1 VFA Class: NodeT1VFA Calculates a T1 map using the variable flip angle (VFA) method. At least two images are required, however, more images are advised if a larger range of T1 values are expected. Flip angle (FA) and repetition time (TR) are detected automatically and it is required that the TR is the same in all images. In addition to the images with varying flip angle, a B1 map can also be provided to improve the accuracy, in particular at high field strengths. The B1 map represents a scaling of FA, hence value 1 indicates that the nominal FA is achieved. An optional mask can also be provided to limit the calculations to a region. Produces a T1 map in the same units as TR, and a \(S_0\) map which is a proton and \(T2^*\)-weighted image. The parameter values are obtained by fitting the data to a linearized version of the spoiled gradient echo signal equation [1]: \[ \begin{equation} S_i = \frac{S_0(1-e^{-TR/T1})\sin(FA_i \cdot B1)}{1-\cos(FA_i \cdot B1)e^{-TR/T1}},~~~~i = 1, 2, ...,n \label{eq:sample} \end{equation} \] where \(n\) is the number of images used. Example Workflows VFA example Inputs Dataset A set spoiled gradient echo images with equal TR and varying flip angles (at least 2 diffrent angles are needed). Note that TE should be the same for all images too. MetaData: The fields RepetitionTime and FlipAngle must be present in the metadata for all images. The flip angle must be given in degrees. Type: Image4DFloat, Required, Multiple (Minimum = 2) Mask An (optional mask) that specifies which pixels to analyse. Type: Image4DBool, Optional, Single B1 Correction An (optional) B1 map that corrects for spatial variations in the flip angles. The values in the map are relative to the nominal flip angle. For example if the actual produced flip angle in a voxel is 8° while the nominal flip angle is 10°, the B1 value should be 0.8 in this voxel. Type: Image4DFloat, Optional, Single Outputs T1 A T1 map calculated for the voxels specified by the mask or in all voxels if no mask is provided. The T1 map has the same unit as the TR, typically given in ms. Type: Image4DFloat S0 A proton and \(T_2^*\) weighted image. Type: Image4DFloat References [1] H. L. M. Cheng and G. A. Wright, “Rapid high-resolution T1 mapping by variable flip angles: Accurate and precise measurements in the presence of radiofrequency field inhomogeneity,” Magn. Reson. Med., vol. 55, no. 3, pp. 566–574, 2006. Keywords: Variable flip angle mehtod, VFA, T1 mapping. ", "tags": "", "url": "nodes.image.mri.relaxation_mapping.t1_map.variable_flip_angles.html"},
{"title": "Schuff", "text": "T1 Schuff Class: NodeT1Schuff Calculates a T1 map using two inversion recovery images and a reference spin or gradient echo image using Schuffs method [1]. For the method to work the repetition time must be long, i.e. \(TR &gt;&gt; T1\) and one inversion time must be short and one long. The short and long inversion times \(TI_1\) and \(TI_2\) must fulfill \[ \begin{equation} TI_1 &lt; T_1 \ln 2, ~~ TI_2 &gt; T_1 \ln 2 \end{equation} \] for all expected T1 values in the imaged region. Further, the echo time must be identical as well as the excitation RF-pulse. When these conditions are met T1 can be estimated using the equation [1]: \[ \begin{equation} T_1 = \frac{TI_2-TI_1}{\ln(SE+SI_1)-\ln(SE-SI_2)}, \end{equation} \] where \(SE\) is the signal intensity in the reference image and \(SI_1\) and \(SI_2\) are the signal intensities in the inversion recovery images with short and long inversion time, respectively. Inputs SE Reference image with long repetition time. Type: Image4DFloat, Required, Single IR Two inversion recovery images with short and long inversion time (and long repetition time). See above for a more precise definition of short and long inversion times. MetaData: Requires the field InversionTime to be present in the metadata. Type: Image4DFloat, Required, Multiple Outputs T1 Map A T1 map. The T1 map has the same unit as the inversion time in the metadata, typically given in ms. Type: Image4DFloat References Jahng, L. Stables, A. Ebel, G. B. Matson, D. J. Meyerhoff, M. W. Weiner, and N. Schuff, “Sensitive and fast T1 mapping based on two inversion recovery images and a reference image,” Med. Phys., vol. 32, no. 6, pp. 1524–1528, May 2005. Keywords: T1 estimation, Schuff's method, T1 map ", "tags": "", "url": "nodes.image.mri.relaxation_mapping.t1_map.schuff.html"},
{"title": "T2/T2* Map", "text": "T2/T2* Map Class: NodeT2Map The node calculates a \(T_2\) or \(T_2^*\) map from spin echo or gradient echo data with multiple echo times. For notational simplicitly \(T_2\) and \(T_2^*\) will be refered to as \(T_2\) below. At least two images are required, however, more images are advised if a larger range of \(T_2\) values are expected. For accurate results it is required that no other setting but TE varies between images. An optional mask can also be provided to limit the calculations to a region. In addition to the \(T_2\) map, a \(S_0\) map which contains all weighting that is independent of \(T_2\) is also produced. The parameter values are obtained by fitting the data to the signal equation \[ \begin{equation} S_i = S_0 e^{-TE_i/T_2}, ~~~i = 1, 2, ...,n \label{#eq:nonlin} \tag{1} \end{equation} \] where \(i\) is an index over \(n\) images with different echo times. Example Workflows T2 example Inputs Echo Series One or several images are used as inputs. If the input contains timeseries the different time points are interpreted different echo times. Atleast two different echo times are needed for the node to function. MetaData: The images must contain the field EchoTime. Type: Image4DFloat, Required, Multiple Mask An (optional mask) that specifies which pixels to analyse. Type: Image4DBool, Optional, Single Outputs T2 A \(T_2\) or \(T_2^*\) map calculated for the voxels specified by the mask or in all voxels if no mask is provided. The map has the same unit as the echo time, typically given in ms. Type: Image4DFloat Settings Method Selection Selects the method to use. Values: Linear, NonLinear References P.A. Boulby and F. Rugg-Gunn, “T2: the Transverse Relaxation Time,” in Quantitative MRI of the brain: Measuring changes caused by disease, P. S. Tofts, Ed. Wiley, 2003, pp. 143–201. See also Keywords: T2 map, T2* map, T2 estimation, T2* estimation. ", "tags": "", "url": "nodes.image.mri.relaxation_mapping.t2t2_map.html"},
{"title": "ADC Map", "text": "ADC Map Class: NodeADCMap Calculates a apparent diffusion coefficient (ADC) map based on diffusion weighted images. At least two images with different b-values are required. An optional mask can also be provided to limit the calculations to a region of interest. Two methods can be used in the calculation of the ADC map; a linear (fast) method and a nonlinear (slower) method. Typically both methods give good results but the linear method involves taking the logarithm of a signal before fitting parameters and will therefore not treat noise optimally. Consequently, for lower signal-to-noise ratio data the nonlinear method is to be preferred. The estimation is based on a signal equation \[ \begin{equation} S_i = S_0 e^{-b_i ADC}, ~~~i = 1, 2, ...,n \label{#eq:nonlin} \tag{1} \end{equation} \] where \(i\) is an index over \(n\) images acquired with different b-values. An ADC map in units [\(\text{mm}^2/\text{s}\)] and a signal map that contains all weighting except that caused by diffusion are produced. Example Workflows [....] <!--- ADC data is missing in Mice example data set. --> Inputs B-Value Series A time-series of images acquired with at least two different b-values. MetaData: Requires that the field BValue is present in the metadata with one value per time frame. Type: Image4DFloat, Required, Single Mask An (optional mask) that specifies which pixels to analyse. Type: Image4DBool, Optional, Single Outputs ADC The ADC map in units \(\text{mm}^2/\text{s}\). (Provided that the b-values are given in \(\text{s}/\text{mm}^2\).) Type: Image4DFloat Signal The weighting due to everything except diffusion, i.e. \(S_0\) in equation (1). Type: Image4DFloat Settings Method Selection Use a linearized or a nonlinear fitting model. When selecting a nonlinear model, equation (1) is fit directly with a square loss term. In the linearized case the data is transformed using a logarithm to yield a linear system of equations \[ \begin{equation} \ln{S_i} = \ln{S_0} - b_i ADC, ~~~i = 1, 2, ...,n. \end{equation} \] The ADC values and \(S_0\) are then obtained using linear regression. NOTE: The nonlinear model fit is in beta-stage and may exhibit some unexpected behavior. Values: Linear, NonLinear References Bernstein, K. F. King, and X. J. Zhou, Handbook of MRI Pulse Sequences. Amsterdam: Elsevier Academic Press, pp. 830 - 53, 2004. Keywords: ADC map, apparent diffusion coefficient, parameter mapping ", "tags": "", "url": "nodes.image.mri.diffusion.adc_map.html"},
{"title": "DTI Estimator", "text": "DTI Estimator Class: NodeDTIEstimator This is the tool tip. Inputs Image Missing description. Type: Image4DFloat, Required, Single xps Missing description. Type: DataCollection, Required, Single Mask Missing description. Type: Image4DBool, Optional, Single Outputs S0 Missing description. Type: Image4DFloat MD Missing description. Type: Image4DFloat FA Missing description. Type: Image4DFloat Diffusion Tensor Missing description. Type: Image4DFloat std(S0) Missing description. Type: Image4DFloat std(MD) Missing description. Type: Image4DFloat std(FA) Missing description. Type: Image4DFloat std(Diffusion Tensor) Missing description. Type: Image4DFloat Settings Settings PluginID Text No description available. Debug Boolean No description available. General device Text The device on which to put the computation. (cpu, cuda:0, cuda:1, ...) Batch Size PythonDouble No description. Nan value PythonDouble What to replace nan values with Compute precision StringList 32 bit precision is faster but may require some regularization. Uncertainty settings Uncertainty method StringList Method used for calculation of standard deviation Number of samples PythonDouble Number of samples needed for the sampled based uncertainty. Discretization Correction Dediscretization jitter Boolean No description. Jitter size PythonDouble No description. Prior Diffusion tensor variance PythonDouble Prior variance of the diffusion tensor (0 mean not used) See also Keywords: ", "tags": "", "url": "nodes.image.mri.diffusion.dti_estimator.html"},
{"title": "DTI Forward Model", "text": "DTI Forward Model Class: NodeDTIForwardModel Calculate b-tensor images given a 6-frame diffusion tensor image, an xps and a S0 map. The forward model has the option to use a stretching parameter a: S(b) = S0 * exp( - (bD)^a ) as described by: Bennett et al. (2003), Characterization of continuously distributed cortical water diffusion rates with a stretched‐exponential model. Magn. Reson. Med., 50: 727-734. Inputs S0 Missing description. Type: Image4DFloat, Required, Single Diffusion Tensor Missing description. Type: Image4DFloat, Required, Single xps Missing description. Type: DataCollection, Required, Single Mask Missing description. Type: Image4DBool, Optional, Single Outputs B-tensor images Missing description. Type: Image4DFloat Settings Settings PluginID Text No description available. Debug Boolean No description available. Default Stretching param PythonDouble Use a stretched exponential model for heterogeneic diffusivity as described by Bennet et al. (2003). A stretching parameter of 1 results in no stretching. See also Keywords: ", "tags": "", "url": "nodes.image.mri.diffusion.dti_forward_model.html"},
{"title": "DTD Analysis", "text": "DTD Analysis Class: NodeDTDAnalysis This is the tool tip. Inputs Image Missing description. Type: Image4DFloat, Required, Single xps Missing description. Type: DataCollection, Required, Single Mask Missing description. Type: Image4DBool, Required, Single Outputs DTD Missing description. Type: Image4DFloat Mask Missing description. Type: Image4DBool Elapsed Time (s) Missing description. Type: Double Settings Settings PluginID Text No description available. Debug Boolean No description available. General Number of bootstraps PythonDouble No description. Number of CPUs Text Can be: auto, 1, 2, ... Advanced Brain Initialization Boolean Initialize components to typical brain values. No of simulation components PythonDouble Number of simulation components used internally by MC-algorithm No of output components PythonDouble Final number of components used. No of prolifiration steps PythonDouble No of prolifiration steps used by the MC-algorithm No of mutation steps PythonDouble No of mutation steps used by the MC-algorithm Mutation angular step size PythonDouble Step size during mutaiton for the theta and phi variables. Mutation diffusion step size PythonDouble Step size during mutaiton for the diffusion variables. Diffusion upper limit [µm²/ms] PythonDouble Upper limit for diffusion variables. Diffusion lower limit [µm²/ms] PythonDouble Lower limit for diffusion variables. Output Update Study Date Boolean No description. Update Study Time Boolean No description. Study Description Text Set Study Description, which will be shown in the database. Date, time and &ldquo;QTI Maps&rdquo; is the default, which is used if this field is empty. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.dtd.dtd_analysis.html"},
{"title": "DTD Fraction Map", "text": "DTD Fraction-map Class: NodeDTDFractionMap This is the tool tip. Inputs DTD Missing description. Type: Image4DFloat, Required, Multiple Mask Missing description. Type: Image4DBool, Required, Single Cell definition Missing description. Type: DataCollection, Optional, Single Outputs Cell Fraction Missing description. Type: Image4DFloat Settings Settings PluginID Text No description available. Debug Boolean No description available. Diffusion environment StringList Type of diffision micro-environment to find fractional occurance of Bootstrap statistic StringList No description. Output Update Study Date Boolean No description. Update Study Time Boolean No description. Study Description Text No description. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.dtd.dtd_fraction_map.html"},
{"title": "DTD Signal Generation", "text": "DTD Fraction-map Class: NodeDTDFractionMap This is the tool tip. Inputs DTD Missing description. Type: Image4DFloat, Required, Multiple Mask Missing description. Type: Image4DBool, Required, Single Cell definition Missing description. Type: DataCollection, Optional, Single Outputs Cell Fraction Missing description. Type: Image4DFloat Settings Settings PluginID Text No description available. Debug Boolean No description available. Diffusion environment StringList Type of diffision micro-environment to find fractional occurance of Bootstrap statistic StringList No description. Output Update Study Date Boolean No description. Update Study Time Boolean No description. Study Description Text No description. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.dtd.dtd_signal_generation.html"},
{"title": "DTD Statistical Descriptors", "text": "DTD Statistical descriptors Class: NodeDTDStatisticalDescriptors This is the tool tip. Inputs DTD Missing description. Type: Image4DFloat, Required, Multiple Mask Missing description. Type: Image4DBool, Required, Single Cell definition Missing description. Type: DataCollection, Optional, Single Outputs Mean[Diso] Missing description. Type: Image4DFloat Mean[Ddelta2] Missing description. Type: Image4DFloat Var[Diso] Missing description. Type: Image4DFloat Var[Ddelta2] Missing description. Type: Image4DFloat Cov[Diso, Ddelta2] Missing description. Type: Image4DFloat Mean[Dtensor] Missing description. Type: Image4DFloat FA Missing description. Type: Image4DFloat µFA Missing description. Type: Image4DFloat OP Missing description. Type: Image4DFloat Settings Settings PluginID Text No description available. Debug Boolean No description available. Diffusion environment StringList Diffusion micro-environment over which expectation is taken Bootstrap statistic StringList No description. Output Update Study Date Boolean No description. Update Study Time Boolean No description. Study Description Text No description. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.dtd.dtd_statistical_descriptors.html"},
{"title": "Cell Type Definitions (Dratio)", "text": "Diff. Environment Bin (Dratio) Class: NodeCTD2 Defines a subsection of the diffusion tensor distribution corresponding to a particular cell type. Outputs Definition Missing description. Type: DataCollection Settings Settings PluginID Text No description available. Debug Boolean No description available. Name Bin name Text No description. Region limits Minimum Diso [μm²/ms] PythonDouble Minimum value of the iso-diffusion coefficient for the specified cell type. Maximum Diso [μm²/ms] PythonDouble Maximum value of the iso-diffusion coefficient for the specified cell type. Minimum Dratio PythonDouble Minimum value of the ratio between the parallel and perpendicular diffusion coefficients for the specified cell type. Maximum Dratio PythonDouble Maximum value of the ratio between the parallel and perpendicular diffusion coefficients for the specified cell type. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.dtd.cell_type_definitions_(dratio).html"},
{"title": "Cell Type Definitions (Ddelta)", "text": "Diff. Environment Bin (Ddelta) Class: NodeCTD3 Defines a subsection of the diffusion tensor distribution corresponding to a particular cell type. Outputs Definition Missing description. Type: DataCollection Settings Settings PluginID Text No description available. Debug Boolean No description available. Default Bin name Text No description. Region limits Minimum Diso [μm²/ms] PythonDouble Minimum value of the iso-diffusion coefficient for the specified cell type. Maximum Diso [μm²/ms] PythonDouble Maximum value of the iso-diffusion coefficient for the specified cell type. Minimum Ddelta [Au] PythonDouble Minimum value of the ratio between the parallel and perpendicular diffusion coefficients for the specified cell type. Maximum Ddelta [Au] PythonDouble Maximum value of the ratio between the parallel and perpendicular diffusion coefficients for the specified cell type. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.dtd.cell_type_definitions_(ddelta).html"},
{"title": "Cell Type Definitions (Ddelta2)", "text": "Diff. Environment Bin (Ddelta²) Class: NodeCTD1 Defines a subsection of the diffusion tensor distribution corresponding to a particular cell type. Outputs Definition Missing description. Type: DataCollection Settings Settings PluginID Text No description available. Debug Boolean No description available. Name Bin name Text No description. Region limits Minimum Diso [μm²/ms] PythonDouble Minimum value of the iso-diffusion coefficient for the specified cell type. Maximum Diso [μm²/ms] PythonDouble Maximum value of the iso-diffusion coefficient for the specified cell type. Minimum Ddelta² [Au] PythonDouble Minimum value of the ratio between the parallel and perpendicular diffusion coefficients for the specified cell type. Maximum Ddelta² [Au] PythonDouble Maximum value of the ratio between the parallel and perpendicular diffusion coefficients for the specified cell type. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.dtd.cell_type_definitions_(ddelta2).html"},
{"title": "QTI Estimator", "text": "QTI Estimator Class: NodeQTIEstimator This is the tool tip. Inputs Image Missing description. Type: Image4DFloat, Required, Single xps Missing description. Type: DataCollection, Required, Single Mask Missing description. Type: Image4DBool, Optional, Single Outputs S0 Missing description. Type: Image4DFloat MD Missing description. Type: Image4DFloat FA Missing description. Type: Image4DFloat µFA Missing description. Type: Image4DFloat OP Missing description. Type: Image4DFloat MKT Missing description. Type: Image4DFloat MKI Missing description. Type: Image4DFloat MKA Missing description. Type: Image4DFloat µMKA Missing description. Type: Image4DFloat Diffusion Tensor Missing description. Type: Image4DFloat Settings Settings PluginID Text No description available. Debug Boolean No description available. General device Text The device on which to put the computation. (cpu, cuda:0, cuda:1, ...) Batch Size PythonDouble No description. Nan value PythonDouble What to replace nan values with Compute precision StringList 32 bit precision is faster but may require some regularization. Uncertainty settings Uncertainty method StringList Method used for calculation of standard deviation Number of samples PythonDouble Number of samples needed for the sampled based uncertainty. Discretization Correction Dediscretization jitter Boolean No description. Jitter size PythonDouble No description. Prior Diffusion tensor variance PythonDouble Prior variance of the diffusion tensor (0 mean not used) Diffusion tensor covariance variance PythonDouble The prior variance of the DT covaraince (0 means not used) Output Update Study Date Boolean No description. Update Study Time Boolean No description. Study Description Text Set Study Description, which will be shown in the database. Date, time and &ldquo;QTI Maps&rdquo; is the default, which is used if this field is empty. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.qti.qti_estimator.html"},
{"title": "XPS Reader", "text": "xps reader Class: NodeXPSReader This is the tool tip. Inputs xps path Missing description. Type: String, Optional, Single Outputs xps Missing description. Type: DataCollection Settings Settings PluginID Text No description available. Debug Boolean No description available. Default path Text Path to the b-tensor data See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.xps_tools.xps_reader.html"},
{"title": "XPS Merge", "text": "Merge xps Class: NodeXPSMerge This is the tool tip. Inputs Input 1 Missing description. Type: DataCollection, Required, Multiple Outputs Output 1 Missing description. Type: DataCollection Settings PluginID Text No description available. Debug Boolean No description available. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.xps_tools.xps_merge.html"},
{"title": "XPS From Bval-Bvec", "text": "xps from bval/bvec Class: NodeXPSBval This is the tool tip. Inputs bval path Missing description. Type: String, Optional, Single bvec path Missing description. Type: String, Optional, Single bdelta path Missing description. Type: String, Optional, Single Outputs xps Missing description. Type: DataCollection Settings Settings PluginID Text No description available. Debug Boolean No description available. Default bval path Text No description. bvec path Text No description. bdelta value PythonDouble No description. Use bdelta file Boolean No description. bdelta path Text No description. See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.xps_tools.xps_from_bval-bvec.html"},
{"title": "Extract B-Tensor Subset", "text": "Extract b-tensor subset Class: NodeExtractBTensor Extract b-tensor subset from conditions of the xps metadata. The variables are defined in the xps dataset. N.B: xps variables are given in SI units. Example: To extract all images with b-values larger than 1 μm²/ms (1000 mm²/s) the query will be: b&gt;1000e6 To extract b-values between 0.2 μm²/ms and 0.8 μm²/ms with a spherical tensor encoding (b_delta = close to zero) the query would be: (b&gt;200e6 &amp; b&lt;800e6) &amp; (b_delta&gt; -0.1 &amp; b_delta &lt; 0.1) Inputs MDD Missing description. Type: Image4DFloat, Required, Single xps Missing description. Type: DataCollection, Required, Single Outputs MDD Missing description. Type: Image4DFloat xps Missing description. Type: DataCollection Settings Settings PluginID Text No description available. Debug Boolean No description available. Default query Text No description. Sorting Sort output Boolean No description. Sort by Text No description. Ascending Text True or False (Capital first letter) See also Keywords: ", "tags": "", "url": "nodes.image.mri.multidimensional_diffusion.xps_tools.extract_b-tensor_subset.html"},
{"title": "Parker AIF", "text": "AIF Class: NodeParkerStandardAIF A population based standard AIF. The bolus arrival of the AIF is adjusted to the data labeled as &lsquo;Dynamic Series&rsquo;. The adjustment is made based on an average curve from the &quot;Dynamic Series''. The region in which the curve is averaged is: - The supplied mask or - The entire image if no mask is supplied.To find the best bolus arrival time (BAT) an extensive search is performed with a time step given in the UI of the node. The merit function on which the best arrival time is based on is a fit to the Kety/Extended Kety model. The fit is performed for a maximum duration after the bolus arrival as indicated in the settings.The node produces an AIF [mM] that is matched to the bolus arrival of the dynamic data. In addition, bolus arrival time and frame number are also accessible as outputs. These are useful when defining the baseline signal of a DCE-MRI scan. Inputs Dynamic Series Input dynamic series. Type: Image4DFloat, Required, Single Mask Input mask. This mask defines the region which is averaged to create the AIF. Type: Image4DBool, Optional, Single Outputs AIF Resulting AIF. Type: CurveCollection Start Time The bolus arrival time. Type: Double Start Frame The bolus arrival frame. Type: Double Settings AIF parameters Peak amplitude, A1, [mM] Number The amplitude of the main peak Peak width, Sigma1, [min] Number The width (standard deviation) of the main peak Peak time, T1, [min] Number The time at the center of the main peak Recirculation peak amplitude, A2, [mM] Number The amplitude of the recirculation peak Recirculation peak width, Sigma2, [mM] Number The width (standard deviation) of the recirculation peak Reciruclation peak time, T2, [min] Number The time at the center of the recirculation peak Tail amplitude, Alpha, [mM] Number The amplitude of the concentration in the tail. Tail drop-off, Beta, [min⁻¹] Number The rate with which the tail concentration drops of. Tail raise, s, [min⁻¹] Number The speed with which the tails raises at the arrival of the bolus. Tail delay time, tau, [min] Number The tail raise delay. Large vessel Hematocrit, Hct Number The Hematocrit. BAT parameters Search timestep [s] Number The BAT search time step. Duration of fit [min] Number The duration (after bolus arrival) during which the fit should be performed. Fitting model Selection The model used in the fitting. Values: Normal, Extended References Parker GJ, Roberts C, Macdonald A, et al. Experimentally-derived functional form for a population-averaged high-temporal-resolution arterial input function for dynamic contrast-enhanced MRI. Magn Reson Med 2006;56:993–1000. Murase K. Efficient method for calculating kinetic parameters using T1-weighted dynamic contrast-enhanced magnetic resonance imaging. Magn Reson Med 2004;51:858–862 Keywords: AIF, Kety, DCE, Parker, BAT, bolus, arrival ", "tags": "", "url": "nodes.image.mri.dce-mri.aif_generation.parker_aif.html"},
{"title": "AIF From Data", "text": "AIF From Data# AIF From Data Class: NodeAIFFromData This node produces an AIF plot from data, i.e. i doesn't fit a model to input data, but just produce the raw AIF plot directly. Inputs Dynamic Series The input time series. Type: Image4DFloat, Required, Single Mask A ROI from which to extract the AIF, usually a vessel. Type: Image4DBool, Required, Single Outputs AIF The output AIF. Type: CurveCollection Settings AIF from Selection Use the mean or max of the ROI to produce the AIF. Values: Mean, Max See also Keywords: ", "tags": "", "url": "nodes.image.mri.dce-mri.aif_generation.aif_from_data.html"},
{"title": "CA Quantifier", "text": "CA Quantifier Class: NodeCAQuantifier Calculates contrast agent (CA) concentration map based on a \(T_1\) map [ms] a baseline signal (signal at zero Ca concentration) and dynamic data acquired during which CA is present in the imaged region. All images must correspond to the same region and Baseline and Dynamic Series must have the same settings. An optional mask can also be provided to limit the calculations to a region.The following signal models are supported: Spoiled gradient echo CA concentration is found from the ratio of the dynamic signal and the baseline signal by inverting the spoiled gradient echo equation(ignoring \(T_2^*\)-effects). Saturation Recovery CA concentration is found by using the signal equation \(S=S_0(1-\exp(-T_I/T_1))\) and a ratio between baseline (\(S_0\)) and dynamic signal (\(S\)). In the signal equation T1 is related to the contrast concentration \(C\) through \(T_1^{-1} = T_{10}^{-1} + r_1C\) In these two equations \(TI\) is the saturation delay (referred to as inversion time in the DICOM data) and \(T_{10}\) is the \(T_1\) without contrast agent.Outputs a CA concentration map [mM]. Inputs T1 Input T1 map. Type: Image4DFloat, Required, Single Baseline Input baseline image. Type: Image4DFloat, Required, Single Dynamic Series Input dynamic series. Type: Image4DFloat, Required, Single Mask Input mask. Type: Image4DBool, Optional, Single Outputs CA Resulting contrast agent concentration map. Type: Image4DFloat Settings Model Selection Signal model. Values: SPGR, SaturationRecovery R1 (mM¯¹s¯¹) Number T1 relaxivity of the CA. Set Undefined Numbers To Number Undefined values(failed fits) are set to this value. References Schabel and D. L. Parker, “Uncertainty and bias in contrast concentration measurements using spoiled gradient echo pulse sequences,” Phys. Med. Biol., vol. 53, no. 9, pp. 2345–2373, May 2008 Blüml Msc, Stefan &amp; R. Schad, Lothar &amp; Stepanow, Boris &amp; J. Lorenz, Walter. (1993). Spin-lattice relaxation time measurment by means of a TurboFLASH technique. Magnetic Resonance in Medicine. 30. 289 - 295. 10.1002/mrm.1910300304. Keywords: dce, dynamic, contrast, enhanced, t1, map ", "tags": "", "url": "nodes.image.mri.dce-mri.ca_quantifier.html"},
{"title": "Linear KETY Estimator", "text": "Kety Class: NodeLinearKetyEstimator Fit a contrast agent concentration (CA) curve to the Kety Model (also known as the Tofts model). Both 2 and 3 parameter models can be used. In the three parameter model CA residing in the vascular compartment is included in the model. To select model, use &lsquo;Normal&rsquo; or 'Extended' for the two and three parameter models, respectively.Three inputs can be used. An image with CA concentation (in milli molar) and an AIF is required. To speed up the calculations a mask can be used to reduce the region where the analysis is performed to a part of the image. A linear least squares method is used for the fitting. Inputs CA Input contrast agent concentration map. Type: Image4DFloat, Required, Single AIF Input arterial input function. Type: CurveCollection, Required, Single Mask Input mask which defines the region where the Kety estimator will be applied. Type: Image4DBool, Optional, Single Outputs Ktrans Ktrans map. A measure of capillary permeability in each voxel. Type: Image4DFloat ve Ve map. The fractional volume of the extravascular extracellular space. Type: Image4DFloat vp Vp map. The fractional plasma volume. Type: Image4DFloat Settings Kety Model Selection Use Normal for the two parameter model and Extended for the 3 parameter model. Values: Normal, Extended Set undefined values to Number Undefined values (failed fits) are set to this value. References 1. Murase K. Efficient method for calculating kinetic parameters using T1-weighted dynamic contrast-enhanced magnetic resonance imaging. Magn Reson Med 2004;51:858–862 See also Keywords: ", "tags": "", "url": "nodes.image.mri.dce-mri.linear_kety_estimator.html"},
{"title": "Brix", "text": "Brix Class: NodeBrix Calculates pharmacokinetic maps using a modified Brix model with the assumption that signal enhancement is linearly dependent on contrast agent (CA) concentration. The model is given by: \(\displaystyle \frac{S(t)}{S(0)} = 1+A \frac{kep}{kel-kep} \Big(\exp(-kep\cdot t)-\exp(-kel\cdot t)\Big)\) in which \(S(t)\) is the dynamic signal and \(S(0)\) is the baseline signal. Two imputs are required: A baseline signal and a dynamic signal.These must correspond to data acquisition sequences with identical settings(except number of frames). An optional mask can also be provided to limit the calculations to a region.Produces a pharmacokinetic maps A [arb. unit], kel [min \(^{-1}\)] and kep [min \(^{-1}\)]. Inputs Signal The dynamic image. Type: Image4DFloat, Required, Single Baseline The baseline image. Type: Image4DFloat, Required, Single Mask Input mask which defines the region where the calculations will be performed. Type: Image4DBool, Optional, Single Outputs A Amplitude parameter map. Type: Image4DFloat Kel The elimination constant parameter map. Type: Image4DFloat Kep The exchange rate constant from the EES to plasma. Type: Image4DFloat Residual Norm The residual norm. Type: Image4DFloat Settings Guess A per voxel Boolean Allow A to be a fitting parameter per voxel (TRUE) or assume a sptially constant A (FALSE). A Number Amplitude parameter. Kel (min¯¹) Number Contrast elimination rate. Kep (min¯¹) Number Contrast extraction rate. References Ma, J. F. Griffith, D. K. Yeung, and P. C. Leung, “Modified brix model analysis of bone perfusion in subjects of varying bone mineral density,” J. Magn. Reson. Imaging, vol. 31, no. 5, pp. 1169–1175, May 2010 Keywords: Brix, dynamic, contrast, dce, kep, kel ", "tags": "", "url": "nodes.image.mri.dce-mri.brix.html"},
{"title": "Area Under Curve", "text": "Area Under Curve Class: NodeAreaUnderCurve Calulate the area under the curve for each voxel in a dynamic series over a set timespan. If a baseline image is connected, values from this image will be subtracted from each voxel before it is added. If no baseline image is connected 0 will be used as baseline. Inputs Time Series Input dynamic series. Type: Image4DFloat, Required, Single Baseline Input baseline image. Type: Image4DFloat, Optional, Single Outputs Out Resulting parameter map. Type: Image4DFloat Settings Timespan(s) Number The number of seconds the algorithm should use to calculate the area. This value needs to be high enough to include at least two frames. Keywords: area, dce, mri, AUC, IAUC ", "tags": "", "url": "nodes.image.mri.dce-mri.area_under_curve.html"},
{"title": "Induced Susceptibility Effect", "text": "ISE Class: NodeInducedSusceptibilityEffect Produces the induced susceptibility effect for the supplied magnetic susceptibility map in form of the local B0-field, distorted image and distortion field. The input values are the image matrix together with the magnetic susceptibility map and patient mask. Example Workflows Induced susceptibility example Inputs Image The image to be destorted due to the susceptibility effect. Type: Image4DFloat, Required, Single Susceptibility The susceptibility map that generates a B0-field determening how Image will be destorted. Type: Image4DFloat, Required, Single Mask Confine the distortion calculation to the region defined in the Mask. Type: Image4DBool, Required, Single Outputs Local B0 The susceptiblity induced B0 field in units of Tesla. Type: Image4DFloat Distorted Image The resulting distorted version of the input Image. Type: Image4DFloat Distortion Field The distortion field in mm. Type: Image4DVector3 Distortion Field Shifted The distortion field in mm with the bulk avarege distortion removed. Type: Image4DVector3 Settings B0 Number The field strength (T) of the B0-field Lorenz Correction Boolean Applies the Lorentz sphere correction Positive Shift X Boolean Sets the direction of the x-gradient in relation to the image matrix Positive Shift Y Boolean Sets the direction of the y-gradient in relation to the image matrix Positive Shift Z Boolean Sets the direction of the z-gradient in relation to the image matrix Bandwidth X (Hz/Voxel) Number The applied bandwidth (frequency encoding) in the X-direction given in Hz/Voxel Bandwidth Y (Hz/Voxel) Number The applied bandwidth (frequency encoding) in the Y-direction given in Hz/Voxel Bandwidth Z (Hz/Voxel) Number The applied bandwidth (read out) in the Z-direction given in Hz/Voxel Gyromagnetic Ratio (Hz/T) Number The gyromagnetic ratio to use. Typically this is the default value for protons of 42.57e+6 Hz/T References J A Lundman, M Bylund, A Garpebring, C Thellenberg Karlsson, T Nyholm. Patient-induced susceptibility effects simulation in magnetic resonance imaging. Physics and Imaging in Radiation Oncology. (2017) DOI: 10.1016/j.phro.2017.02.004 &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.mri.distortion_modelling.induced_susceptibility_effect.html"},
{"title": "Susceptibility Map", "text": "Susceptibility Class: NodeSusceptibility Converts a computed tomography (CT) image to a magnetic susceptibility map by using a mapping between Hounsfield (HU) value and susceptibility. Example Workflows Induced susceptibility example Inputs CT Image Input CT image (in HU units) from which the susceptibility map is computed. Type: Image4DFloat, Required, Single Mask Restricts the computations to the region defined by the mask. Type: Image4DBool, Optional, Single Outputs Susceptibility Resulting susceptibility map. Type: Image4DFloat References J A Lundman, M Bylund, A Garpebring, C Thellenberg Karlsson, T Nyholm. Patient-induced susceptibility effects simulation in magnetic resonance imaging. Physics and Imaging in Radiation Oncology. (2017) DOI: 10.1016/j.phro.2017.02.004 See also Keywords: susceptibility, map, magnetic, CT ", "tags": "", "url": "nodes.image.mri.distortion_modelling.susceptibility_map.html"},
{"title": "B0 Distortion", "text": "B0 Distortion Class: NodeB0Distortion Produces the distortions created by B0 inhomogeneities. The input values are the image matrix together with the \(\Delta B_0\) map and patient mask. Inputs Image The input image which is to be distorted. Type: Image4DFloat, Required, Single B0 The \(\Delta B_0\) map. Type: Image4DFloat, Required, Single Mask A mask which is TRUE within the patient and FALSE elsewhere. Type: Image4DBool, Required, Single Outputs Distorted Image The distorted image. Type: Image4DFloat Distortion Field The distortion field in mm. Type: Image4DVector3 Distortion Field Shifted The distortion field in mm with the bulk avarege distortion removed. Type: Image4DVector3 Settings Positive Shift X Boolean Sets the direction of the x-gradient in relation to the image matrix Positive Shift Y Boolean Sets the direction of the y-gradient in relation to the image matrix Positive Shift Z Boolean Sets the direction of the z-gradient in relation to the image matrix Bandwidth X (Hz/Voxel) Number The applied bandwidth (frequency encoding) in the X-direction given in Hz/Voxel Bandwidth Y (Hz/Voxel) Number The applied bandwidth (frequency encoding) in the Y-direction given in Hz/Voxel Bandwidth Z (Hz/Voxel) Number The applied bandwidth (read out) in the Z-direction given in Hz/Voxel Gyromagnetic Ratio (Hz/T) Number The gyromagnetic ratio to use. Typically this is the default value of 42.57e+6 Hz/T References J A Lundman, M Bylund, A Garpebring, C Thellenberg Karlsson, T Nyholm. Patient-induced susceptibility effects simulation in magnetic resonance imaging. Physics and Imaging in Radiation Oncology. (2017) DOI: 10.1016/j.phro.2017.02.004 &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.image.mri.distortion_modelling.b0_distortion.html"},
{"title": "N4 Bias Field Correction", "text": "Bias Field Correction Class: NodeN4BiasFieldCorrection The nonparametric nonuniform intensity normalization (N3) algorithm, as introduced by Sled et al. in 1998 is a method for correcting nonuniformity associated with MR images. The algorithm assumes a simple parametric model (Gaussian) for the bias field and does not require tissue class segmentation. In addition, there are only a couple of parameters to tune with the default values performing quite well.The N4 algorithm is a variation of the original N3 algorithm with the additional benefits of an improved B-spline fitting routine which allows for multiple resolutions to be used during the correction process. Inputs Image Input image. Type: Image4DFloat, Required, Single Mask Image to use as mask. Type: Image4DBool, Optional, Single Outputs Output Corrected image. Type: Image4DFloat Bias Field An approximation of the bias field. Type: Image4DFloat Settings Convergence Threshold Number Set the convergence threshold. Convergence is determined by the coefficient of variation of the difference image between the current bias field estimate and the previous estimate. If this value is less than the specified threshold, the algorithm proceeds to the next fitting level or terminates if it is at the last level. Field Width at Half Maximum Number Set the full width at half maximum parameter characterizing the width of the Gaussian deconvolution. Default = 0.15. Number of Control Points Integer Set the control point grid size defining the B-spline estimate of the scalar bias field. In each dimension, the B-spline mesh size is equal to the number of control points in that dimension minus the spline order. Default = 4 control points in each dimension for a mesh size of 1 in each dimension. Number of Histogram Bins Integer Set number of bins defining the log input intensity histogram. Default = 200. Spline Order Integer Set the spline order defining the bias field estimate. Default = 3. Wiener Filter Noise Number Set the noise estimate defining the Wiener filter. Default = 0.01. Downsample Boolean If set the filter will downsample the image before calculating the bias field, this is recommended. Shrink Factor Integer The shrink factor for the downsample. Upsample Interpolator Selection The interpolator to use when upsampling the resulting bias field before applying it to the original image. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References Tustison N., Gee J. N4ITK: Nick's N3 ITK Implementation For MRI Bias Field Correction. 2010 Dec. J.G. Sled, A.P. Zijdenbos and A.C. Evans. &lsquo;A Nonparametric Method for Automatic Correction of Intensity Nonuniformity in Data&rsquo; IEEE Transactions on Medical Imaging, Vol 17, No 1. Feb 1998. N.J. Tustison, B.B. Avants, P.A. Cook, Y. Zheng, A. Egan, P.A. Yushkevich, and J.C. Gee. &lsquo;N4ITK: Improved N3 Bias Correction&rsquo; IEEE Transactions on Medical Imaging, 29(6):1310-1320, June 2010. &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.image.mri.distortion_correction.n4_bias_field_correction.html"},
{"title": "B1 Correction Map", "text": "B1 Correction Map Class: NodeBOneCorrection Calculates a B1 correction map (i.e. a correction of the transmit \(B_1^+\) map) using the double angle method. The nominal flip angles are automatically dected from the metadata and the second angle must be twice as large as the first. The method requires gradient echo images (\(S_1\) and \(S_2\)) with long repetition time, i.e. \(TR \gg T1\) and that the echo time is the same for both images. When these conditions are fullfilled the actual flip-angle can be calculated as [1]: \[ \begin{equation} FA = \arccos\left( \frac{S_2}{2S_1}\right). \end{equation} \] The output is a B1 correction map meaning that the map represents a scaling of flip angles and a value of 1 indicates that the nominal FA is achieved. Example Workflows B1 example Inputs Angle 1 Gradient echo image with nominal \(FA = \alpha\). MetaData: Requires that the field FlipAngle is present. Type: Image4DFloat, Required, Single Angle 2 Gradient echo image with nominal \(FA = 2\alpha\). MetaData: Requires that the field FlipAngle is present. Type: Image4DFloat, Required, Single Outputs B1 Map B1 correction map. The values in the map are relative to the nominal flip angle. For example if the actual produced flip angle in a voxel is 8° while the nominal flip angle is 10°, the B1 correctgion value is 0.8 in this voxel. Type: Image4DFloat References Wang, W. Mao, M. Qiu, M. B. Smith, and R. T. Constable, “Factors Influencing Flip Angle Mapping in MRI : RF Pulse and B 0 Inhomogeneities Measurement of Relative Flip Angles,” Magn. Reson. Med., vol. 56, no. 2, pp. 463–468, 2006 Keywords: B1 map, B1 correction, B1, Dubble angle method ", "tags": "", "url": "nodes.image.mri.distortion_correction.b1_correction_map.html"},
{"title": "SUV", "text": "SUV Class: NodePETSUV Calculates the standardized uptake value (SUV) of a PET image. The SUV is a dimensionless, semiquantative measure of tracer uptake, i.e. it is the ratio of actavity in each voxel related to the injected activity. It is calculated as \[ \begin{equation} SUV = \frac{r}{(a'/w)} \label{eq:sample} \end{equation} \] where \(r\) is the radioactivity concentration measured by the PET scanner, \(a'\) is the decay corrected amount of injected tracer and \(w\) is the patient weight. Inputs PET Image A PET image. To calulcate SUV (without having to override the metadata and provide numbers manually), some metadata tags pertaining to half-life, patient weight, total administered dose and administration time are mandatory. Type: Image4DFloat, Required, Single Outputs Result The output SUV parameter map. Type: Image4DFloat Settings Override Patient Weight Boolean If set the specified patient weight will be used instead of the weight from metadata. Half Life Boolean If set the specified half life will be used instead of the half life from metadata. Total Dose Boolean If set the specified dose will be used instead of the dose from metadata. Administration Date/Time Boolean If set the specified date/time will be used instead of the date/time from metadata. Override Parameters Patient Weight(kg) Number Patient weight in kilograms. Half Life(s) Number The radionuclide half life, in seconds, that was used in the correction of this image. Total Dose(MBq) Number Total dose specified in MBq to use when &lsquo;Set Total Dose&rsquo; is selected. Administration(Date/Time) Date The actual time of radiopharmaceutical administration to the patient for imaging purposes. References SUV on Wikipedia See also Keywords: Standardized uptake value ", "tags": "", "url": "nodes.image.pet.suv.html"},
{"title": "Dose Volume Histogram", "text": "DVH Class: NodeDoseVolumeHistogram A dose-volume histogram relates the radiation dose to the tissue volume and summarizes a 3D dose distribution to a graphical 2D format. The node produces the cumulative dose-volume histogram for the supplied dose matrix and structure(s). The structures are supplied as images (i.e. Smooth masks) to ensure that the output values are accurate. Example workflows Dose-volume histogram example Inputs Dose An image containing the dose matrix to be evaluated. This image is normally produced by importing a DICOM RT DOSE, or RD file. Type: Image4DFloat, Required, Single Volume(s) One or multiple Smooth Mask(s), describing the structures for which the DVH should be produced. They must be of the same matrix size as the dose image. Type: Image4DFloat, Required, Multiple Outputs DVH Plot A plot contains the DVH. The DVH can be viewed in the Node Output panel, in the Plot pane. Type: CurveCollection DVH Data A table containing the DVH parameters. Basic parameters include image and structure information, such as names and volume. It also includes Dmin, Dmax and Dmean by defeault. It also includes other parameters that are specified in the Node Settings panel, for example D95. Type: DataCollection DVH Plot Data A table with the DVH plot data, so that the user can plot the DVHs using any other software. The first column lists the dose levels (x-axis) and each of the following columns contain the volume levels (y-axis) for a specific structure specified by the Smooth Mask(s). Type: DataCollection Settings Structures For detailed explanations on supersampling of structures, see Struct Processor. Render Structures Boolean Renders all structures available in a connected RT-Struct collection, instead of connecting multiple Smooth Masks, on the connected Dose input to produce DVH data. Maximum Volume Error(%) Number The tolerance of difference between the numeric volumes calculated directly from the RT-struct polygons and the rendered Smooth Mask. Maximum Iterations Integer Sets the maximum number of iterations of adaptive supersumpling to reach Maximum Volume Error (%) before breaking. Use Error Stopping Criteria Boolean If set, the automatic upsampling will stop if the volume error doesn't change between iteration. Error Stopping Criteria(%) Number If using error stopping criteria the automatic upsampling will stop if the absolute volume error doesn't change by at least this much compared to the error of the previous iteration. End Cap Thickness (mm) Number Sets the end cap thickness to use when rendering structures Histogram Title Text Title of the diagram. Minimum Dose(Gy) Number Minimum dose of the histogram. Maximum Dose(Gy) Number Maximum dose of the histogram. Bins Integer Number of bins in the histogram. Analysis Prescribed Dose(Gy) Number Set the prescribed dose. Used to calculate relative dose (needed in e.g. V90%). Dose Levels Text Set the dose levels of interest to be explicitly displayed in the DVH Data output. Supplied as a comma separated list, so if you want D2 and D98, write &ldquo;2, 98&rdquo;. Volume Levels(%) Text Set the volume levels of interest to be explicitly displayed in the DVH Data output. Supplied as a comma separated list, so if you want V10 and V60, write &ldquo;10, 60&rdquo;. Volume Levels(Gy) Text Set the volume levels of interest to be explicitly displayed in the DVH Data output. Supplied as a comma separated list, so if you want V5Gy and V10Gy, write &ldquo;5, 10&rdquo;. Output Absolute Volume Boolean Output volume in cc instead of %. References Dose-volume histogram on Wikipedia See also Keywords: DVH, Dose-volume histogram, Smooth Mask ", "tags": "", "url": "nodes.image.radiotherapy.dose_volume_histogram.html"},
{"title": "Gamma Index", "text": "Gamma Index Class: NodeDoseGammaIndex Calculates the gamma index, first introduced by Low et al, between a reference and an evaluation dose distribution in 3D with sub-voxel accuracy according to the algorithm described by Wendling et al. It will only calculate the gamma index for reference voxels &gt;0. Definition of the gamma index The gamma index combines the dose difference and the distance difference into a dimensionless metric. In principle, this metric should be calculated for each reference point against all points in the evaluated dose distribution. The gamma statistic is calculated as \[ \begin{equation} \Gamma(\textbf{r}_R,\textbf{r}_E) = \sqrt{\frac{\Delta r^2(\textbf{r}_R,\textbf{r}_E)}{\delta r^2} + \frac{\Delta D^2(\textbf{r}_R,\textbf{r}_E)}{\delta D^2}} \label{eq:sample} \end{equation} \] where \(\delta r\) is the distance criterion (distance to agreement or DTA) and \(\delta D\) is the dose difference criterion. The \(\gamma\) is then taken as the minimum \(\Gamma\) value over all evaluated points. If \(\gamma &lt; 1\), that point will pass. Standard values for \(\delta r\) is 3 mm and \(\delta D\) is 3%, and a standard value for accepting agreement between two distributions is usually that 97% of all evaluated points should pass. Example workflows Gamma index example Inputs Reference Dose An image containing the dose matrix to be used as reference. This image is normally produced by importing a DICOM RT DOSE, or RD file. Type: Image4DFloat, Required, Single Evaluated Dose An image containing the dose matrix to be evaluated. This image is normally produced by importing a DICOM RT DOSE, or RD file. It must have the same matrix size as the reference dose. Type: Image4DFloat, Required, Single Mask A mask which specifies in which area the gamma index should be evaluated. It only applies to points in the evaluated dose. It must have the same matrix size as the reference dose. Type: Image4DBool, Optional, Single Outputs Map A parameter map which contains the \(\gamma\) values. Type: Image4DFloat Fail Map A binary image which is True where \(\gamma &gt; 1\), i.e. failed points. Type: Image4DBool Evaluated Map A binary image which is True for points that have been included in the evaluation. Type: Image4DBool Gamma Index A table which contains information on the gamma evaluation, such as names of the evaluated distributions, the number of evaluated voxels and the gamma pass rate. Type: DataCollection Settings Sample Step Size(mm) Number Determines the resolution of the evaluation, i.e. the accuracy of the interpolation. Recommended step size is at most 1/3 of the distance to agreement (DTA) and a fraction of the resolution of the voxel size. As an example, for a 1 mm DTA and voxel size of 2 mm, a step size of 0.25 mm would be suitable. Increasing resolution increases computation time. Prescribed Dose(Gy) Number The dose to which the dose criteria is related to if the option Use Local Dose Reference is not selected. I.e. if a 3% dose criterion is chosen and the prescribed dose is 10 Gy, the absolute dose difference criteria in the gamma calculations will be 0.3 Gy. Use Local Dose Reference Boolean If comparing the gamma distribution on a local level, i.e. not normalized to the prescribed dose, this option should be activated. This will check the dose difference at each individual sample point and normalize it to the dose level in the current reference voxel. Dose Criteria(%) Number Sets the dose criteria. Distance Criteria(mm) Number Sets the distance criteria, or distance to agreement. Search Radius(mm) Number Sets the radius of the sphere around each evaluated voxel to evaluate the gamma index for. If the user desires a pass/fail gamma evaluation, the Search Radius can be set equal to Distance Criteria. If a more thorough evaluation is desired, set the Search Radius to at least 3 times the Distance Criteria. Increasing the search radius increases the computation time. References 1. Low D a, Harms WB, Mutic S, et al. A technique for the quantitative evaluation of dose distributions. Med. Phys. 1998;25:656–61. 2. Wendling M, Zijp LJ, McDermott LN, et al. A fast algorithm for gamma evaluation in 3D. Med. Phys. 2007;34:1647–54. See also Keywords: ", "tags": "", "url": "nodes.image.radiotherapy.gamma_index.html"},
{"title": "Equivalent Uniform Dose", "text": "EUD Class: NodeEquivalentUniformDose Calculates the equivalent uniform dose (EUD), tumor control probability (TCP) and normal tissue complication probability (NTCP) to volumes, which can be used for quantitatively comparing and reporting inhomogeneous dose distributions based on radiobiological effect. The EUD parameter summarizes the 3D dose distribution in a volume to a dose &ldquo;which, when distributed uniformely across the target volume, cases the survival of the same number of clonogens&rdquo;, as described by Niemierko. EUD is calculated as follows: \[ \begin{equation} EUD = \left(\sum_i{v_i D_i^a}\right)^{1/a} \label{eq:1} \end{equation} \] where \(v_i\) is the fractional organ volume recieving a dose \(D_i\) and \(a\) is a tissue specific parameter that describes the volume effect. TCP is calculated as \[ \begin{equation} TCP = \frac{1}{1 + \left(\frac{TCD_{50}}{EUD}\right)^{4\gamma50}} \label{eq:2} \end{equation} \] where \(\gamma_{50}\) describes the slope of the dose-response curve. \(TCD_{50}\) is the dose to control 50% of the tumors. NTCP is calculated as \[ \begin{equation} NTCP = \frac{1}{1 + \left(\frac{TD_{50}}{EUD}\right)^{4\gamma50}} \label{eq:3} \end{equation} \] where \(TD_{50}\) is the tissue tolerance dose, i.e. the dose that causes normal tissue complication in 50% of cases. Example workflows Equivalent uniform dose example Inputs Dose An image containing the dose matrix to be evaluated. This image is normally produced by importing a DICOM RT DOSE, or RD file. Type: Image4DFloat, Required, Single Volume(s) Mask(s) containing the structures for which to calculate the EUD. Must have the same matrix size as the dose. Type: Image4DBool, Required, Multiple Outputs EUD A table containing information on the dose and structures evaluated as well as the EUD, normal tissue complication probability (NTCP) and and tumor control probability (TCP). Type: DataCollection Settings The values of these settings can be found in literature, for example in this reference by Emami. EUD a Number Tissue specific parameter that describes volume effect. NTCP/TCP γ50 Number Slope of the dose-response curve. TD50 Number The tissue tolerance dose, i.e. the dose that causes normal tissue complication in 50% of cases. TCD50 Number The dose of radiation that locally controls 50% of tumors. References 1. %22Reporting and analyzing dose distributions: A concept of equivalent uniform dose%22, Medical Physics, 1996, Andrzej Niemierko. See also Keywords: EUD, TCP, NTCP, equivalent uniform dose, normal tissue complication probablity, tumor control ", "tags": "", "url": "nodes.image.radiotherapy.equivalent_uniform_dose.html"},
{"title": "Descriptive Statistics", "text": "Statistics Class: NodeImageStatistics Calculate statistical properties of one or more images, with option to supply one or more masks. For multiple images and masks, the statistial properties of all combinations of images and masks will be returned. Example Workflows Statistics examples Inputs Input One or more images on which the statistics will be calculated. If a mask is supplied, all images and masks must have the same matrix size. If no mask is supplied, image can have different matrix sizes. Type: Image4DFloat, Required, Multiple Masks On or mor masks can be supplied to define regions in which statistics will be calculated. The matrix size of the mask(s) must match the matrix size of the image(s). Type: Image4DBool, Optional, Multiple Outputs Output A data table with the statistical information selected in the settings for all inputs. Type: DataCollection Settings Node Tag Text The name of the data. If you export the data to .xls or .csv, this will be used as the file name. Statistics Mean Boolean Calculate the mean voxel value of the image, or region of the image defined by the mask. Max Boolean Calculate the maximum voxel value of the image, or region of the image defined by the mask. Min Boolean Calculate the minimum voxel value of the image, or region of the image defined by the mask. Standard Deviation Boolean Calculate the standard deviation of voxel values of the image, or region of the image defined by the mask. Volume Boolean Calculate the volume of the image, or region of the image defined by the mask. Median Boolean Calculate the median voxel value of the image, or region of the image defined by the mask. Kurtosis Boolean Calculate the kurtosis of voxel values of the image, or region of the image defined by the mask. Skewness Boolean Calculate the skewness of voxel values of the image, or region of the image defined by the mask. Calculate Percentiles Boolean Calculate the percentiles (defined below) of the image, or region of the image defined by the mask. Percentiles Text The percentiles to calculate if the &ldquo;Calculate percentiles&rdquo; option is true. See also Keywords: ", "tags": "", "url": "nodes.image.statistics.descriptive_statistics.html"},
{"title": "Histogram", "text": "Histogram Class: NodeImageHistogram Creates histogram plots for connected images. Example Workflows Statistics examples Inputs Images One or more image(s). Type: Image4DFloat, Required, Multiple Outputs Out Histogram plots of the input image(s). Type: CurveCollection Settings Bins Integer Sets the number of bins for the histogram(s). Automatic Bounds Boolean If TRUE, the bounds for each histogram will be the lowest and highest voxel value in each image. Lower Bound Number If not using automatic bounds this value will be used as the lower bound for all histograms. Upper Bound Number If not using automatic bounds this value will be used as the upper bound for all histograms. Logarithmic Scale Boolean If TRUE the histogram will be presented in a logarithmic scale. See also Keywords: ", "tags": "", "url": "nodes.image.statistics.histogram.html"},
{"title": "Image Time Statistics", "text": "Time Statistics Class: NodeTimeImageStatistics Calculate statistical properties per voxel in a time series. This node generates 3D images where each voxel value reflects a statistical property in the temporal dimension. Example Workflows Statistics examples Inputs Input An image time series. Type: Image4DFloat, Required, Single Mask A 3D binary mask. Type: Image4DBool, Optional, Single Outputs Mean The mean value of each voxel in the temporal dimension. Type: Image4DFloat Max The maximum value of each voxel in the temporal dimension. Type: Image4DFloat Min The minimum value of each voxel in the temporal dimension. Type: Image4DFloat Standard Deviation The standard deviation of each voxel in the temporal dimension. Type: Image4DFloat Settings Node Set Undefined Numbers To Number Undefined values are set to this value. Statistics Mean Boolean Calculate the temporal mean of each voxel, or voxels defined by the mask. Max Boolean Calculate the temporal maximum of each voxel, or voxels defined by the mask. Min Boolean Calculate the temporal minimum of each voxel, or voxels defined by the mask. Standard Deviation Boolean Calculate the temporal standard deviation of each voxel, or voxels defined by the mask. Median Boolean Calculate the temporal median of each voxel, or voxels defined by the mask. Kurtosis Boolean Calculate the temporal kurtosis of each voxel, or voxels defined by the mask. Skewness Boolean Calculate the temporal skewness of each voxel, or voxels defined by the mask. Calculate Percentiles Boolean Calculate the temporal percentiles (defined below) of each voxel, or voxels defined by the mask Percentiles Text The percentiles to calculate if the &ldquo;Calculate percentiles&rdquo; option is true, separated by commas. See also Keywords: ", "tags": "", "url": "nodes.image.statistics.image_time_statistics.html"},
{"title": "Region Time Statistics", "text": "Time Statistics Class: NodeTimeStatisticsRegion Calculate statistics of a time series, frame-by-frame, in supplied regions. The output Data Table is similar to the Statistics node, but in this node statistical properties are calculated frame-by-frame. Example Workflows Statistics examples Inputs Time Series An image time series. Type: Image4DFloat, Required, Single Label Maps A Label map image where statistical properties should be calculated. Type: Image4DFloat, Required, Single Outputs Data A Data Table with the statistical properties of the image in the different labels. Type: DataCollection Mean A plot showing the mean value for each frame and label. Type: CurveCollection Min A plot showing the minimum value for each frame and label. Type: CurveCollection Max A plot showing the maximum value for each frame and label. Type: CurveCollection Sum A plot showing the sum for each frame and label. Type: CurveCollection SD A plot showing the standard deviation for each frame and label. Type: CurveCollection Settings Tag Text The name of the data. If you export the data to .xls or .csv, this will be used as the file name. See also Keywords: ", "tags": "", "url": "nodes.image.statistics.region_time_statistics.html"},
{"title": "DICOM .dcm", "text": "DICOM Class: NodeExportDICOM Convert and save connected images to DICOM files on disk. DICOM is a standardized image format for storing and sending medical images from many different modalities. With each image comes extensive metadata information regaring e.g. imaging modality, imaging settings, scan time and date, patient information etc. Many metadata tags are specific to one modality, which makes a function that fully adheres to the DICOM standard difficult to implement. This is important if images are imported in other software such as dose planning programs or sent to a DICOM node or PACS for storage. For this reason, MICE Toolkit supports three DICOM image export modalities; CT, MRI, and RTDOSE. Quantization errors in DICOM DICOM can only save pixel data in integer values between 0 and 65,535. To represent decimal values, a linear transformation is applied to the pixel data. The slope and intercept of this transformation is calculated so that the range of integer values in the dicom image covers the dynamic range of the values being stored. For large pixel ranges this method will lead to quantization error. To minimize the ammount of quantization, make sure you limit the range of values in the images. Voxels with extreme values outside the window of interest will lead to a large quantization error. This is illustrated in the figure below. The figure shows two image histograms after a linear transformation. The images are identical, except for a few outlier voxel values of 100 in the right image. In this toy example, there are 50 gray levels available. If the span of intensities is [0 - 15], the quantization error is quite small. However, if the span is [0 - 100], the quantization error is much larger. Example Workflows Export to DICOM examples Inputs In One or more images. Type: Image4DFloat, Required, Multiple Settings Export Modality Selection Defines what the resulting DICOM images modality should be. Values: MR, CT, RTDOSE Series Description Text Defines what the resulting DICOM images series description should be. Slicewise Slope/Intercept Boolean If TRUE, the intercept and slope will be recalculated for each slice, this might lead to a smaller quantization error. Force Integer Values Boolean If TRUE, the node will try to save voxel values as integer values (if modality is set to RTDOSE this setting will be ignored). The slope will always be 1, intercept will be adjusted. Voxel values will be rounded to the nearest integer value. If the total span of values in the image is more than 65535, values outside that span will be truncated.WARNING: Using this feature might drastically change your data and should only be used if you fully understand what it does. Protocol Name Text Name of the protocol if applicable. Set Image Name Boolean If TRUE, the specified image name will be used to name the image(s). If more than one image is connected, a counter will be added to the end of the name. Image Name Text The new image name, will be used to name the image if the &ldquo;Set Image Name&rdquo; option is selected. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Metadata Override Metadata Boolean If TRUE, the metadata for the exported files will be set to the fields in this category. The patient metadata from the input images will not be used if this is set. Patient ID Text Set the new patient ID. Patient Name Text Set the new patient name. Frame of Reference Text Set the new frame of reference. Study Date Date Set the new study date. DICOM Remote Send to remote storage Boolean If TRUE, the files will be sent to a remote DICOM storage instead of being saved to disk. Host Text The IP or hostname of the remote DICOM storage. AE-Title Text The AE title of the remote DICOM storage. Port Integer Port to use when connecting to the remote dicom storage. See also DICOM Standard Browser for a complete list of all DICOM tags. Keywords: ", "tags": "", "url": "nodes.image.export.dicom_.dcm.html"},
{"title": "Database", "text": "Export DB Class: NodeExportDB Save an image to a selected database. Internally, the image will be saved using the mhd file format with associated metadata. Due to current 32 bit limitations, the maximum size for one image in the database is 4 GB. This limitation can be circumvented in 4D images by splitting the data into multiple images with a specific number of frames, which can be set in the node settings. Inputs Images Image to save to database. The input type can be changed in the settings from Image4DFload to any image format supported in MICE Toolkit, i.e binary mask, vector field or complex image. Type: Image4DFloat, Required, Single Links Optionally, link the image to another image allready in the database. Type: Image4DFloat, Optional, Multiple Settings Export Database Text The name of the target database. Make sure that you have write permission to the selected database. Image Type Selection The input image type. Values: Mask, Image, Complex, Vector Linked Image Type Selection The linked image type. Values: Mask, Image, Complex, Vector Metadata Override Study Boolean If TRUE the metadata for the exported files will be set to the fields in this category. The patient metadata from the input images will not be used if this is TRUE. Study Description Text Set new Study description. Study ID Text Set new Study ID. Study Instance UID Text Set new Study Instance UID. Split Image Split Image by Frames Boolean Split one 4D image into multiple 4D images with a specific number of frames per image. This option can be used to save datasets larger than 4GB in the database. Block Size (frames) Integer Number of frames per 4D image Block Naming Text How to name the images in the database. Four variable placeholder can be used: $n: image name $c: block number $sf: start frame $ef: end frame Default string: $n Block $c Frames $sf-$ef Block Count Offset Integer Set offset for the block counter ($c). By default, the offset is 0 and the counter starts at 1. Frame Count Offset Integer Set offset for the frame counter. By default, the offset is 0 and the counter starts at 1. See also Keywords: ", "tags": "", "url": "nodes.image.export.database.html"},
{"title": "NIfTI .nii", "text": "NIfTI Class: NodeExportNIfTI Convert and export all connected images to NIfTI files. The NIfTI file format is much simpler than the DICOM format. Images are stored in one single file, and are not constrained to integer values. The default support for metadata is limited, and constrained to image properties such as position, orientation and resolution. Note: No DICOM metadata will be written to the file. Example Workflows Export image examples Inputs In One or more images. Type: Image4DFloat, Required, Multiple Settings Image Prefix Text Sets the image prefix, this string will be added to beginning of the image name. Compress Image Boolean Copresses the output image without loss of data. Turn this off for faster exports. Export Metadata Boolean If set a JSON file containing image metadata will be exported as well. Path Text Sets the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. References WriteImage filter in SimpleITK Neuroimaging Informatics Technology Initiative The NIfTI file format See also Keywords: ", "tags": "", "url": "nodes.image.export.nifti_.nii.html"},
{"title": "Image .bmp, .jpg etc", "text": "Image Class: NodeExportBitmap Export images to a raster graphics image without metadata. Each slice is exported as a separate image. The following file formats are supported: bmp, gif, jpeg, png, tiff. Example Workflows Export image examples Inputs In One or more images to be exported. Type: Image4DFloat, Required, Multiple Settings Export Image Format Selection Format of the image(s). Values: Bmp, Gif, Jpeg, Png, Tiff Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). JPEG Quality % Integer Set the quality of the output JPEG. Single Slice Preview Boolean Export only the middle slice in the stack. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Window Colormap Selection Select the colormap of the exported image. Values: BlackBody, Bone, Cividis, Cool, Copper, Dose, GE, Gray, InverseGray, Inferno, Jet, Magma, Moreland, Pink, Plasma, Sokoloff, Spring, Summer, Viridis, Winter Full Range Window Boolean If selected, the image intensity min and max bounds will be the min and max of the image. Window Min Number Set the intensity min (applies only if the Full range window option is false). Window Max Number Set the intensity max (applies only if the Full range window option is false). See also Keywords: ", "tags": "", "url": "nodes.image.export.image_.bmp,_.jpg_etc.html"},
{"title": "MetaIO .mhd", "text": "MHD Class: NodeExportMHDFloat Convert and export all connected images to .mhd files. This file format is developed by the Insight Software Consortium, and a part of the Insight Segmentation and Registration Toolkit (ITK). Two files are written for each image: an .mhd file, which is a header file containing metadata describing image properties such as voxel size, matrix size, orientation and position, and a link to the binary image. This file can also contain limited metadata information. a .raw file, containing the binary image. The raw file can be compressed using gzip. Voxel values will be written as they are with no quantization. This might lead to very large files in some cases. Metadata can optionally be exported as an .xml file with the same basename as the exported image(s). Note: No DICOM metadata will be written to the .mhd file. Example Workflows Export image examples Inputs In One or more images to be exported. Type: Image4DFloat, Required, Multiple Settings Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). Compress Image Boolean Use lossless compression on the output .raw-file. Turn this off for faster exports. Export Metadata Boolean If TRUE, an XML file containing image metadata will be exported. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Keywords: ", "tags": "", "url": "nodes.image.export.metaio_.mhd.html"},
{"title": "MATLAB .mat", "text": "MAT Class: NodeExportMATFloat Convert and export all connected images to MATLAB .mat files. Voxel values will be written as they are with no quantization, this might lead to very large files in some cases. Each .mat file will contain a structure array, with the following fields: Position: The position of the image Orientation: The orientation of the image VoxelSize: The voxel size of the image. Matrix: The image matrix. Version: The version of MICE Toolkit that was used to create the file. No DICOM metadata will be written to the MAT file. Inputs In One or more images to be exported. Type: Image4DFloat, Required, Multiple Settings Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Keywords: ", "tags": "", "url": "nodes.image.export.matlab_.mat.html"},
{"title": "CSV .csv", "text": "Image CSV Class: NodeExportImageCSV Convert and export all connected images to csv files. By default, the output will be a .csv text file with the following columns: Voxel Index X: The X index of the voxel. Voxel Index Y: The Y index of the voxel. Voxel Index Z: The Z index of the voxel. Voxel Index T: The T index of the voxel. Voxel Value: The value of the voxel. It is possible to export Voxel position and/or Patient Information for each voxel as well. The exact format of the output can be defined in the settings. This format is suited for exporting smaller regions of an image to be used for further processing, analysis or plotting in an external program. It is not intended for storing entire images, since this format is stored in text instead of binary which will lead to large file sizes. Example Workflows Export image examples Inputs In One or more images to be exported. Type: Image4DFloat, Required, Multiple Mask A mask of the same dimensions as the input image(s), defining a region to be exported. Type: Image4DBool, Optional, Single Settings Export Image Prefix Text Set the file name prefix. This string will be added to beginning of the file name(s). Separator Text Set the separator between columns. Write Column Headers Boolean If TRUE, column headers will be written to the file. Single File Boolean Write all connected image values in the same file, in order for this to work all dimensions, positions and orientations needs to be exactly the same for all connected images.Note: If you don't need voxel center information only the matrix sizes need to be the same. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Image Information Patient Information Boolean if TRUE, the two first columns describe patient information. Patient ID and Patient Name will be written to each row. Voxel Index Boolean If TRUE, voxel indices will be written to each row. Voxel Center Boolean If TRUE, voxel positions will be written to each row. See also Keywords: ", "tags": "", "url": "nodes.image.export.csv_.csv.html"},
{"title": "Transformix .txt", "text": "TFX Class: NodeExportTFX Export transformix parameters to a text file. If the input transform has one or more initial transforms, each initial transform will be exported to a separete file, and referenced in the InitialTransformParametersFileName field of each respective file. Example Workflows Export and import of transformix files Inputs In One transform from an Elastix node. The export node will also export all initial transforms. Type: TransformixParameter, Required, Single Settings Filename Text Sets the file name for the parameters to be saved. If the parameters use initial transforms, they will be saved in the same folder as &quot;it&lt;N&gt;_&lt;file name&gt;&quot;, where N is the number of initial transforms. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Elastix homepage Keywords: registration, transform, ", "tags": "", "url": "nodes.image.export.transformix_.txt.html"},
{"title": "SQL", "text": "SQL Class: NodeExportDatabase Appends data to a database. Inputs Image Missing description. Type: Image4DFloat, Required, Single Structures Missing description. Type: Image4DFloat, Optional, Multiple Settings Host Text Databse host. Database Text The database to export to. Compress Image Boolean Copresses the output image with gzip. See also Keywords: ", "tags": "", "url": "nodes.image.export.sql.html"},
{"title": "Visualize", "text": "Visualize Class: NodeImageVisualize Send an image or a mask to the visualizer. This node allows you to automate the display of images from your workflow without any interactions. Example Workflows Visualizer node example Inputs In Input image or mask. Type: Image4DFloat, Required, Single Settings Image Type Selection The type of image to visualize. Values: Mask, Image Viewport Integer Set the target viewport number. Layer Integer Set the layer in which the image or mask will be displayed. The bottom layer is layer 1. Lock Viewport Boolean Set to TRUE if you want to lock the viewport coordinate system to other viewports. Colormap ColorMap Select the colormap of the image. Full Range Window Boolean If set to TRUE, the image intensity min and max bounds will be the min and max of the image. Window Min Number Set the min value of the window if the full range is set to FALSE. Window Max Number Set the max value of the window if the full range is set to FALSE. Opacity Number Set the global opacity of the image. This only affects images in layers 2 and above. Slice Integer Select the slice to display. A slice of 0 means the middle slice will be selected. Frame Integer Select the frame to display. Orientation Selection Select the projection of the image, which can be axial (AX), sagittal (SAG), coronal (COR) or a 3D rendering (XYZ). Values: AX, SAG, COR, XYZ Interpolation Selection Set the image interpolation. Values: Cubic, Linear, Nearest See also Keywords: ", "tags": "", "url": "nodes.image.visualization.visualize.html"},
{"title": "Visualize RGB", "text": "Visualize RGB Class: NodeImageVisualizeRGB Sometimes the provided colormaps are not sufficient when displaying the colors of an image. This node can visualize three images as the red, green and blue channels of an RGB image. The inputs can be three separate R, G, and B images, a vector image where the vector components x, y and z will be shown as the red, green and blue channels respectively; and a time series where the three frames will be displayed as red, green and blue respecively. Example Workflows Visualizer node example Inputs R The red channel. Type: Image4DFloat, Required, Single G The green channel. Type: Image4DFloat, Required, Single B The blue channel. Type: Image4DFloat, Required, Single Settings Input Type Selection Select the input format of the RGB data. If the R, G, and B channels are times series (or have multiple frames) they need to be supplied as separate R, G and B channels. The number number of frames of the R channel will determine the number of frames of the RGB image. If the G or B channels have fewer frames, the last frame will be repeated to match the red channel frame count. Values: RGB, Frames, VectorField Viewport Integer Set the target viewport number. Layer Integer Set the layer in which the image or mask will be displayed. The bottom layer is layer 1. Lock Viewport Boolean Set to TRUE if you want to lock the viewport coordinate system to other viewports. Window Min Number Set the min value. Window Max Number Set the max value. Slice Integer Select the slice to display. A slice of 0 means the middle slice will be selected. Frame Integer Select the frame to display. Orientation Selection Select the projection of the image, which can be axial (AX), sagittal (SAG), coronal (COR) or a 3D rendering (XYZ). Values: AX, SAG, COR, XYZ Interpolation Selection Set the image interpolation. Values: Cubic, Linear, Nearest See also Keywords: ", "tags": "", "url": "nodes.image.visualization.visualize_rgb.html"},
{"title": "Create RGB Image", "text": "Colormap Class: NodeImageColorMap Apply a colormap to an image and split the result into R, G and B channels. Example Workflows Visualizer node example Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs R The red channel of the resulting image. Type: Image4DFloat G The green channel of the resulting image. Type: Image4DFloat B The blue channel of the resulting image. Type: Image4DFloat Settings Colormap Colormap Selection Select the colormap of the image. Values: BlackBody, Bone, Cividis, Cool, Copper, DivergingBlueRed, DivergingRedGreen, Dose, GE, Gray, InverseGray, Inferno, Jet, Magma, Moreland, Pink, Plasma, Sokoloff, Spring, Summer, Viridis, Winter Clamping Boolean If TRUE, values below the min value will be mapped to the lowest color value, and values above the max value will be mapped to the highest color value. If FALSE, values outside the range are mapped to black. Window Full Range Window Boolean If selected, the image intensity min and max bounds will be the min and max of the image. Window Min Number Set the intensity min (applies only if the Full range window option is false). Window Max Number Set the intensity max (applies only if the Full range window option is false). Output Output Min Number Set the intensity min (applies only if the Full range window option is false). Output Max Number Set the intensity max (applies only if the Full range window option is false). See also Keywords: ", "tags": "", "url": "nodes.image.visualization.create_rgb_image.html"},
{"title": "Create New Image", "text": "Create Class: NodeImageCreate Creates a new image based on user settings. Outputs Out Resuling image. Type: Image4DFloat Settings Image Name Text Name of the image. Image Type Selection The type of image to create. Values: Mask, Image, Complex, Vector Clone Metadata Boolean Name of the image. Metadata Image Type Selection The type of image to create. Values: Mask, Image, Complex, Vector Size Matrix Size X Integer Number of pixels in x-direction Matrix Size Y Integer Number of pixels in y-direction Matrix Size Z Integer Number of pixels in z-direction Matrix Size T Integer Number of frames Position Position Offset X [mm] Number Offset in x-direction Position Offset Y [mm] Number Offset in y-direction Position Offset Z [mm] Number Offset in z-direction Resolution Resolution X [mm] Number Resolution in x-direction Resolution Y [mm] Number Resolution in y-direction Resolution Z [mm] Number Resolution in z-direction Resolution T [s] Number Time step between frames in seconds Rotation Rotation Axis X Number Rotation axis x-direction (not normalized) Rotation Axis Y Number Rotation axis y-direction (not normalized) Rotation Axis Z Number Rotation axis z-direction (not normalized) Rotation Angle [degrees] Number Rotation angle around the rotation axis in degrees Keywords: create, empty, image ", "tags": "", "url": "nodes.image.create_new_image.html"},
{"title": "Rename Image", "text": "Rename Class: NodeSetImageName Rename an image. Example Workflows Rename an image Inputs Image Image to be renamed. Type: Image4DFloat, Required, Single Outputs Image Renamed image. Type: Image4DFloat Settings Image Type Selection Select the input and output image type. Values: Mask, Image, Complex, Vector New Name Text Set the new name. See also Keywords: ", "tags": "", "url": "nodes.image.rename_image.html"},
{"title": "AND", "text": "AND Class: NodeMaskAnd Performs a voxel-wise boolean AND operation in all supplied masks. If a voxels is TRUE in all masks, the resulting voxel in the output mask has is TRUE, otherwise it is FALSE. Inputs In At least two binary masks of the same dimensions. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Out A binary mask with the same spatial properties as the input masks. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.boolean_algebra.and.html"},
{"title": "NOT", "text": "NOT Class: NodeMaskNot Inverts a binary mask. For each voxel, the output is TRUE if input is FALSE and vice versa. Inputs In A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.boolean_algebra.not.html"},
{"title": "OR", "text": "OR Class: NodeMaskOr Performs a voxel-wise boolean OR operation in all supplied masks. If at least one input voxel is TRUE, the resulting voxel in the output mask is TRUE, otherwise it is FALSE. Inputs In At least two binary masks of the same dimensions. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Out A binary mask with the same spatial properties as the input masks. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.boolean_algebra.or.html"},
{"title": "XOR", "text": "XOR Class: NodeMaskXor Performs a voxel-wise boolean XOR operation in all supplied masks. If an odd number of input voxels are TRUE, the resulting voxel in the output mask is TRUE, otherwise it is FALSE. Inputs In At least two binary masks of the same dimensions. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Out A binary mask with the same spatial properties as the input masks. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.boolean_algebra.xor.html"},
{"title": "Erode", "text": "Erode Class: NodeMaskErode Erode a mask using binary morphology. Morphological erosion shrinks the boundary of a region of foreground pixels, i.e. pixels with value True, using a kernel. The resuling region is obtained by letting the kernel trace the boundary of the region, and removing voxels that cannot be reached by the center of the kernel. Fig. 1. The original mask (in gray) is eroded using a &ldquo;cross&rdquo; kernel, resulting in the white mask. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Erosion in SimpleITK Erosion on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.erode.html"},
{"title": "Dilate", "text": "Dilate Class: NodeMaskDilate Dilate a mask using binary morphology. Morphological dilation expands the boundary of a region of foreground pixels, i.e. pixels with value True, using a kernel. The resuling region is obtained by letting the kernel center trace the boundary of the region, and the resulting region includes all voxels that can be reached by the kernel. Fig. 1. The original mask (in gray) is dilated using a &ldquo;cross&rdquo; kernel, resulting in the white mask. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Dilation in SimpleITK Dilation on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.dilate.html"},
{"title": "Opening", "text": "Opening Class: NodeMaskOpening Apply the morphological opening operation on a binary mask. The morphological opening of a binary mask \(I\) is defined as the dilation of the erosion of the mask: \(\textrm{Opening}\left(I\right) = \textrm{Dilatation}\left(\textrm{Erosion}\left(I\right)\right)\). This filter removes small foreground structures in the mask. The size of the affected structures is controlled by the shape and size of the kernel. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Opening in SimpleITK Opening on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.opening.html"},
{"title": "Closing", "text": "Closing Class: NodeMaskClosing Apply the morphological closing operation on a binary mask. The morphological closing of a binary mask \(I\) is defined as the erosion of the silation of the mask: \(\textrm{Closing}\left(I\right) = \textrm{Erosion}\left(\textrm{Dilation}\left(I\right)\right)\). This filter removes small background structures such as holes in the mask. The size of the affected structures is controlled by the shape and size of the kernel. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. Safe Border Boolean A safe border is added to input image to avoid borders effects. It is removed after the closing operation is done. References Closing in SimpleITK Closing on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.closing.html"},
{"title": "Opening by Reconstruction", "text": "Opening by Reconstruction Class: NodeMaskOpeningByReconstruction This node preserves foreground regions that can completely contain the structuring element, and removes regions of foreground pixels that cannot contain the structuring element. Contrary to the morphological opening, the opening by reconstruction preserves the shape of the components that are not removed by erosion. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Opening by reconstruction in SimpleITK Opening by reconstruction on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.opening_by_reconstruction.html"},
{"title": "Closing by Reconstruction", "text": "Closing by Reconstruction Class: NodeMaskClosingByReconstruction This node removes holes in foreground components that will not completely fit the structuring element. Contrary to morphological closing, closing by reconstruction preserves the external shape of the foreground components. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Kernel Selection The shape of the structuring element. Values: Annulus, Ball, Box, Cross Radius X Integer The radius of the kernel in the X direction, specified in voxels. Radius Y Integer The radius of the kernel in the Y direction, specified in voxels. Radius Z Integer The radius of the kernel in the Z direction, specified in voxels. References Closing by reconstruction in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.closing_by_reconstruction.html"},
{"title": "Seed Reconstruction", "text": "Seed Reconstruction Class: NodeMaskSeedReconstruction Extracts connected regions in the input mask using seeds from the seed image. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Seed A binary mask with the same spatial properties as the input mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same dimensions as the input mask. Type: Image4DBool Settings Diagonal Connections Boolean If True, diagonal voxels will be considered when the regions are segmented. See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.seed_reconstruction.html"},
{"title": "Fill Hole", "text": "Fill Hole Class: NodeMaskFillHole Remove holes not connected to the boundary of the mask.Note: Geodesic morphology and the Fillhole algorithm is described in Chapter 6 of Pierre Soille's book &lsquo;Morphological Image Analysis: Principles and Applications&rsquo;, Second Edition, Springer, 2003. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Fully Connected Boolean Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. For objects that are 1 pixel wide, use FullyConnectedOn. Slicewise Boolean Perform the fill hole operation slice by slice. References 1.Fill hole in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.fill_hole.html"},
{"title": "Contour Interpolation", "text": "Interpolate mask Class: NodeMaskInterpolate Generates interpolated contours in empty slices in the specified slice orientation. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Result A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Orientation Selection Specifies the orientation of slices. E.g. if slice orientation is XY, slice interpolation will be in the z-direction. Values: XY, XZ, YZ See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.contour_interpolation.html"},
{"title": "Bounding Box", "text": "Bounding box Class: NodeMaskBounds Create a mask which defines the bounding box of the input mask. This bounding box is the smallest rectangular parallelepiped with sides parallel to the i, j and k axes that contains all TRUE voxels in the input mask. Inputs In A binary mask. Type: Image4DBool, Required, Multiple Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.bounding_box.html"},
{"title": "Contour", "text": "Contour Class: NodeMaskContour Creates contours of all connected regions in the input mask. Boundary voxels are kept TRUE, while the interior voxels are set to FALSE. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool Settings Fully Connected Boolean Sets whether the connected components are defined strictly by face connectivity or by face+edge+vertex connectivity. For objects that are 1 pixel wide, use FullyConnectedOn. Slicewise Boolean Perform the morphological operation on a slice-by-slice basis. References BinaryContourImage in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.contour.html"},
{"title": "Thinning", "text": "Thinning Class: NodeMaskThinning This node will produce a skeleton of each foreground object in the mask. The algorithm corresponds with the 2D implementation described in:Rafael C.Gonzales and Richard E.Woods.Digital Image Processing.Addison Wesley, 491-494, (1993). Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask with the same spatial properties as the input mask. Type: Image4DBool References Thinning filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.morphology.thinning.html"},
{"title": "Hausdorff Distance", "text": "Hausdorff Distance Class: NodeMaskHausdorff Computes the Hausdorff distance and average Hausdorff distance between the set of non-zero pixels of two images. The Hausdorff distance measures the degree of mismatch between two sets. The average Hausdorff distance is the Hausdorff distance averaged over all points in the two masks. To get the Hausdorff distance (HD), one first calculates the shortest distance from every point in one set to the other set, and find the maximum of all the shortest distances. This is called the one-sided HD (hd). This is done for both sets. The Hausdorff distance is the maximum of the one-sided HDs of the two sets. In essence, the HD is the is the longest distance one has to travel from a point in one of the two sets to its closest point in the other set. This measure is a good indication of the difference between two sets, such as e.g. a segmentation mismatch. If more than two images are supplied to the node, the Hausdorff distance will be calculated between all combinations of input masks. Example workflows Haussdorff Distance example Inputs Masks At least two binary masks of the same size. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Distances A Data table with four columns: Mask 1, Mask 2, Hausdorff Distance and Average Hausdorff distance Type: DataCollection References Hausdorff Distance in SimpleITK Hausdorff Distance on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.mask.analysis.hausdorff_distance.html"},
{"title": "Maurer Distance", "text": "Maurer Distance Class: NodeMaskMaurerDistance This filter calculates the Euclidean distance transform of a binary image in linear time for arbitrary dimensions. Each voxel value in the resulting image represents the euclidian distance to the closest edge voxel in the mask. By default, voxels inside the TRUE values of a mask are the negative euclidian distance to the cloeset edge voxel. Inputs Image Input mask. Type: Image4DBool, Required, Single Outputs Output Resulting distance map. Type: Image4DFloat Settings Use Squared Distances Boolean Output the squared distance. Inside is Positive Boolean If TRUE, the inside distance of the mask is positive, and the outside distance from the mask is negative. Use Image Spacing Boolean If TRUE, the filter will use the spacing of the input image when calculating the distance map. References Maurer distance image filter in SimpleITK Keywords: Maurer, distance, euclidian, map, mask, binary. ", "tags": "", "url": "nodes.mask.analysis.maurer_distance.html"},
{"title": "Overlap Measures", "text": "Overlap Measures Class: NodeMaskOverlapMeasures Compute Jaccard overlap, Dice coefficient, volume similarity, false negative error and false positive error similarity of two or more binary masks. The measures are defined as follows: \(\textrm{Jaccard} = \displaystyle 2\frac{S \cap T}{S\cup T}\) \(\textrm{Dice} = \displaystyle 2\frac{S \cap T}{S + T} = \frac{2\times Jaccard}{1+Jaccard}\) \(\textrm{Volume Similarity} = 2 \displaystyle \frac{S-T}{S+T}\) \(\textrm{False Negative Error} = \displaystyle \frac{T \setminus \!\!S}{S}\) \(\textrm{False Positive Error} = \displaystyle \frac{S \setminus \!\!T}{T}\) Example Workflows Overlap measures example Inputs Masks At least two binary masks of the same size. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Measures A Data Table with seven columns: Mask 1, Mask 2, Dice, Jaccard, Volume Similarity, False Negative Error, False Positive Error Type: DataCollection Settings Slicewise Boolean Perform the analysis slice by slice. Each slice will result in one row in the output result data table. Slice Direction Selection If slicewise analysis is selected this specifies the orientation of slices. E.g. if slice orientation is XY, slice interpolation will be in the z-direction. Values: XY, XZ, YZ References Jaccard overlap on Wikipedia Dice coefficient on Wikipedia Tustison N., Gee J. Introducing Dice, Jaccard, and Other Label Overlap Measures To ITK. 2009 Dec. Overlap measures in SimpleITK See also Keywords: Jaccard overlap, Dice coefficient ", "tags": "", "url": "nodes.mask.analysis.overlap_measures.html"},
{"title": "STAPLE", "text": "STAPLE Class: NodeMaskStaple The STAPLE filter implements the Simultaneous Truth And Performance Level Estimation algorithm for generating ground truth volumes from a set of binary expert segmentations. The STAPLE algorithm treats segmentation as a pixelwise classification, which leads to an averaging scheme that accounts for systematic biases in the behavior of experts in order to generate a fuzzy ground truth volume and simultaneous accuracy assessment of each expert. The ground truth volumes produced by this filter are floating point volumes of values between zero and one that indicate the probability of each pixel being in the object targeted by the segmentation. Example Workflows STAPLE and voting workflow Inputs Masks At least two binary masks of the same size. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Probability An image with the same spatial properties as the input mask, with values between zero and one that indicate the probability of each pixel is a part of the object targeted by the segmentation. Type: Image4DFloat Fraction A Data Table that summarizes the Sensitivity and Specificity of each mask. Type: DataCollection Settings Confidence Weight Number The Confidence Weight parameter is a modifier for the prior probability that any pixel would be classified as inside the target object. This implementation of the STAPLE algorithm automatically calculates prior positive classification probability as the average fraction of the image volume filled by the target object in each input segmentation. The Confidence Weight parameter allows for scaling the of this default prior probability: if \(g_t\) is the prior probability that a pixel would be classified inside the target object, then \(g_t\) is set to \(g_t \times \textrm{ConfidenceWeight}\) before iterating on the solution. In general ConfidenceWeight should be left to the default of 1.0. Maximum Iterations Integer Set the maximum number of iterations. The STAPLE algorithm is an iterative E-M algorithm and will converge on a solution after some number of iterations that cannot be known a priori. If the maximum number of iterations is reached, the algorithm will stop iterating regardless of whether or not it has converged. This implementation of the STAPLE algorithm will find the solution to within seven digits of precision unless it is stopped early. References S Warfield, K. Zou, W. Wells, &ldquo;Validation of image segmentation and expert quality with an expectation - maximization algorithm&rdquo; in MICCAI 2002: Fifth International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer-Verlag, Heidelberg, Germany, 2002, pp. 298-306 STAPLE in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.analysis.staple.html"},
{"title": "Voting", "text": "Voting Class: NodeMaskVoting This node performs pixelwise voting among an arbitrary number of input binary images, where each image represents a segmentation of the same region in the same frame of reference. The majority value is selected for each pixel in the output mask. If a pixel has the same number of votes for TRUE and FALSE, it is set to TRUE. For two binary masks, the output is equivalent to the Boolean OR operation. Example workflows STAPLE and voting workflow Inputs Masks At least two binary images of the same size. Type: Image4DBool, Required, Multiple (Minimum = 2) Outputs Vote A binary mask with the same spatial properties as the input binary mask. Type: Image4DBool References T. Rohlfing and C. R. Maurer, Jr., &ldquo;Multi - classifier framework for atlas - based image segmentation&rdquo; Pattern Recognition Letters, 2005. Voting in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.analysis.voting.html"},
{"title": "Shape Statistics", "text": "Shape Statistics Class: NodeMaskShapeStatistics Computes shape properties of a binary mask. The following properties are calculated: Property Description Elongation The ratio of the largest principal moment to the smallest principal moment. Its value is greater or equal to 1. Equivalent Ellipsoid Diameter The diameters of the ellipsoid with the same size and ratio of all the axes as the object. The value depends on the image spacing. Equivalent Spherical Perimeter The equivalent perimeter of a hypersphere with the same volume as the object. The value depends on the image spacing. Equivalent Spherical Radius The radius of a sphere with the same volume as the region. Feret Diameter The diameter of the sphere that inclues the region. Flatness Number of Pixels Number of pixels in the region Number of Pixels on Border Number of pixels adjacent to a pixel with value FALSE. Perimeter Perimeter on Border Perimeter on Border Ratio Physical Size The volume of the region in physical units Principal Axes The principal axes of the region Principal Moments The principal moments of the region Roundness The roundness of the object Example Workflows Shape Statistics workflow Inputs Masks One or more binary masks. Type: Image4DBool, Required, Multiple Outputs Shape A Data Table with the shape properties of each binary mask. Type: DataCollection References Lehmann G., Label object representation and manipulation with ITK, Insight Journal Label shape statistics image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.analysis.shape_statistics.html"},
{"title": "Image", "text": "Mask To Image Class: NodeMaskToImage Converts a binary mask to an image. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Image An image with the same size as the input binary mask. Type: Image4DFloat Settings True Value Number Set the output intensity of all TRUE values in the mask. False Value Number Set the output intensity of all FALSE values in the mask. See also Keywords: ", "tags": "", "url": "nodes.mask.convert_to.image.html"},
{"title": "Label Map (Regions)", "text": "Mask To Label Map Class: NodeMaskToRegionImage Converts a mask to an image where all connected components in the mask are assigned a unique intensity value. The object labels start with 1 and are consecutive. The background value is labelled 0. Inputs Mask A binary mask. Type: Image4DBool, Required, Single Outputs Image A image with the same size as the input mask. Type: Image4DFloat Settings Diagonal Connections Boolean If TRUE, diagonal voxels will be considered neighbours when regions are segmented. See also Keywords: ", "tags": "", "url": "nodes.mask.convert_to.label_map_(regions).html"},
{"title": "Surface Estimation", "text": "Surface Estimation Class: NodeMaskToSurfaceEstimation This node executes a surface-fitting method for estimation of a surface from a binary volume. This process can be used to reduce aliasing artifacts which result in visualization of binary partitioned surfaces. This implementation uses a sparse field level set solver instead of the narrow band implementation described in the reference below, which may introduce some differences in how fast and how accurately (in terms of RMS error) the solution converges. Inputs Mask A binary image. Type: Image4DBool, Required, Single Outputs Output An image with the same size as the input binary image. Type: Image4DFloat Settings Maximum RMS Error Number Used to determine when the solution has converged. A lower value will result in a tighter-fitting solution, but will require more computations. Too low a value could put the solver into an infinite loop. Values should always be less than 1.0. A value of 0.07 is a good starting estimate. Iterations Integer Set the number of iterations. References Whitaker, Ross. &ldquo;Reducing Aliasing Artifacts In Iso - Surfaces of Binary Volumes&rdquo; IEEE Volume Visualization and Graphics Symposium, October 2000, pp.23-32. Antialias binary image filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.convert_to.surface_estimation.html"},
{"title": "Custom Mask From Image", "text": "Generate Mask Class: NodeMaskCustom Generates an elliptical or box shaped mask of a specified size at a specified position in the image space defined by the reference image. Example Workflows Maurer Distance example Hausdorff Distance example Inputs Reference Image Type: Image4DFloat, Required, Single Outputs Result Binary mask with the same size as the input image. Type: Image4DBool Settings Shape Selection Select the shape of the mask. Values: Ellipsoid, Box Size X (mm) Number The size of the mask in mm in the X direction. Size Y (mm) Number The size of the mask in mm in the Y direction. Size Z (mm) Number The size of the mask in mm in the Z direction. Center X (mm) Number The position of the mask in the X direction. Center Y (mm) Number The position of the mask in the Y direction. Center Z (mm) Number The position of the mask in the Z direction. See also Keywords: Create mask, ", "tags": "", "url": "nodes.mask.generate.custom_mask_from_image.html"},
{"title": "Point Cloud", "text": "Point Cloud Class: NodeMaskPointCloud Generate regularly spaced foreground objects in a reference space. The shape, size and spacing of the objects can be defined in the settings. Inputs Reference Image Type: Image4DFloat, Required, Single Outputs Result Binary mask with the same spatial properties as the input image. Type: Image4DBool Settings Point Shape Selection The shape of each point. Values: Ellipsoid, Box Size X (mm) Number The size of the point in the X direction Size Y (mm) Number The size of the point in the Y direction Size Z (mm) Number The size of the point in the Z direction Offset X (mm) Number The offset of the first point in the X direction. Offset Y (mm) Number The offset of the first point in the Y direction. Offset Z (mm) Number The offset of the first point in the Z direction. Cloud Spacing X (mm) Number The spacing between points in X direction. Spacing Y (mm) Number The spacing between points in Y direction. Spacing Z (mm) Number The spacing between points in Z direction. See also Keywords: ", "tags": "", "url": "nodes.mask.generate.point_cloud.html"},
{"title": "Crop To Bounding Box", "text": "Crop To Bounds Class: NodeMaskCropToBounds Crop the output mask dimensions to the bounding box of the values that are TRUE in the mask. Inputs In A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask. Type: Image4DBool Settings Use Frame Selection Set Largest to crop to the combined bounding box of all frames or Selected to crop to a specific frame. Values: Largest, Selected Specific Frame Integer If a selected frame is used for cropping, select the frame. See also Keywords: ", "tags": "", "url": "nodes.mask.reshape.crop_to_bounding_box.html"},
{"title": "Pad", "text": "Pad Class: NodeMaskPad Increase the size of the binary mask by padding. Inputs In A binary mask. Type: Image4DBool, Required, Single Outputs Out A binary mask. Type: Image4DBool Settings Pad Value Integer Set value of new voxels. X Lower Integer Set the number of voxels to expand the matrix with in the lower X direction. Y Lower Integer Set the number of voxels to expand the matrix with in the lower Y direction. Z Lower Integer Set the number of voxels to expand the matrix with in the lower Z direction. X Upper Integer Set the number of voxels to expand the matrix with in the upper X direction. Y Upper Integer Set the number of voxels to expand the matrix with in the upper Y direction. Z Upper Integer Set the number of voxels to expand the matrix with in the upper Z direction. References Constant Pad Image Filter in SimpleITK See also Keywords: ", "tags": "", "url": "nodes.mask.reshape.pad.html"},
{"title": "MetaIO .mhd", "text": "MHD Class: NodeExportMHDBool Convert and export all connected binary images to MHD files. Inputs In Input binary masks. Type: Image4DBool, Required, Multiple Settings Image Prefix Text Set the image prefix. This string will be added to beginning of the filename. Compress Image Boolean Use lossless gzip compression on the raw data. Export Metadata Boolean Export metadata to an XML file. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, mask, mhd ", "tags": "", "url": "nodes.mask.export.metaio_.mhd.html"},
{"title": "MATLAB .mat", "text": "MAT Class: NodeExportMATBool Convert and export all connected binary images to a MATLAB .mat-file. file. Inputs In One or more binary masks. Type: Image4DBool, Required, Multiple Settings Image Prefix Text Sets the image prefix, this string will be added to beginning of the image name. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Keywords: ", "tags": "", "url": "nodes.mask.export.matlab_.mat.html"},
{"title": "Apply To Image", "text": "Apply Mask Class: NodeMaskApply Apply a mask to an image. TRUE values in the mask will unaffected in the input image, FALSE values will be set to a specified value. Inputs Image Input image. Type: Image4DFloat, Required, Single Mask Input mask. Type: Image4DBool, Required, Single Outputs Result Resulting image. Type: Image4DFloat Settings Node Crop Image to Mask Bounds Boolean Crops the resulting image size to the bounds of the mask. Masked Voxel Value Number Voxels in the resulting image where the mask is FALSE will be set to this value. Time Series Use Frame Selection If crop Image is true, select Largest to crop to the combined bounding box of all frames or Selected to crop to a specific frame. Values: Largest, Selected Specific Frame Integer If crop image is true and a selected frame is used for cropping, select the frame. Keywords: apply, mask, image ", "tags": "", "url": "nodes.mask.apply_to_image.html"},
{"title": "Mask", "text": "Mask Class: NodeStructProcessor Selects and renders a structure to a binary mask from an RT-Struct Collection on a reference image. Example workflows Structure handling example Inputs Image The input image on which to render the structures. Type: Image4DFloat, Required, Single Structures The structure set to render. Type: RTStructCollection, Required, Single Outputs Mask The rendered mask. Type: Image4DBool Smooth Mask The rendered Smooth mask. Type: Image4DFloat Statistics Statistics regarding the mask and smooth mask, such as volumes and volume error. Volume error is the relative difference between the volume calculated directly from the polygon structure compared to the rendered binary and smooth mask. Type: DataCollection Settings Struct Selection Structure Name(s) Text Name of the structure to render, if you define several structures as a comma separated list it will render the first structure that matches. Condition Selection Condition to use when matching strings to find the structure. Values: Equals, Contains, NotEqual, DoesNotContain, Regex Case Sensitive Boolean When enabled a case sensitive string match will be used. Initial Supersampling Method Selection Sets the initial supersampling method. Values: None, Grid, Random Grid Divisions X Integer Sets the number of sub voxel divisions in the X-direction for grid supersampling. Grid Divisions Y Integer Sets the number of sub voxel divisions in the Y-direction for grid supersampling. Grid Divisions Z Integer Sets the number of sub voxel divisions in the Z-direction for grid supersampling. Number of Points Integer Sets the number of sub voxel points to generate for random supersampling. Adaptive Supersampling Adaptive Method Selection Sets the adaptive supersampling method. Can only be used if initial supersampling is used, it will resample any voxel that has a value &gt;0 and &lt;1 after the initial supersampling. Values: None, Grid, Random Adaptive Grid Divisions X Integer Sets the number of sub voxel divisions in the X-direction for grid supersampling. Adaptive Grid Divisions Y Integer Sets the number of sub voxel divisions in the Y-direction for grid supersampling. Adaptive Grid Divisions Z Integer Sets the number of sub voxel divisions in the Z-direction for grid supersampling. Adaptive Number of Points Integer Sets the number of sub voxel points to generate for random supersampling. Mask Generation Threshold(%) Number Sets how much of a single voxel that needs to be inside the structure for the voxel to be set to one in the mask. Threshold Type Selection The type of criteria used to set the resulting mask voxel to 1. Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals Structure Geometry End Cap Thickness (mm) Number Sets the end cap thickness of the structure. See also Keywords: ", "tags": "", "url": "nodes.structure.convert_to.mask.html"},
{"title": "Point Data", "text": "Point Data Class: NodeStructToData Convert connected structures into point data. RTStructs are defined as points forming a polygon on a plane. This node will export all points for all structures in the connected structure set. WARNING! The resulting data table can be very large! Consider extracting only relevant structs before applying this node. Inputs Structure Input structure. Type: RTStructCollection, Required, Single Outputs Points Resulting data table. Type: DataCollection Keywords: structure, rtstruct, data, table, point, csv ", "tags": "", "url": "nodes.structure.convert_to.point_data.html"},
{"title": "Isosurface", "text": "Isosurface Class: NodeImageIsoToStruct Transforms an image to a structure using an intensity value (iso-value) using the marching cubes algorithm. The contours are defined on the slice locations in the input image. Example workflows Image to struct example Inputs Image The input image from which to generate the structure. Type: Image4DFloat, Required, Single Outputs Structure The generated structure. Type: RTStructCollection Settings Node Frame Integer Select in which frame from which to generate the isosurface (if input is 4D). Segmentation ISO Value Number The iso (intensity) value which forms the surface of the structure. Region Extraction Mode Selection Specifies the mode that decides which regions to keep in the structure. Values: AllRegions, LargestRegions, SpecificRegions Regions to Keep Integer The number of regions to keep if LargestRegions is chosen as mode. 1 keeps the largest region, 2 keeps the two largest, and so on. Specific Regions Text Spefifies the regions to keep if SpecificRegions is chosen as mode. Structure ROI Type Selection Set the ROI Type. Values: EXTERNAL, PTV, CTV, GTV, TREATED_VOLUME, IRRAD_VOLUME, BOLUS, AVOIDANCE, ORGAN, MARKER, REGISTRATION, ISOCENTER, CONTRAST_AGENT, CAVITY, BRACHY_CHANNEL, BRACHY_ACCESSORY, BRACHY_SRC_APP, BRACHY_CHNL_SHLD, SUPPORT, FIXATION, DOSE_REGION, CONTROL, NONE ROI Name Text Set the ROI Name. See also Keywords: ", "tags": "", "url": "nodes.structure.generate_from.isosurface.html"},
{"title": "Mask", "text": "Mask Class: NodeMaskToStruct Converts a mask to a structure. Inputs Mask A binary mask. If it is a mask with multiple frames, the contours will be generated in an additive fashion, i.e. a slice contour will be produced for each frame and added to a single slice. Type: Image4DBool, Required, Single Outputs Out A structure. Type: RTStruct Settings Structure ROI Type Selection Set the ROI Type. Values: EXTERNAL, PTV, CTV, GTV, TREATED_VOLUME, IRRAD_VOLUME, BOLUS, AVOIDANCE, ORGAN, MARKER, REGISTRATION, ISOCENTER, CONTRAST_AGENT, CAVITY, BRACHY_CHANNEL, BRACHY_ACCESSORY, BRACHY_SRC_APP, BRACHY_CHNL_SHLD, SUPPORT, FIXATION, DOSE_REGION, CONTROL, NONE ROI Name Text Set the ROI Name. Decimation Decimate Boolean Reduces the number of points used to represent the structure.Note: If this option is used the resulting structure will not produce exactly the same mask if rendered again. Max Iterations Integer Set the maximum number of iterations for polygon reduction. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org See also Keywords: ", "tags": "", "url": "nodes.structure.generate_from.mask.html"},
{"title": "Point Data", "text": "Structure Class: NodeDataToStruct Convert connected structure point data into structures. Inputs Points Input data table. Type: DataCollection, Required, Single Outputs Structure Resulting RTStruct. Type: RTStructCollection Keywords: convert, points, structure, rtstruct ", "tags": "", "url": "nodes.structure.generate_from.point_data.html"},
{"title": "DICOM (RTSTRUCT)", "text": "DICOM (RTSTRUCT) Class: NodeExportRTSTRUCT Converts and exports all connected structures into one Dicom RS (RT Structure Set) file. Example workflows Export structure example Inputs Reference Image The reference image to the RT structure set. The FrameOfReference tag, as well as PatientID, Name, BirthDate, Sex, Weight and referenced SOP Instance UIDs are taken from this reference image. Type: Image4DFloat, Required, Single Structures The input structures to be exported. Type: RTStruct, Required, Multiple Settings Label Text The structure set DICOM label, tag (3006,0002). Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Note: This parameter will be overridden if you use this node for batch calculations. References RT Structure Set on dicom.nema.org See also Keywords: rs, rtstruct, structure set, ROI ", "tags": "", "url": "nodes.structure.export.dicom_(rtstruct).html"},
{"title": "Mesh (STL)", "text": "Mesh (STL) Class: NodeExportStructSTL Converts structure(s) to mesh(es) and exports it as one or several STL-files. Example workflows Export structure example Inputs Structures The input structure(s) to be exported. Type: RTStruct, Required, Multiple Settings File Prefix Text String which is added to the beginning of the filename. The last part of the filename is taken from the specific structure name. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Note: This parameter will be overridden if you use this node for batch calculations. References STLWriter on vtk See also Keywords: mesh, structure set, ROI ", "tags": "", "url": "nodes.structure.export.mesh_(stl).html"},
{"title": "Image", "text": "Struct Images Class: NodeExportStructImages Converts a RTSTRUCT to a mesh and exports it as an STL-file. Inputs Structures Missing description. Type: RTStructCollection, Required, Multiple Settings Label Text Missing description. Arrows Boolean Missing description. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. See also Keywords: ", "tags": "", "url": "nodes.structure.export.image.html"},
{"title": "Clean", "text": "Clean Class: NodeStructCleaner Removes contours from structures depending on their area. Example workflows Structure handling example Inputs In The input structure collection to be cleaned. Type: RTStructCollection, Required, Single Outputs Out The cleaned output collection. Type: RTStructCollection Settings Area (mm²) Number Area condition for the contour filter. Condition Selection The type of criteria used to match the contours, if the filter finds a matching contour that contour will be removed. Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals See also Keywords: ", "tags": "", "url": "nodes.structure.edit.clean.html"},
{"title": "Reduce", "text": "Reduce Class: NodeStructReduce Reduces the number of points of structures in a structure set by calculating the area of the parallelogram defined by 3 consecutive points on the contour. One side is defined by point 1-2 and the other by 1-3. If the area of the parallelogram is less the the stopping criteria, point 2 is discarded. The process is iterative and will be continued until maximum iterations is reached, or no more points can be discarded with set stopping criteria. Example workflows Reduce number of points in a structure set Inputs Structure The input structure set to be reduced. Type: RTStructCollection, Required, Single Outputs Out The reduced structure set. Type: RTStructCollection Settings Iterations Integer Set the maximum number of iterations for polygon reduction. Stopping Criteria Number The maximum area the parallelogram can have for a point to be removed in mm2. References 1. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.structure.edit.reduce.html"},
{"title": "Filter", "text": "Filter Class: NodeStructFilter This filter is used to filter struct collections by removing or keeping some structures depending on their name. Example workflows Structure handling example Inputs In The input RTStruct collection. Type: RTStructCollection, Required, Single Outputs Out The input RTStruct collection with some of the RTStructs removed. Type: RTStructCollection Settings Structure Name(s) Text A comma separated list of names to match. Condition Selection Condition to use when matching strings to find the structure(s). Values: Equals, Contains, NotEqual, DoesNotContain, Regex Action Selection What action should be taken when a structure matches the filter condition. Values: Discard, Keep Case Sensitive Boolean If TRUE, a case sensitive string match will be used. Keywords: RTStruct, collection, filter ", "tags": "", "url": "nodes.structure.edit.filter.html"},
{"title": "Rename", "text": "Rename Class: NodeStructRenamer Rename structures according to a set of rules defined by the user. Supports export and import of predefined sets of renaming rules. You can also use dictionaries of acceptable names to harmonize structure naming. Predefined naming rules can be supplied in a .txt or .dsv file the following format (the delimiter can be changed during the import): PATTERN;NEW NAME;CONDITION;CASE SENSITIVE where PATTERN is the character combination used to identify the structure from its original name and NEW NAME is the name that will be assigned to the structures that match the rule. CONDITION defines the condition that must be fulfilled when the pattern is compared to the old name which can be Contains; DoesNotContain; Equals; NotEqual; Regex. Most of these are self explanatory, while the term regex might not be familiar to all. It's short for regular expression, and is a sequence of characters that define a search pattern. To learn more on how to write regular expressions, this article on Wikipedia can be helpful. CASE SENSITIVE can be True;False and of course determines if the comparison between the pattern and the original name should be case sensitive. A naming convention or dictionary is simply a .txt file in the format StructureName;Description which is located in the MICE Toolkit program catalog under ...\External\Structure Naming Conventions. To add user defined naming conventions, copy the .txt file containing your naming convention to this path. The swedish naming convention published by the Swedish Radiation Safety Authority is supplied by default. Example workflows Structure handling example Inputs In The renamed struct collection. Type: RTStructCollection, Required, Single Outputs Out Resulting RTStruct collection. Type: RTStructCollection Settings Renaming Rules Text A list of rules to apply when renaming structures, the list is evaluated from top to bottom and the first matching rule will be applied. Default Action Selection This is the default action that will be applied if no rules on the list matches the structure. Values: Keep, Rename, Discard, Stop Default Name Text If the default action is &lsquo;Rename&rsquo; this is the name that non matching structures will be renamed to. Use $n to insert old structure name and $c to insert duplicate name counter. Keywords: rename, struct, rtstruct, dicom ", "tags": "", "url": "nodes.structure.edit.rename.html"},
{"title": "Merge", "text": "Merge Class: NodeStructMerge This filter is used to merge multiple struct collections into one collection. Inputs In Input structure sets. Type: RTStructCollection, Required, Multiple Outputs Out Merged output structure set. Type: RTStructCollection See also Keywords: ", "tags": "", "url": "nodes.structure.edit.merge.html"},
{"title": "Apply Transform", "text": "Transform Class: NodeStructApplyTransform Transforms structures with the connected transformix parameters. Existing initial transforms are ignored. NB: See details regarding deformable transforms under Settings - Fixed to Moving. Example workflows Apply struct transform Inputs Transform The transformix parameters to be applied. Type: TransformixParameter, Required, Single Structure The structure set which should be transformed. Type: RTStructCollection, Required, Single Reference An image reference which specifies at what slice locations the contours should be generated. If a reference is not supplied, the polygon points are still transformed, but the contours may not be coplanar. Type: Image4DFloat, Optional, Single Outputs Structure The transformed structure set. Type: RTStructCollection Settings Transform Fixed to Moving Boolean By default this node will transform the structure points from the moving image space to the fixed, set this to perform the transformation from the fixed image space to the moving. NB: This setting will only have effect on linear transforms, i.e. translation, rigid and affine transforms, since the inverse of a deformable registration can only be obtained through an optimization. To perform a moving to fixed deformable structure transform, either first invert the deformation field using the method specified in the elastix manual, or perform the inverse deformable registration. Deformable Structure Generation Min Polygon Area (mm2) Number The minimum polygon area that will be generated after a deformable transform of the structure set. Smaller structures will be disregarded. Decimation Decimate Points Boolean If set the number of points in the result will be reduced. Iterations Integer Set the maximum number of iterations for polygon reduction. Stopping Criteria Number The maximum area the parallelogram can have for a point to be removed in mm2. See Reduce. Reference Image Image Type Selection The type of image to get information from. Values: Mask, Image, Complex, Vector References 1. S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, %22elastix: a toolbox for intensity based medical image registration%22, IEEE Transactions on Medical Imaging, vol. 29, no. 1, pp. 196 - 205, January 2010. 2. D.P. Shamonin, E.E. Bron, B.P.F. Lelieveldt, M. Smits, S. Klein and M. Staring, %22Fast Parallel Image Registration on CPU and GPU for Diagnostic Classification of Alzheimer’s Disease%22, Frontiers in Neuroinformatics, vol. 7, no. 50, pp. 1-15, January 2014. 3. %22The Insight Segmentation and Registration Toolkit%22 www.itk.org See also Keywords: ", "tags": "", "url": "nodes.structure.transform.apply_transform.html"},
{"title": "Re-Slice to Image", "text": "Re-Slice Class: NodeStructReslice Re-slices the structure to fit in a new image space, i.e. creates contours at new positions. This is done by first converting the input contours to a mesh, reading the slice positions from the reference image, and producing new contours at those slice locations. Inputs Structure The input structure set which is to be re-sliced. Type: RTStructCollection, Required, Single Reference The reference image with new slice positions. Type: Image4DFloat, Required, Single Outputs Out The re-sliced structure set. Type: RTStructCollection Settings Reference Image Image Type Selection The type of image to get new slice positions from. Values: Mask, Image, Complex, Vector Structure Generation Min Polygon Area (mm2) Number Sets the minimum area a closed contour must have to be kept after re-slicing. See also Keywords: ", "tags": "", "url": "nodes.structure.transform.re-slice_to_image.html"},
{"title": "Merge Curves", "text": "Merge Class: NodeMergeCurves Merges a number of curves into one curve collection. Inputs In Curves to merge. Type: CurveCollection, Required, Multiple Outputs Out Resulting curve collection. Type: CurveCollection Settings Title Text This is the title the resulting curve collection. X-Axis Title Text This is the title for the X axis in the resulting curve collection. Y-Axis Title Text This is the title for the Y axis in the resulting curve collection. See also Keywords: ", "tags": "", "url": "nodes.data.curve.merge_curves.html"},
{"title": "Create Expression", "text": "Expression Class: NodeCurveExpression Create a custom expression for a curve with X and Y data.Special Variables:e: The natural logarithmic base.pi: The ratio of the circumference of a circle to its diameter.Some Functions:abs(x), acos(x), asin(x), atan(x), atan2(x, y), ceiling(x), cos(x), cosh(x), floor(x), log(x), log(x, b), log10(x), max(x, y), min(x, y), rand(x), rande(x), randg(o, s), randn(m, sd), round(x), sign(x), sin(x), sinh(x), sqrt(x), tan(x), tanh(x), truncate(x) Inputs In The input curve. Type: CurveCollection, Required, Single Outputs Result The resulting curve. Type: CurveCollection Settings Expression Expression for X Text The expression which should be calculated for values on the X axis. Expression for Y Text The expression which should be calculated for values on the Y axis. Result Set Infinity To Number What value should Infinity be set to. Set Undefined Numbers To Number What value should undefined numbers be set to. See also Keywords: ", "tags": "", "url": "nodes.data.curve.create_expression.html"},
{"title": "Data To Curve", "text": "Data To Curve Class: NodeDataToCurve Extracts two columns of a data collection as a curve of X and Y. Inputs In The input data collection. Type: DataCollection, Required, Single Outputs Out The output curve. Type: CurveCollection Settings Curve Title Text Set the name of the resulting curve. X Axis Text Set the title of the X axis. Y Axis Text Set the title of the Y axis. Data X Column Integer Set the column index of the data table for the X axis. Y Column Integer Set the column index of the data table for the Y axis. See also Keywords: ", "tags": "", "url": "nodes.data.curve.data_to_curve.html"},
{"title": "CSV", "text": "CSV Class: NodeExportCSV Export all connected data tables to .csv files. Inputs In Input data collection. Type: DataCollection, Required, Multiple Settings File Prefix Text Set the file prefix. This string will be added to beginning of the filename. File Suffix Text Set the file suffix. This string will be added to the end of the filename. Separator Text Define the separator character. Default value is a semicolon. (;). Write Column Headers Boolean Writes the column headers as the first line in the file, if Append to End of File setting is used this setting will be ignored. Append to End of File Boolean If set the node will append the data to the end of an existing .csv-file. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, data, csv ", "tags": "", "url": "nodes.data.export.csv.html"},
{"title": "Excel", "text": "Excel Class: NodeExportExcel Convert and export all connected data collections to excel files. Inputs In Input data table. Type: DataCollection, Required, Multiple Settings File Prefix Text Sets the file prefix, this string will be added to beginning of the filename. File Suffix Text Sets the file suffix, this string will be added to the end of the filename. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords:Excel, export, data, write, disk ", "tags": "", "url": "nodes.data.export.excel.html"},
{"title": "Data Elements", "text": "Generate Data Class: NodeDataGenerateDataElements Create a new data collection with columns and values taken from the connected data elements. Inputs Column 1 Input data element. Type: DataElement, Required, Single Outputs Out Resulting data table. Type: DataCollection Settings Input Number of Columns Integer Set the number of columns in the output data table. Node Dataset Name Text This is the name applied to the resulting data collection. See also Keywords: create, data, table, collection ", "tags": "", "url": "nodes.data.generate_from.data_elements.html"},
{"title": "Curves", "text": "Curve Data Class: NodeGenerateDataCurves Creates a new data collection with columns and values taken from the connected curves. Inputs Curves Input curve(s). Type: CurveCollection, Required, Multiple Outputs Out Output data table. Type: DataCollection Settings Data Name Text The name of the resulting data. Curve Description Text If not empty a column named description will be added with this information. Keywords: curve, data, table ", "tags": "", "url": "nodes.data.generate_from.curves.html"},
{"title": "Transpose Data", "text": "Transpose Class: NodeTransposeData Transposes data table. Inputs In The input data collection. Type: DataCollection, Required, Single Outputs Out The transposed data collection. Type: DataCollection Settings Column Names Selection Specify a naming convention for the new columns. Numbered will number each column, while FirstRow will use the first row as column headers instead of data. Values: Numbered, FirstRow Save Column Headers as First Column Boolean If set to true, the first column will contain the column headers of the original data. If set to false, the headers are lost after transposing. See also Keywords: ", "tags": "", "url": "nodes.data.transpose_data.html"},
{"title": "Extract Data", "text": "Extract Class: NodeExtractData Extract a subset of a data collection. Inputs In Inptut data table. Type: DataCollection, Required, Single Outputs Out Resulting data table. Type: DataCollection Settings Data Name Text Set the name of the resulting data collection. Column Selection Start Column Integer Set the first column to extract. Must be larger or equal to 1. Stop Column Integer Set the last column to extract. This value is ignored if &lsquo;Extract Remaining Columns&rsquo; is selected. Must be larger or equal to 1. Extract Remaining Columns Boolean If TRUE, the remaining columns after the start column will be extracted and the &lsquo;Stop Column&rsquo; value will be ignored. Row Selection Start Row Integer Set the first row to extract. Must be larger or equal to 1. Stop Row Integer Set the last row to extract. This value is ignored if &lsquo;Extract Remaining Rows&rsquo; is selected. Must be larger or equal to 1. Extract Remaining Rows Boolean If TRUE, the remaining rows after the start row will be extracted and the &lsquo;Stop Row&rsquo; value will be ignored. Keywords: data, table, subset, extract ", "tags": "", "url": "nodes.data.extract_data.html"},
{"title": "Merge Data", "text": "Merge Class: NodeMergeData Merges a number of data tables into one data table. You can merge the data horizontally (i.e. add columns) or vertically (add rows). If you wish to merge vertically, the input data tables must have the same columns in all input data. Inputs In Inpt data tables. Type: DataCollection, Required, Multiple Outputs Out Resulting data table. Type: DataCollection Settings Dataset Name Text This is the name the resulting data collection. Add Collection Column Boolean Adds a column with the name of the collection the row belongs to. Merge Direction Selection This is the direction the merge will be performed, a vertical merge will merge rows with the same column layout and a horizontal merge will add columns to the collection.Note: A vertical merge requires the connected data collections to have the same number of columns and a horizontal merge requires the same number of rows in each collection. Values: Vertical, Horizontal See also Keywords: ", "tags": "", "url": "nodes.data.merge_data.html"},
{"title": "Sort Data", "text": "Sort Class: NodeSortData Sort a data collection. Inputs In The input data collection. Type: DataCollection, Required, Single Outputs Out The sorted data collection. Type: DataCollection Settings Sort Rows Primary Column Integer Sets the primary column to sort the data by. Set to 0 to skip sorting. Sort Order Selection Sets the primary column to sort the data by. Set to 0 to skip sorting. Values: Ascending, Descending Secondary Column Integer Sets the secondary column to sort the data by. Set to 0 to skip sorting. Sort Order Selection Sets the secondary column to sort the data by. Set to 0 to skip sorting. Values: Ascending, Descending Sort Columns Order Column Headers Boolean If set to true, the columns will be ordered by their header names. Sort Order Selection Sets the order to sort the columns by. Values: Ascending, Descending See also Keywords: ", "tags": "", "url": "nodes.data.sort_data.html"},
{"title": "Create Expression", "text": "Expression Class: NodeDataExpression Calculates new column data with a user defined expression. Expressions can contain variables from several columns, and can be output either in the original data collection or as a new single column data collection. Inputs In The input data collection. Type: DataCollection, Required, Single Outputs Result The resulting data collection. Type: DataCollection Settings Data Column Indices Text Specify which columns that should be used in the expression using a comma separated list. First chosen column is designated a, second b and so on (e is reserved for the exp-function an is skipped). Expression Expression Text The expression which should be calculated on the data columns. Result Output Type Selection Overwrite results to a specific column, Append to the end, or output as New data collection. Values: Overwrite, Append, New Column Header Text Header name for results column. Set Infinity To Number What value should Infity be set to. Set Undefined Numbers To Number What value should undefined numbers be set to. Overwrite Overwrite To Column Integer Overwrite to specified column. New New Table name Text If New is selected, this is the name of the new data collection. See also Keywords: ", "tags": "", "url": "nodes.data.create_expression.html"},
{"title": "AND", "text": "AND Class: NodeBoolAnd Output is TRUE if all inputs are TRUE. Inputs In Input bits. Type: Boolean, Required, Multiple Outputs Value Resulting bit. Type: Boolean Keywords: Bool, boolean, and ", "tags": "", "url": "nodes.values.bit.boolean_algebra.and.html"},
{"title": "NOT", "text": "NOT Class: NodeBoolNot Output is TRUE if input is FALSE. Inputs In Input bit. Type: Boolean, Required, Single Outputs Value Output bit. Type: Boolean Keywords: Not, invert ", "tags": "", "url": "nodes.values.bit.boolean_algebra.not.html"},
{"title": "OR", "text": "OR Class: NodeBoolOr Output is TRUE if any input is TRUE. Inputs In Input bits. Type: Boolean, Required, Multiple Outputs Value Output bit. Type: Boolean Keywords: Boolean operations ", "tags": "", "url": "nodes.values.bit.boolean_algebra.or.html"},
{"title": "XOR", "text": "XOR Class: NodeBoolXor Output is TRUE if an odd number of inputs are TRUE. Inputs In Input bits. Type: Boolean, Required, Multiple Outputs Value Resulting bit. Type: Boolean Keywords: xor, bit, boolean ", "tags": "", "url": "nodes.values.bit.boolean_algebra.xor.html"},
{"title": "Create Constant", "text": "Bit Class: NodeGenerateBool Create a bit (true/false) value. Outputs Value Resulting bit. Type: Boolean Settings Bit Value Boolean Bit value, (TRUE/FALSE). Variable Name Text Set the name of this value. If you are using this as a batch variable make sure it is uniqe for the process Show Name Boolean Should the name be shown. Enable Batching Boolean If true the variable will be available when batching. Keywords: Bit, value, boolean, logical ", "tags": "", "url": "nodes.values.bit.generate_from.create_constant.html"},
{"title": "Number", "text": "Number To Bit Class: NodeDoubleToBool Create bit (TRUE/FALSE) value from a number, using conditionals. Inputs Double Input number. Type: Double, Required, Single Outputs Value Output bit. Type: Boolean Settings Condition Value Number The conditional value. Condition Selection The condition for returning TRUE/FALSE Values: HigherOrEqual, Higher, LowerOrEqual, Lower, Equals Show Condition Boolean Display condition in node. Keywords: double, number, float, integer, int, convert, bit, boolean, bool, condition ", "tags": "", "url": "nodes.values.bit.generate_from.number.html"},
{"title": "Text", "text": "Text To Bit Class: NodeStringToBool Create bit (TRUE/FALSE) value from a text string, using conditionals. Inputs String Input text string. Type: String, Required, Single Outputs Value Resulting bit. Type: Boolean Settings Bool Condition Value Text Conditional value. Bit Condition Selection The condition for returning TRUE/FALSE Values: Equals, Contains, NotEqual, DoesNotContain Case Sensitive Boolean Should the conditional be case sensitive. Show Condition Boolean Display condition in node. Keywords: string, text, convert, bit, boolean, bool, condition ", "tags": "", "url": "nodes.values.bit.generate_from.text.html"},
{"title": "Data Element", "text": "Number To Data Element Class: NodeBoolToDataElement Convert bit (true/false) value to a data element. Inputs Bool Input bit value. Type: Boolean, Required, Single Outputs Value Output data element. Type: DataElement Settings Column Name Text The name of the column where the bit is placed. Keywords: Bit, bool, data, element ", "tags": "", "url": "nodes.values.bit.convert_to.data_element.html"},
{"title": "Display Bit", "text": "Equals Class: NodeBoolDisplay Display the bit (true/false) value. Inputs In Bit to display. Type: Boolean, Required, Single Outputs Value Output bit, always the same as input bit. Type: Boolean ", "tags": "", "url": "nodes.values.bit.display_bit.html"},
{"title": "Add", "text": "Add Class: NodeDoubleAdd Add two or more numbers. Inputs In Input numbers to add. Type: Double, Required, Multiple Outputs Value Resulting number. Type: Double Keywords: add number, float, double, int ", "tags": "", "url": "nodes.values.number.math._operations.add.html"},
{"title": "Subtract", "text": "Subtract Class: NodeDoubleSubtract Subtract one or more numbers from a number. Inputs In Input value. Type: Double, Required, Single Sub Subtraction value. Type: Double, Required, Multiple Outputs Value Resulting value. Type: Double Keywords: subtract, value ", "tags": "", "url": "nodes.values.number.math._operations.subtract.html"},
{"title": "Multiply", "text": "Multiply Class: NodeDoubleMultiply Multiply two or more numbers. Inputs In Input number. Type: Double, Required, Multiple Outputs Value Resulting value. Type: Double See also Keywords: ", "tags": "", "url": "nodes.values.number.math._operations.multiply.html"},
{"title": "Divide", "text": "Divide Class: NodeDoubleDivide Divide one number with one or more numbers. Inputs In Input numerator. Type: Double, Required, Single Div Input denominator(s). Type: Double, Required, Multiple Outputs Value Resulting value. Type: Double See also Keywords: divide, division, number, double ", "tags": "", "url": "nodes.values.number.math._operations.divide.html"},
{"title": "Raise To Power", "text": "Raise To Power Class: NodeDoubleRaiseToPower Raise one number to the power of another number. Inputs In Input base. Type: Double, Required, Single Pow Input exponent. Type: Double, Required, Single Outputs Value Resulting value. Type: Double Keywords: power, base, exponent ", "tags": "", "url": "nodes.values.number.math._operations.raise_to_power.html"},
{"title": "Sqrt", "text": "Sqrt Class: NodeDoubleSqrt Get the square root of a number. Inputs In Input number. Type: Double, Required, Single Outputs Value Resulting value. Type: Double See also Keywords: ", "tags": "", "url": "nodes.values.number.math._operations.sqrt.html"},
{"title": "Sin", "text": "Sin Class: NodeDoubleSin Get the sine for a number. Inputs In Input number. Type: Double, Required, Single Outputs Value Resulting number. Type: Double Keywords: Math ", "tags": "", "url": "nodes.values.number.math._operations.sin.html"},
{"title": "Cos", "text": "Cos Class: NodeDoubleCos Get the cosine of a number. Inputs In Input value. Type: Double, Required, Single Outputs Value Output value. Type: Double Keywords: cos, cosine, value ", "tags": "", "url": "nodes.values.number.math._operations.cos.html"},
{"title": "Tan", "text": "Tan Class: NodeDoubleTan Get the tangent for a number. Inputs In Input value. Type: Double, Required, Single Outputs Value The tan of the input value. Type: Double Keywords: Tan ", "tags": "", "url": "nodes.values.number.math._operations.tan.html"},
{"title": "Log", "text": "Log Class: NodeDoubleLog Get the base e logarithm of a number. Inputs In input value. Type: Double, Required, Single Outputs Value Resulting value. Type: Double Keywords: natural, log, logarithm ", "tags": "", "url": "nodes.values.number.math._operations.log.html"},
{"title": "Log 10", "text": "Log 10 Class: NodeDoubleLogTen Get the base 10 logarithm of a number. Inputs In Input value. Type: Double, Required, Single Outputs Value Output value. Type: Double Keywords: log, logarithm, base, 10 ", "tags": "", "url": "nodes.values.number.math._operations.log_10.html"},
{"title": "Create Expression", "text": "Expression Class: NodeDoubleExpression Create a custom expression using the input values. The user can specify an arbitrary number of input values and bits, which are assigned a variable name, starting with \(a\). At least one value is mandatory. The variable names can then be used to create an expression to be calculated. As an example, to create a node that takes an input value \(a\), ads it to a second input value \(b\), and multiplies the result with \(e\) raised to the power of an input number \(c\), you would write: (a+b)*e^c Conditional statements are also possible. To return the largest value of two inputs \(a\) and \(b\), the following expression would be used: if(a&gt;b, a, b) Special Variables: e: The natural logarithmic base. pi: The ratio of the circumference of a circle to its diameter. Conditional statements and logical expressions: if(expression, true, false): if statement with a conditional expression, and the returned value when this expression is true and false, respectively. =, &lt;&gt;, &lt;, &gt;, ⇐, &gt;=: Comparison operators. and: Logical and. or: Logical or. xor: Logical exclusive or. not: Logical not. Inputs a The default value input. Type: Double, Required, Single Outputs Result The resulting value. Type: Double Settings Display Show Expression Boolean If TRUE, the expression will be displayed beneath the node name in the process window. Node Name Text The display name of the node in the process window. Expression Expression Text The expression which should be calculated. Inputs Numbers Integer The number of input values. Bits Integer The number of input bits. Result Set Infinity To Number What value should Infity be set to. Set Undefined Numbers To Number What value should undefined numbers be set to. Keywords: expression, math ", "tags": "", "url": "nodes.values.number.math._operations.create_expression.html"},
{"title": "Pi", "text": "Pi Class: NodeGenerateDoublePi Return the value of Pi. Outputs Value The value of Pi. Type: Double Keywords:value, pi ", "tags": "", "url": "nodes.values.number.constants.pi.html"},
{"title": "Create Constant", "text": "Number Class: NodeGenerateDouble Generate a constant number. Outputs Value Resulting number. Type: Double Settings Number Value Number Value of the output. Variable Name Text Set the name of this value. If you are using this as a batch variable make sure it is uniqe for the process. Show Name Boolean Should the name be shown. Enable Batching Boolean If true the variable will be available when batching. Keywords: Constant, create, double, float, number ", "tags": "", "url": "nodes.values.number.constants.create_constant.html"},
{"title": "Image", "text": "Numbers Class: NodeImageToDouble Extract mask properties such as size and position to values. Inputs Image Input image. Type: Image4DFloat, Required, Single Settings Position Position X Boolean The x position of the image. Position Y Boolean The y position of the image. Position Z Boolean The z position of the image. Center Position X Boolean The x position of the center of the image. Center Position Y Boolean The y position of the center of the image. Center Position Z Boolean The z position of the center of the image. Size Matrix Size X Boolean The number of voxels in the x direction. Matrix Size Y Boolean The number of voxels in the y direction. Matrix Size Z Boolean The number of voxels in the z direction. Matrix Size T Boolean The number of voxels in the t direction. Matrix Size X (mm) Boolean The physical size of the image in the x direction. Matrix Size Y (mm) Boolean The physical size of the image in the y direction. Matrix Size Z (mm) Boolean The physical size of the image in the z direction. Matrix Size T (s) Boolean The physical size of the image in the t direction. Voxel Size X Boolean The voxel size in the x direction. Voxel Size Y Boolean The voxel size in the y direction. Voxel Size Z Boolean The voxel size in the z direction. Statistics Mean Boolean The mean value of the image. Min Boolean The minimum value of the image. Max Boolean The maximum value of the image. Sum Boolean The sum of all voxel values. Standard Deviation Boolean The standard deviation of the image. Keywords: value, image, property ", "tags": "", "url": "nodes.values.number.generate_from.image.html"},
{"title": "Mask", "text": "Numbers Class: NodeMaskToDouble Extract mask properties such as size and position to values. Inputs Image Input mask. Type: Image4DBool, Required, Single Settings Position Position X Boolean The x position of the mask. Position Y Boolean The y position of the mask. Position Z Boolean The z position of the mask. Center Position X Boolean The x position of the center of the mask. Center Position Y Boolean The y position of the center of the mask. Center Position Z Boolean The z position of the center of the mask. Mass Center X Boolean The x position of the mass center of the mask. Mass Center Y Boolean The y position of the mass center of the mask. Mass Center Z Boolean The z position of the mass center of the mask. Size Matrix Size X Boolean The number of voxels in the x direction. Matrix Size Y Boolean The number of voxels in the y direction. Matrix Size Z Boolean The number of voxels in the z direction. Matrix Size T Boolean The number of voxels in the t direction. Matrix Size X (mm) Boolean The physical size of the mask in the x direction. Matrix Size Y (mm) Boolean The physical size of the mask in the y direction. Matrix Size Z (mm) Boolean The physical size of the mask in the z direction. Matrix Size T (s) Boolean The physical size of the mask in the t direction. Voxel Size X Boolean The voxel size in the x direction. Voxel Size Y Boolean The voxel size in the y direction. Voxel Size Z Boolean The voxel size in the z direction. Statistics Voxel Count Total Boolean The total number of voxels in the mask. Voxel Count True Boolean The number of TRUE voxels in the mask. Voxel Count False Boolean The number of FALSE voxels in the mask. Keywords: value, mask, property ", "tags": "", "url": "nodes.values.number.generate_from.mask.html"},
{"title": "Data", "text": "Data to Number Class: NodeDataToDouble Extract a number from a data table. Inputs Data Input Data table. Type: DataCollection, Required, Single Outputs Value Output number. Type: Double Settings Column Name Text The name of the column from where the number is extracted. Use Specific Column Number Boolean If checked the column name will be ignored and the value will be selected from a specific column number. Column Number Integer If &lsquo;Use Specific Column Number&rsquo; setting is checked the value will be selected from this column number. Row Number Integer The number will be selected from this row. Show Name Boolean If TRUE, the name of the column is displayed on the node. See also Keywords: Data, table, number ", "tags": "", "url": "nodes.values.number.generate_from.data.html"},
{"title": "Curve", "text": "Numbers Class: NodeCurveToDouble Calculate statistical properties of a curve/plot. Inputs Curve Input curve. Type: CurveCollection, Required, Single Settings Mean Boolean Calculate the mean value of the curve. Min Boolean Calculate the minimum value of the curve. Max Boolean Calculate the maximum value of the curve. Sum Boolean Calculate the sum of the curve. Standard Deviation Boolean Calculate the standard deviation of the curve. Full Width Half Maximum Boolean Try to find the full width half maximum value of the curve. Keywords: statistics, curve, numbers, mean, min, minimum, max, maximum, sum, std, standard, deviation, fwhm, full, width, half, maximum ", "tags": "", "url": "nodes.values.number.generate_from.curve.html"},
{"title": "Dicom Tag", "text": "Dicom Tag Class: NodeDicomTagToDouble Parses a DICOM tag into a number. Inputs Image Image containing the tag. Type: Image4DFloat, Required, Single Outputs Value The resulting number. Type: Double Settings Tag Text The tag to extract, private tags are defined like (gggg,eeee). Field Index Integer The index of the element to extract from the tag, if it is a single value set this to 1. Show Tag Boolean Should the tag be displayed in the node representation. See also Keywords: ", "tags": "", "url": "nodes.values.number.generate_from.dicom_tag.html"},
{"title": "Text", "text": "Number To Text Class: NodeDoubleToString Convert a number to text. Inputs Double Input number. Type: Double, Required, Single Outputs Value Resulting string. Type: String Keywords: Number, double, float, string, text, convert ", "tags": "", "url": "nodes.values.number.convert_to.text.html"},
{"title": "Data Element", "text": "Number To Data Element Class: NodeDoubleToDataElement Convert a number to a data element. Inputs Double Input number. Type: Double, Required, Single Outputs Value Output data element. Type: DataElement Settings Column Name Text The name of the column the data element should belong to. See also Keywords: double, number, data, table, element ", "tags": "", "url": "nodes.values.number.convert_to.data_element.html"},
{"title": "Display Number", "text": "Equals Class: NodeDoubleDisplay Display number value. Inputs In Input value. Type: Double, Required, Single Outputs Value Output value, identical to the input. Type: Double Keywords:display, number ", "tags": "", "url": "nodes.values.number.display_number.html"},
{"title": "Get Voxel Position", "text": "Voxel Position Class: NodeGetVoxelPosition Get the X, Y and Z center position of the specified voxel index in the attached image coordinate system. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs X The X position of the voxel. Type: Double Y The Y position of the voxel. Type: Double Z The Z position of the voxel. Type: Double Settings Voxel Index X Number Zero indexed voxel index in the X direction, fractions of voxels are supported Voxel Index Y Number Zero indexed voxel index in the Y direction, fractions of voxels are supported Voxel Index Z Number Zero indexed voxel index in the Z direction, fractions of voxels are supported Keywords: position, voxel, index ", "tags": "", "url": "nodes.values.number.get_voxel_position.html"},
{"title": "Get Voxel Index", "text": "Voxel Index Class: NodeGetVoxelIndex Gets the voxel index of the voxel at the specified position in the connected image coordinate system. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs X X component of voxel position. Type: Double Y Y component of voxel position. Type: Double Z Z component of voxel position. Type: Double Settings Position X Number X coordinate of the voxel. Position Y Number Y coordinate of the voxel. Position Z Number Z coordinate of the voxel. Keywords: Voxel, position, index ", "tags": "", "url": "nodes.values.number.get_voxel_index.html"},
{"title": "Create Constant", "text": "String Class: NodeGenerateString Create text string. Outputs Value Output text string. Type: String Settings String Value Text Text string value. Variable Name Text Set the name of this value. If you are using this as a batch variable make sure it is uniqe for the process. Show Name Boolean Should the name be shown. Enable Batching Boolean If true the variable will be available when batching. Keywords: text, string ", "tags": "", "url": "nodes.values.text.constants.create_constant.html"},
{"title": "DICOM UID", "text": "DICOM UID Class: NodeGenerateDicomUid Generate a DICOM Unique Identifier (UID). Use this node to generate UIDs that can be used when creating e.g. a new StudyInstanceUID for a many images belonging to the same study within a single workflow. Outputs Value DICOM UID Type: String See also Keywords: ", "tags": "", "url": "nodes.values.text.random.dicom_uid.html"},
{"title": "GUID", "text": "GUID Class: NodeGenerateGuid Generate a Globally Unique Identifier (GUID). It is a 128-bit integer number used to uniquely identify resources, represented as 32 hexadecimal digits displayed in five groups separated by hyphens. Outputs Value GUID string Type: String See also GUID on Wikipedia Keywords: ", "tags": "", "url": "nodes.values.text.random.guid.html"},
{"title": "Concatenate", "text": "Concatenate Class: NodeStringConcatenate Combine strings. Inputs S1 First string. Type: String, Required, Single S2 Second string. Type: String, Required, Single Outputs Value Resulting string. Type: String Settings Separator Text If not empty this text will be inserted between the strings. Keywords: concatenate, combine, string ", "tags": "", "url": "nodes.values.text.format.concatenate.html"},
{"title": "Extract Substring", "text": "Substring Class: NodeExtractSubstring Extracts a substring from a string. Inputs In Input string. Type: String, Required, Single Outputs Value Extracted string. Type: String Settings Start Index Integer Sets the start index of the substring. Length Integer Sets the length of the substring. Keywords: substring, extract, split, string ", "tags": "", "url": "nodes.values.text.format.extract_substring.html"},
{"title": "Image Metadata", "text": "Metadata Class: NodeMetadataToString Extract image metadata as a text string. Inputs Image Input image. Type: Image4DFloat, Required, Single Example Workflows Extract text from image metadata Outputs Value Output text string. Type: String Settings Image Image Type Selection The type of image to get information from. Values: Mask, Image, Complex, Vector Metadata Tag Name Text Name of the metadata tag. Use Frame Prefix Boolean If TRUE, the tag name needs to be preceded by a frame index. To extract the SOPInstanceUID from the second frame, write: 2.SopInstanceUID See also Keywords: ", "tags": "", "url": "nodes.values.text.generate_from.image_metadata.html"},
{"title": "Dicom Tag", "text": "Dicom Tag Class: NodeDicomTagToString Extract string from DICOM tag. Inputs Image The DICOM image from where the string should be extracted. Type: Image4DFloat, Required, Single Outputs Value The extracted string. Type: String Settings Tag Text The DICOM tag to be extracted. It can be selected from a the list, or written. Private tags are defined like (gggg,eeee). Field Index Integer The index of the element to extract from the tag, if it is a single value set this to 1. Show Tag Boolean Should the tag be displayed in the node representation. See also Keywords: ", "tags": "", "url": "nodes.values.text.generate_from.dicom_tag.html"},
{"title": "Data", "text": "Data to Text Class: NodeDataToString Extract text from a data table. Inputs Data Input data table. Type: DataCollection, Required, Single Outputs Value Extracted string. Type: String Settings Column Name Text Name of the column where the text is located. Use Specific Column Number Boolean If TRUE, the column name will be ignored and the value will be selected from a specific column number. Column Number Integer If &lsquo;Use Specific Column Number&rsquo; setting is checked the value will be selected from this column number. Row Number Integer The row number where the extracted text is placed. Show Name Boolean If TRUE, the column name will be shown in the node. Keywords: extract, get, string, text, data, table, ", "tags": "", "url": "nodes.values.text.generate_from.data.html"},
{"title": "Image Name", "text": "Image Name Class: NodeImageNameToString Extract image name as a string. Example Workflows Extract text from image metadata Inputs Image Input image. Type: Image4DFloat, Optional, Single Outputs Value Output name. Type: String Settings Image Type Selection The type of image to get information from. Values: Mask, Image, Complex, Vector See also Keywords: ", "tags": "", "url": "nodes.values.text.generate_from.image_name.html"},
{"title": "Data Element", "text": "Number To Data Element Class: NodeStringToDataElement Convert a string to a data element. Inputs String Input string. Type: String, Required, Single Outputs Value Output data element. Type: DataElement Settings Column Name Text The name of the column where the string is placed. Keywords: String, data, element ", "tags": "", "url": "nodes.values.text.convert_to.data_element.html"},
{"title": "Display Text", "text": "Equals Class: NodeStringDisplay Display string in the worflow. Inputs In Input string. Type: String, Required, Single Outputs Value OUtput string, identical to the input. Type: String Keywords:string, show, display ", "tags": "", "url": "nodes.values.text.display_text.html"},
{"title": "Add Database Tag", "text": "TAG Class: NodeExportTagDB Add a tag to an object in a databse. Inputs Value Input value. Type: Double, Required, Single Reference Input reference object. Type: Image4DFloat, Optional, Single Settings Tag Tag Type Selection Set the type of tag to export. Values: Bit, Number, Text Tag Name Text Set the name of the tag. Software Text Set the software version of the tag. Update Boolean If TRUE, the tag will be updated if it is already present for this series. Database Series ID Integer The SeriesID of the object in the database. Database Text Database name. Reference Image Image Type Selection The type of image to get database information from. Values: Mask, Image, Complex, Vector Keywords:Tag, database, value ", "tags": "", "url": "nodes.values.add_database_tag.html"},
{"title": "Add", "text": "Add Class: NodeVectorAdd Add two vector fields. Inputs Add Input vector fields. Type: Image4DVector3, Required, Multiple Outputs Out Resulting vector field. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: add, vector, fields ", "tags": "", "url": "nodes.vector.math._operations.add.html"},
{"title": "Subtract", "text": "Subtract Class: NodeVectorSubtract Subtract vector images. Inputs Image Input vector image. Type: Image4DVector3, Required, Single Subtract Subtraction input vector image(s). Type: Image4DVector3, Optional, Multiple Outputs Out Resulting Vector image. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: subtract, subtraction, minus, vector, field ", "tags": "", "url": "nodes.vector.math._operations.subtract.html"},
{"title": "Multiply", "text": "Multiply Class: NodeVectorMultiply Perform a scalar multiplication of each component of two or more vector images of the same size, or by a constant value defined in the settings. Inputs Multiply Images Input vector image(s). Type: Image4DVector3, Required, Multiple Outputs Out Resulting vector image. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: Vector, scalar, multiplication ", "tags": "", "url": "nodes.vector.math._operations.multiply.html"},
{"title": "Divide", "text": "Divide Class: NodeVectorDivide Perform a scalar division of each component of two or more vector images of the same size, or by a constant value defined in the settings. Inputs Image Numerator input vector image. Type: Image4DVector3, Required, Single Divide Images Denominator vector image(s). Type: Image4DVector3, Optional, Multiple Outputs Out Resulting vector image. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: vector, scalar, divide, division ", "tags": "", "url": "nodes.vector.math._operations.divide.html"},
{"title": "Ceiling", "text": "Ceiling Class: NodeVectorCeiling Perform the ceiling operation (rounding up to the closes upper integer value) on each component of the vector field. Inputs Image Input vector field. Type: Image4DVector3, Required, Single Outputs Out Resulting vector field. Type: Image4DVector3 Keywords: vector, ceiling, ceil ", "tags": "", "url": "nodes.vector.math._operations.ceiling.html"},
{"title": "Floor", "text": "Floor Class: NodeVectorFloor Perform the floor operation (rounding down to the closes lower integer value) on each component of the vector field. Inputs Image Input vector field. Type: Image4DVector3, Required, Single Outputs Result Resulting vector field. Type: Image4DVector3 See also Keywords: vector, floor ", "tags": "", "url": "nodes.vector.math._operations.floor.html"},
{"title": "Round", "text": "Round Class: NodeVectorRound Round to the closes intege value for each component of the vector field. Inputs Image Input vector image. Type: Image4DVector3, Required, Single Outputs Result Resulting vector image. Type: Image4DVector3 Keywords: round, vector, field, ", "tags": "", "url": "nodes.vector.math._operations.round.html"},
{"title": "Dot Product", "text": "Dot Product Class: NodeVectorDotProduct Calculate the dot product of two vector fields of the same size. Inputs v1 Input vector field. Type: Image4DVector3, Required, Single v2 Input vector field. Type: Image4DVector3, Optional, Single Outputs Out Resulting scalar field. Type: Image4DFloat Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: dot, product, vector, multiplication ", "tags": "", "url": "nodes.vector.math._operations.dot_product.html"},
{"title": "Cross Product", "text": "Cross Product Class: NodeVectorCrossProduct Calculate the cross product of two vector fields. Inputs v1 The first input vector field. Type: Image4DVector3, Required, Single v2 The second input vector field. Type: Image4DVector3, Optional, Single Outputs Out Resulting vector field. Type: Image4DVector3 Settings Scalar X Number A value used to perform the calculation if no secondary image is connected. Scalar Y Number A value used to perform the calculation if no secondary image is connected. Scalar Z Number A value used to perform the calculation if no secondary image is connected. Keywords: cross, product, vector, field ", "tags": "", "url": "nodes.vector.math._operations.cross_product.html"},
{"title": "Invert Displacement Field", "text": "Invert Class: NodeVectorInvertDisplacement Inverts a displacement field using a fixed-point approach. Inputs Image Input vector field. Type: Image4DVector3, Required, Single Outputs Output Resulting inverted vector field. Type: Image4DVector3 Settings Interpolator Selection Specifies which interpolation method should be used for the resampling. Default is Linear interpolation. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc Iterations Integer Set the number of iterations. References Chen, Mingli &amp; Lu, Weiguo &amp; Chen, Quan &amp; Ruchala, Kenneth &amp; H Olivera, Gustavo. (2008). A simple fixed-point approach to invert a deformation field. Medical physics. 35. 81-8. 10.1118/1.2816107. Inverse Displacement Field in SimpleITK Keywords: Invert, vector, field, displacement ", "tags": "", "url": "nodes.vector.math._operations.invert_displacement_field.html"},
{"title": "Principal Component Analysis", "text": "PCA Class: NodeVectorPCA Principal component analysis (PCA) is a method that is often used to reduce the dimensionality of data, by transforming a large set of variables into a smaller one that still contain most of the information contained in the full dataset. It can make data easier to explore and visualize. By expressing the dataset in terms of componenents (combination of variables) that contributes most to the variation in the data, the number of variables used to describe the dataset can be reduced. The cost is that some high-frequency information is lost (which can be used as a noise reduction technique). The figure shows PCA of a 2D dataset. After PCA, component 2 contains very little information and practically all of the variance in the dataset is described by component 1. The PCA in MICE is based on Extreme Optimization. Inputs Image The input image to be analyzed. Type: Image4DVector3, Required, Single Mask A mask defining which area should be included in the analysis. Must have the same matrix size as the input image. Type: Image4DBool, Optional, Single Outputs Components The components found using PCA. Will have have the same dimensionality as the input data, i.e. if you input 3 frames of a time series and perform PCA along the T dimension, the number of components will be 3. Type: Image4DVector3 Prediction The prediction of the input data using the Number of Components defined in the Node settings. Type: Image4DVector3 Data A table containing the eigen values and eigen vectors of the components. Type: DataCollection Settings Scaling Method Selection When the variables in a PCA analysis use very different scales, the principal components will give more weight to the variable with the larger values. To put all variables on an equal footing, the variables are often scaled. The ScalingMethod property determines if and how this transformation is performed. This value is of type ScalingMethod which can take on the following values: Property Description None No scaling is performed. UnitVariance The columns are scaled to have unit variance. This is the default. VectorNorm The columns are scaled to have unit norm. Pareto The columns are scaled by the square root of the standard deviation. Range The columns are scaled to have unit range (difference between largest and smallest value). Level The columns are scaled by the column mean. Values: None, UnitVariance, VectorNorm, Pareto, Range, Level Number of Components Integer The number of components that is used to recreate the prediction of the output data, given the input data. If the number of components is set to the same number as the dimensionality of the input data, the output will equal the input. If set to a lower value, it will contain less noise. Dimension Selection Along which image dimension should the PCA be performed. Values: X, Y, Z, T Zero Variance Compensation Number If value scaling is used this value will be added to one element of columns with no variance, otherwise the scaling will fail. References Principal component analysis on Wikipedia Principal component analysis on Extreme Optimization Keywords: Principal component analysis, dimensionality reduction, noise reduction, eigen values, eigen vectors ", "tags": "", "url": "nodes.vector.math._operations.principal_component_analysis.html"},
{"title": "Jacobian Determinant", "text": "Jacobian Determinant Class: NodeVectorJacobian Compute the jacobian determinant of a vector field. The jacobian determinant describes the deformation in each voxel; a value less than 1 implies a local compression, a value larger than 1 implies a local expansion. Inputs In Input vector image. Type: Image4DVector3, Required, Single Outputs Out Output jacobian determinant value map. Type: Image4DFloat References The Jacobian Determinant filter in SimpleITK Jacobian determinant information on Wikipedia See also Keywords: ", "tags": "", "url": "nodes.vector.math._operations.jacobian_determinant.html"},
{"title": "Normalize", "text": "Normalize Class: NodeVectorNormalize Normalize the vector field. Each [x,y,z] vector is scaled to unit length, i.e. so that the norm is 1. Inputs v Input image. Type: Image4DVector3, Required, Single Outputs Out Resulting rescaled image. Type: Image4DVector3 Keywords: Normalize, rescale ", "tags": "", "url": "nodes.vector.math._operations.normalize.html"},
{"title": "Image", "text": "Vector To Image Class: NodeVectorToImage Convert vector field properties or components to an image. Inputs v Input vector field. Type: Image4DVector3, Required, Single Outputs Image Output image. Type: Image4DFloat Settings Image Value Selection Select the output scalar property of the vector field. Values: Norm, NormSquared, NormX, NormY, NormZ, NormXY, NormXZ, NormYZ, ValueX, ValueY, ValueZ See also Keywords: vector, field, image, Norm, NormSquared, NormX, NormY, NormZ, NormXY, NormXZ, NormYZ, ValueX, ValueY, ValueZ ", "tags": "", "url": "nodes.vector.convert_to.image.html"},
{"title": "Elastix Transform", "text": "Transform to Vector Class: NodeDeformationAnalysis Takes a transformix parameter input and will output the movement in each pixel of the fixed image as a vector image. If an image reference is supplied, the movement will be evaluated at the voxel positions of the image reference. Note that this is much slower. This node is especially useful for analyzing deformations resulting from non-rigid image registrations. Input points are specified in the fixed image domain, since the transformation direction is from fixed to moving image. Example workflows Deformation analysis example Inputs Image Reference Optional input image. If supplied, the deformation will be evaluated at the voxel positions of the image reference. Type: Image4DFloat, Optional, Single Transformix The transformix parameter input to be evaluated. Type: TransformixParameter, Required, Single Mask Optional mask. Only voxel positions marked as true will be evaluated. Only applies if an optional image reference is supplied. Type: Image4DBool, Optional, Single Outputs Deformation The deformation field at the specified voxel positions. Type: Image4DVector3 Settings Ignore Existing Initial Transform Boolean Ignores the initial transform specified in the parameters file. References S. Klein, M. Staring, K. Murphy, M.A. Viergever, J.P.W. Pluim, 2010. &ldquo;elastix: a toolbox for intensity based medical image registration&rdquo; See also Keywords: registration, elastix ", "tags": "", "url": "nodes.vector.create_from.elastix_transform.html"},
{"title": "XYZ Images", "text": "Images To Vector Class: NodeVectorGenerateImages Create a vector field from three scalar images, defining the x, y and z components of the vector field. Inputs X X component of the vector field. Type: Image4DFloat, Required, Single Y Y component of the vector field. Type: Image4DFloat, Required, Single Z Z component of the vector field. Type: Image4DFloat, Required, Single Outputs Vector Field Resulting vector field. Type: Image4DVector3 Keywords: create, vector, field, component, image ", "tags": "", "url": "nodes.vector.create_from.xyz_images.html"},
{"title": "MetaIO .mhd", "text": "MHD Class: NodeExportMHDVector3 Export all connected vector images to MHD files. Voxel values will be written as they are with no quantization, this might lead to very large files in some cases. Inputs In Input vector image(s). Type: Image4DVector3, Required, Multiple Settings Image Prefix Text Set the image prefix. This string will be added to beginning of the image name. Compress Image Boolean Copress the output image without loss of data. Export Metadata Boolean If TRUE, an XML file containing image metadata will be exported. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, vector, field, mhd ", "tags": "", "url": "nodes.vector.export.metaio_.mhd.html"},
{"title": "MATLAB .mat", "text": "MAT Class: NodeExportMATVector3 Export all connected images to Matlab MAT files. Voxel values will be written as they are with no quantization, this might lead to very large files in some cases. Inputs In Input vector images. Type: Image4DVector3, Required, Multiple Settings Image Prefix Text Set the image prefix. This string will be added to beginning of the image name. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, matlab, mat, .mat, vector ", "tags": "", "url": "nodes.vector.export.matlab_.mat.html"},
{"title": "Magnitude/Phase Images", "text": "Complex Class: NodeComplexToPMImage Calculate the magnitude and phase component images from a complex image. Inputs Image Input complex image. Type: Image4DComplex, Required, Single Outputs Magnitude Output magnitude image. Type: Image4DFloat Phase Output phase image. Type: Image4DFloat Keywords: Complex, phase, magnitude, convert ", "tags": "", "url": "nodes.complex.convert_to.magnitudephase_images.html"},
{"title": "Real/Imaginary Images", "text": "Complex Class: NodeComplexToImage Calculate the real and imaginary component images from a complex image. Inputs Image Input complex image. Type: Image4DComplex, Required, Single Outputs Real Output real component of the complex image. Type: Image4DFloat Imaginary Output imaginary component of the complex image. Type: Image4DFloat Keywords: complex, image, real, imaginary ", "tags": "", "url": "nodes.complex.convert_to.realimaginary_images.html"},
{"title": "Magnitude/Phase Images", "text": "Complex Class: NodeComplexGeneratePMImages Generate a complex image from magnitude and phase images. Inputs Magnitude Input magnitude image. Type: Image4DFloat, Required, Single Phase Input phase image. Type: Image4DFloat, Required, Single Outputs Image Resulting complex image. Type: Image4DComplex Keywords: complex, magnitude, phase ", "tags": "", "url": "nodes.complex.generate_from.magnitudephase_images.html"},
{"title": "Real/Imaginary Images", "text": "Complex Class: NodeComplexGenerateImages Generate a complex image from real and imaginary images. Inputs Real The real component of the complex image. Type: Image4DFloat, Required, Single Imaginary The imaginary component of the complex image. Type: Image4DFloat, Required, Single Outputs Image Resulting complex image. Type: Image4DComplex Keywords:Complex, image, real, imaginary ", "tags": "", "url": "nodes.complex.generate_from.realimaginary_images.html"},
{"title": "MetaIO .mhd", "text": "MHD Class: NodeExportMHDComplex Export all connected complex images to MHD files. Voxel values will be written with no quantization, this might lead to very large files in some cases. Inputs In Input complex images. Type: Image4DComplex, Required, Multiple Settings Image Prefix Text Set the image prefix. This string will be added to beginning of the image name. Compress Image Boolean Compress the output image without loss of data. Export Metadata Boolean If TRUE, an XML file containing image metadata will be exported. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: export, mhd, complex ", "tags": "", "url": "nodes.complex.export.metaio_.mhd.html"},
{"title": "MATLAB .mat", "text": "MAT Class: NodeExportMATComplex Converts and exports all connected images to Matlab MAT files. Voxel values will be written as they are with no quantization, this might lead to very large files in some cases.Note: No DICOM metadata will be written to the MAT file. Inputs In Input complex image. Type: Image4DComplex, Required, Multiple Settings Image Prefix Text Sets the image prefix, this string will be added to beginning of the image name. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Keywords: Matlab, export, complex ", "tags": "", "url": "nodes.complex.export.matlab_.mat.html"},
{"title": "PDF", "text": "PDF Class: NodeExportPDF Generates a PDF report from the connected data. Inputs Images Optional input images. Type: Image4DFloat, Optional, Multiple Tables Optional input Data Tables. Type: DataCollection, Optional, Multiple Plots Optional input plots. Type: CurveCollection, Optional, Multiple Settings Export Filename Text Sets the file prefix, this string will be added to beginning of the filename. Path Text Set the output directory of the node.Note: This parameter will be overridden if you use this node for batch calculations. Report Report Title Text Sets the title of the report. Text Section Text Title Text Sets the title of the text section, if empty no title will be added. Text Text Sets the text of the text section. Image Section Image Title Text Sets the title of the image section, if empty no title will be added. Images Per Row Integer Sets the number of images per row in the image section. Image Font Size Number Sets the font size of the description below the image. Middle Slice Only Boolean Export only the middle slice in the stack. Colormap Selection Select the colormap to use for the images. Values: BlackBody, Bone, Cividis, Cool, Copper, Dose, GE, Gray, InverseGray, Inferno, Jet, Magma, Moreland, Pink, Plasma, Sokoloff, Spring, Summer, Viridis, Winter Full Range Window Boolean If selected, the image intensity min and max bounds will be the min and max of the image. Window Min Number Set the intensity min (applies only if the Full range window option is false). Window Max Number Set the intensity max (applies only if the Full range window option is false). Table Section Table Title Text Sets the title of the table section, if empty no title will be added. Max Columns Integer Sets the number of columns to include, if set to 0 all columns will be included. Round Numbers Boolean If set, the numeric values will be rounded to the number of decimals set. Decimals Integer Sets the number of decimals to round numbers to. Odd/Even Row Indication Boolean If set, a slightly darker background will be drawn for even rows. Table Font Size Number Sets the font size of the tables. Plot Section Plot Title Text Sets the title of the plot section, if empty no title will be added. Keywords: pdf, report, export, disk ", "tags": "", "url": "nodes.applications.reports.pdf.html"},
{"title": "Brainweb MR BETA", "text": "Brainweb MR Class: NodePhantomBrainwebMR This node is a tool for generating parameter maps relevant for magnetic resonance images, e.g. T1 and T2 maps. The node is based on the BrainWeb Phantom and two different brain datasets are available. Example Workflows Create T1, T2, T2* and PD maps Outputs PD [Optional output] Proton density map. Type: Image4DFloat T1 [Optional output] T1 map in units of seconds. Type: Image4DFloat T2 [Optional output] T2 map in units of seconds. Type: Image4DFloat T2* [Optional output] T2* map in units of seconds. Type: Image4DFloat X [Optional output] Magnetic susceptibility map. Type: Image4DFloat CSF [Optional output] Cerebrospinal fluid (CSF) map. Fraction of tissue in each pixel that is CSF. Type: Image4DFloat Skull [Optional output] Skull tissue map. Fraction of tissue in each pixel that is skull. Type: Image4DFloat Dura Mater [Optional output] Dura mater tissue map. Fraction of tissue in each pixel that is dura mater. Type: Image4DFloat Fat [Optional output] Fat tissue map. Fraction of tissue in each pixel that is fat. Type: Image4DFloat Connective [Optional output] Connective tissue map. Fraction of tissue in each pixel that is connective tissue. Type: Image4DFloat Bone Marrow [Optional output] Bone marrow tissue map. Fraction of tissue in each pixel that is bone marrow. Type: Image4DFloat Muscles [Optional output] Muscle tissue map. Fraction of tissue in each pixel that is muscle. Type: Image4DFloat Muscles Skin [Optional output] Muscles or skin tissue map. Fraction of tissue in each pixel that is muscle or skin and not counted as muscle. Type: Image4DFloat Gray Matter [Optional output] Gray matter map. Fraction of tissue in each pixel that is gray matter. Type: Image4DFloat White Matter [Optional output] White matter map. Fraction of tissue in each pixel that is white matter. Type: Image4DFloat Vessels [Optional output] Vessel map. Fraction of tissue in each pixel that are vessels. Type: Image4DFloat Background [Optional output] Map indicating if a pixel is background. Type: Image4DFloat Settings Phantom Subject Selection Select dataset from which the maps or masks should be generated. Values: Subject04, Subject05 Tissue Parameters Text Edit the tissue specific parameter values used in the image generation. Source Tissues Specify what tissues to be used when generating parameter maps. By default all tissues are selected. CSF Boolean Use CSF tissue for parameter maps generation. Skull Boolean Use skull tissue for parameter maps generation. Dura Mater Boolean Use dura mater tissue for parameter maps generation. Fat Boolean Use fat tissue for parameter maps generation. Connective Boolean Use connective tissue for parameter maps generation. Bone Marrow Boolean Use bone marrow tissue for parameter maps generation. Muscles Boolean Use muscle tissue for parameter maps generation. Muscles Skin Boolean Use muscle/skin tissue for parameter maps generation. Gray Matter Boolean Use gray matter for parameter maps generation. White Matter Boolean Use white matter for parameter maps generation. Vessels Boolean Use vessels for parameter maps generation. Output Maps Specify what type of parameter maps to generate. PD Boolean Enable proton density map output. T1 [ms] Boolean Enable T1 map output. T2 [ms] Boolean Enable T2 map output. T2* [ms] Boolean Enable T2* map output. X Boolean Enable susceptibility map output. Ktrans [min⁻¹] Boolean Enable Ktrans map output. ve Boolean Enable ve map output. vp Boolean Enable vp map output. Output Tissues Specify which tissue masks to generate. CSF Boolean Enable CSF tissue fraction map output. Skull Boolean Enable skull tissue fraction map output. Dura Mater Boolean Enable dura mater tissue fraction map output. Fat Boolean Enable fat fraction map output. Connective Boolean Enable connective tissue fraction map output. Bone Marrow Boolean Enable bone marrow tissue fraction map output. Muscles Boolean Enable muscles tissue fraction map output. Muscles Skin Boolean Enable muscles/skin tissue fraction map output. Gray Matter Boolean Enable gray matter fraction map output. White Matter Boolean Enable white matter fraction map output. Vessels Boolean Enable vessels fraction map output. Output Masks Background Boolean Enable background map output. Geometry Settings determining the geometry of the generated maps. Edit Boolean Enable modification of geometry. Note: If not set, all geometry settings will be ignored and a default image size will be created. Matrix X Integer Number of pixels in x-direction. Matrix Y Integer Number of pixels in y-direction. Matrix Z Integer Number of pixels in z-direction. Resolution X [mm] Number Resolution in x-direction, i.e. the size (in mm) of a pixel in the x-direction. Resolution Y [mm] Number Resolution in y-direction, i.e. the size (in mm) of a pixel in the y-direction. Resolution Z [mm] Number Resolution in z-direction, i.e. the size (in mm) of a pixel in the z-direction. Position offset RL [mm] Number Image offset in the x-direction. Position offset AP [mm] Number Image offset in the y-direction. Position offset SI [mm] Number Image offset in the y-direction. Rotation axis RL Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in RL-direction. The rotation vector does not need to be normalized. Rotation axis AP Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in AP-direction. The rotation vector does not need to be normalized. Rotation axis SI Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in SI-direction. The rotation vector does not need to be normalized. Rotation Angle [degrees] Number The angle to rotate the image around the rotation axis. See the setting: Rotation axis RL/AP/SI. Extrapolation value Number Value of voxels outside the phantom. Interpolator Selection Interpolator used when resampling data. Values: NearestNeighbour, Linear, BSpline, Gaussian, BlackmanWindowedSinc, CosineWindowedSinc, HammingWindowedSinc, LanczosWindowedSinc, WelchWindowedSinc References 1. http://www.bic.mni.mcgill.ca/brainweb/ 2. C.A. Cocosco, V. Kollokian, R.K.-S. Kwan, A.C. Evans : %22BrainWeb: Online Interface to a 3D MRI Simulated Brain Database%22 NeuroImage, vol.5, no.4, part 2 / 4, S425, 1997-- Proceedings of 3 - rd International Conference on Functional Mapping of the Human Brain, Copenhagen, May 1997. 3. R.K.-S. Kwan, A.C. Evans, G.B. Pike : %22MRI simulation - based evaluation of image - processing and classification methods%22 IEEE Transactions on Medical Imaging. 18(11):1085 - 97, Nov 1999. 4. R.K.-S. Kwan, A.C. Evans, G.B. Pike : %22An Extensible MRI Simulator for Post - Processing Evaluation%22 Visualization in Biomedical Computing(VBC'96). Lecture Notes in Computer Science, vol. 1131. Springer-Verlag, 1996. 135-140. 5. D.L. Collins, A.P. Zijdenbos, V. Kollokian, J.G. Sled, N.J. Kabani, C.J. Holmes, A.C. Evans : %22Design and Construction of a Realistic Digital Brain Phantom%22 IEEE Transactions on Medical Imaging, vol.17, No.3, p.463--468, June 1998. 6. B. Aubert-Broche, D.L. Collins, A.C. Evans: %22A new improved version of the realistic digital brain phantom%22 NeuroImage, in review - 2006. 7. B. Aubert-Broche, M. Griffin, G.B. Pike, A.C. Evans and D.L. Collins: %2220 new digital brain phantoms for creation of validation image data bases%22 IEEE TMI, in review - 2006 See also MRI Emulator BETA, Gradient-echo contrast BETA, Spin-echo contrast BETA Keywords: BrainWeb, MRI parameter maps, Tissue maps ", "tags": "", "url": "nodes.applications.digital_phantoms.brainweb_mr_beta.html"},
{"title": "Spin-echo contrast BETA", "text": "Spin Echo Contrast Class: NodeSpinEchoContrast This node generates simulated MRI images of spin-echo type using proton density, T1 and T2 maps and signal equations. Generate a spin-echo image Inputs PD Proton density map. Type: Image4DFloat, Required, Single T1 T1 map in units of seconds. Type: Image4DFloat, Required, Single T2 T2 map in units of seconds. Type: Image4DFloat, Required, Single Outputs Signal The calculated image. Type: Image4DFloat Settings Contrast Selection Select type of contrast. For SpinEcho the signal is cacluated using: \[ \begin{equation} S = PD\cdot(1-2e^{-(TR-TE/2)/T_1}+e^{-TR/T_1})e^{-TE/T_2} \end{equation} \] For InversionRecovery the signal is cacluated using: \[ \begin{equation} S = PD\cdot(1-2e^{-TI/T_1}+e^{-TR/T_1})e^{-TE/T_2} \end{equation} \] Values: SpinEcho, InversionRecovery Repetition time [ms] Number The repetition time (TR). Echo time [ms] Number The repetition time (TE). Inversion time [ms] Number The repetition time (TI). See also Brainweb MR BETA, Gradient-echo contrast BETA Keywords: MRI, Spin-echo, Inversion recovery ", "tags": "", "url": "nodes.applications.digital_phantoms.spin-echo_contrast_beta.html"},
{"title": "Gradient-echo contrast BETA", "text": "Gradient Echo Contrast Class: NodeGradientEchoContrast This node generates simulated MRI images of gradient-echo type using proton density, T1 and T2* maps and signal equations. Example Workflows Generate a gradient-echo image Inputs PD Proton density map. Type: Image4DFloat, Required, Single T1 T1 map in units of seconds. Type: Image4DFloat, Required, Single T2* T2* map in units of seconds. Type: Image4DFloat, Required, Single Outputs Signal The calculated image. Type: Image4DFloat Settings Contrast Selection Select type of contrast. For SpoiledGradientEcho the signal is cacluated using: \[ \begin{equation} S = PD\frac{1-e^{-TR/T_1}}{1-\cos(FA) e^{-TR/T_1}} \sin(FA) e^{-TE/T_2^*} \end{equation} \] Values: SpoiledGradientEcho Repetition time [ms] Number The repetition time (TR). Echo time [ms] Number The echo time (TR). Flip angle [deg] Number Flip angle (FA) Inversion time [ms] Number Inversion/saturation time (TI) See also Brainweb MR BETA, Spin-echo contrast BETA Keywords: MRI, gradient-echo ", "tags": "", "url": "nodes.applications.digital_phantoms.gradient-echo_contrast_beta.html"},
{"title": "MRI Emulator BETA", "text": "MRI Emulator Class: NodeMRIEmulator This node is a tool for emulating magnetic resonance images for various imaging setting. It can generate contrast for spin-echo and gradient echo sequences, add realistic noise as well as simulate effects such as aliasing and fat-water-shift. Output is an image and an estimated imaging time. The node is based on the BrainWeb Phantom and two different brains datasets are available. Figure 1: Examples of some of the images that can be created using the node. Outputs MR Image Magnitude MR image. Type: Image4DFloat Imaging time An estimate of the imaging time. Type: String Settings Phantom Subject Selection Select dataset from which the MR images should be generated. Values: Subject04, Subject05 Tissue Parameters Text Edit the tissue specific parameter values used in the image generation. Geometry Settings determining the geometry of the generated image. Matrix X Integer Number of pixels in x-direction. Matrix Y Integer Number of pixels in y-direction. Matrix Z Integer Number of pixels in z-direction. Resolution X [mm] Number Resolution in x-direction, i.e. the size (in mm) of a pixel in the x-direction. Resolution Y [mm] Number Resolution in y-direction, i.e. the size (in mm) of a pixel in the y-direction. Resolution Z [mm] Number Resolution in z-direction, i.e. the size (in mm) of a pixel in the z-direction. Position offset RL [mm] Number Image offset in the x-direction. Position offset AP [mm] Number Image offset in the y-direction. Position offset SI [mm] Number Image offset in the y-direction. Rotation axis RL Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in RL-direction. The rotation vector does not need to be normalized. Rotation axis AP Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in AP-direction. The rotation vector does not need to be normalized. Rotation axis SI Number Oblique slices can be obtained by rotating the image around an axis given in three coordinates in (RL, AP, SI) directions. This setting specifies the rotation axis component in SI-direction. The rotation vector does not need to be normalized. Rotation Angle [degrees] Number The angle to rotate the image around the rotation axis. See the setting: Rotation axis RL/AP/SI. System System related settings, such as field strength. Fieldstrength Selection Select field strength of the scanner. Note that this setting only affects the SNR. To change tissue parameters such as T1 and T2 use the Tissue Parameters setting. Values: B1_5T, B3T Imaging coil Selection Select imaging coil. This will impact the SNR. The IdealCoil value will produce an image with no noise. Values: BodyCoil, HeadCoil, IdealCoil, FlexCoil Maximum Gradient Strength [mT/m] Number Select maximum gradient strength of the scanner. Currently this setting has no effect. Sequence Sequence Name Selection Select sequence. Currently the Fast spin echo only differs from spin echo in terms of imaging time. Values: SPGR, SE, IRSE, FSE, IRFSE Sequence Type Selection Select type of imaging. Values: dim2D, dim3D Phase endocing direction Selection Select the phase encoding direction. Values: dirX, dirY Pixel bandwidth [Hz] Number Bandwidth per pixel in Hertz. Number of averages Number Number of images that are averaged. Parallel imaging factor Number Parallel imaging acceleration factor. Affects SNR. Use partial Fourier Boolean Use partial Fourier to accelerate the imaging (Partial Fourier factor = 5/8). Repetition time [ms] Number The repetition time. Echo time [ms] Number The echo time. 2D settings Slice gap [mm] Number Slice gap in z-direction. Will not affect the resolution or image coverage. Only SNR will be affected since the effective slice thickness is decreased. Inversion recovery settings Inversion time [ms] Number The inversion time. Real reconstruction Boolean Reconstruct real images SPGR settings Flip angle [deg] Number The exitation flip angle. References 1. http://www.bic.mni.mcgill.ca/brainweb/ 2. C.A. Cocosco, V. Kollokian, R.K.-S. Kwan, A.C. Evans : %22BrainWeb: Online Interface to a 3D MRI Simulated Brain Database%22 NeuroImage, vol.5, no.4, part 2 / 4, S425, 1997-- Proceedings of 3 - rd International Conference on Functional Mapping of the Human Brain, Copenhagen, May 1997. 3. R.K.-S. Kwan, A.C. Evans, G.B. Pike : %22MRI simulation - based evaluation of image - processing and classification methods%22 IEEE Transactions on Medical Imaging. 18(11):1085 - 97, Nov 1999. 4. R.K.-S. Kwan, A.C. Evans, G.B. Pike : %22An Extensible MRI Simulator for Post - Processing Evaluation%22 Visualization in Biomedical Computing(VBC'96). Lecture Notes in Computer Science, vol. 1131. Springer-Verlag, 1996. 135-140. 5. D.L. Collins, A.P. Zijdenbos, V. Kollokian, J.G. Sled, N.J. Kabani, C.J. Holmes, A.C. Evans : %22Design and Construction of a Realistic Digital Brain Phantom%22 IEEE Transactions on Medical Imaging, vol.17, No.3, p.463--468, June 1998. 6. B. Aubert-Broche, D.L. Collins, A.C. Evans: %22A new improved version of the realistic digital brain phantom%22 NeuroImage, in review - 2006. 7. B. Aubert-Broche, M. Griffin, G.B. Pike, A.C. Evans and D.L. Collins: %2220 new digital brain phantoms for creation of validation image data bases%22 IEEE TMI, in review - 2006 See also Brainweb MR BETA Keywords: Magnetic resonance imaging, Image generation ", "tags": "", "url": "nodes.applications.digital_phantoms.mri_emulator_beta.html"},
{"title": "Patch Based Denoising", "text": "Denoising Class: NodePatchBasedDenoising Deprecated! Implements a denoising filter that uses iterative non-local, or semi-local, weighted averaging of image patches for image denoising. The intensity at each pixel &lsquo;p&rsquo; gets updated as a weighted average of intensities of a chosen subset of pixels from the image. Inputs Image Input image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Noise Model Selection Select model. Values: NoModel, Gaussian, Rician, Poisson Noise Sigma Number Noise std. dev. Fidelity Weight Number Set the fidelity weight. This weight prevents large deviations of the denoised image from the noisy data. Kernel Bandwidth Estimation Use Estimation Boolean If TRUE, the kernal bandwith will be estimated automatically. Fraction Pixels Number Set the fraction of voxels in the image that will be used for kernel bandwidth sigma estimation. To reduce the computational burden for computing sigma, a small random fraction of the image pixels can be used. Multiplication Factor Number Set the kernel bandwidth sigma multiplication factor used to modify the automatically-estimated kernel bandwidth sigma. At times, it may be desirable to modify the value of the automatically-estimated sigma. Typically, this number isn't very far from 1. Note: This is used only when Use Estimation is TRUE. Kernel Sigma Number Set initial kernel bandwidth estimate. Note: This is changed when Use Estimation is TRUE. Update Frequencey Integer Set the update frequency. An optimal bandwidth will be re-estimated based on the denoised image after every &lsquo;n&rsquo; iterations. Defaults to 3, i.e. bandwidth updated after every 3 denoising iteration. Filter Number Of Iterations Integer Set the number of denoising iterations to perform. Defaults to 3. Number Of Sample Patches Integer Set the number of patches to sample for each pixel. Patch Radius Integer Set the patch radius specified in physical coordinates. Patch radius is preferably set to an even number. Currently, only isotropic patches in physical space are allowed; patches can be anisotropic in voxel space. Sample Varience Number Set the variance of the domain where patches are sampled. References Patch Based Denoising in SimpleITK Patch Based Denoising base class in SimpleITK Keywords: patch, denoising, noise ", "tags": "", "url": "nodes.deprecated.patch_based_denoising.html"},
{"title": "Landweber Deconvolution", "text": "Deconvolution Class: NodeImageLandweberDeconvolution Deprecated! Deconvolve an image using the Landweber deconvolution algorithm as defined in Bertero M and Boccacci P, &ldquo;Introduction to Inverse Problems in Imaging&rdquo;, 1998. The algorithm assumes that the input image has been formed by a linear shift-invariant system with a known kernel and is best suited for images that have zero-mean Gaussian white noise.This is the base implementation of the Landweber algorithm. It may produce results with negative values. For a version of this algorithm that enforces a positivity constraint on each intermediate solution, use Projected Landweber Deconvolution. Inputs Image Input image. Type: Image4DFloat, Required, Single Kernel Kernel image. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Boundary Condition Selection Sets the method to use when calculating voxels close to the bounds of the image. Values: ZeroPad, ZeroFluxNeumannPad, PeriodicPad Output Region Mode Selection Sets the output region mode. Values: Same, Valid Alpha Number Relaxation factor. Normalize Boolean Normalize the output image by the sum of the kernel components. Iterations Integer Set the number of iterations. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.deprecated.landweber_deconvolution.html"},
{"title": "Projected Landweber Deconvolution", "text": "Deconvolution Class: NodeImageProjectedLandweberDeconvolution Deprecated! Deconvolve an image using the Landweber deconvolution algorithm as defined in Bertero M and Boccacci P, &ldquo;Introduction to Inverse Problems in Imaging&rdquo;, 1998. The algorithm assumes that the input image has been formed by a linear shift-invariant system with a known kernel and is best suited for images that have zero-mean Gaussian white noise.At each iteration, negative pixels in the intermediate result are projected (set) to zero. This is useful if the solution is assumed to always be non-negative, which is the case when dealing with images formed by counting photons, for example. Inputs Image Input image. Type: Image4DFloat, Required, Single Kernel Image to use as kernel. Type: Image4DFloat, Required, Single Outputs Output Resulting image. Type: Image4DFloat Settings Boundary Condition Selection Sets the method to use around the boundaries. Values: ZeroPad, ZeroFluxNeumannPad, PeriodicPad Output Region Mode Selection Sets the output region mode. Values: Same, Valid Alpha Number Relaxation factor. Normalize Boolean Normalize the output image by the sum of the kernel components. Iterations Integer Set the number of iterations. References &ldquo;The Insight Segmentation and Registration Toolkit&rdquo; www.itk.org ", "tags": "", "url": "nodes.deprecated.projected_landweber_deconvolution.html"},
{"title": "Getting Started", "text": "Getting Started 1. Building your first workflow 2. Introduction to nodes 3. Nodes and status lights ", "tags": "", "url": "tutorials.videos.getting_started.html"},
{"title": "Import Data", "text": "Import Data 1. Creating and Using Image Databases 2. Import DICOM data from disk to workflow ", "tags": "", "url": "tutorials.videos.import_data.html"},
{"title": "The Visualizer", "text": "The Visualizer 1. Introduction to the Visualizer 2. Drawing custom masks ", "tags": "", "url": "tutorials.videos.the_visualizer.html"},
{"title": "Organize your Workflow", "text": "Organize your Workflow 1. Introduction to group nodes 2. Repeaters 3. Expose node settings as node inputs ", "tags": "", "url": "tutorials.videos.organize_your_workflow.html"},
{"title": "Batching", "text": "Batching 1. Creating a batch analysis - the basics 2. Creating a batch analysis - using images from different exams 3. Creating a batch analysis - batching over variables ", "tags": "", "url": "tutorials.videos.batching.html"},
{"title": "1.1.0", "text": "1.1.0 October 22, 2019 In this version support for the old licensing system has been removed and keys generated in the old system will not work. If you are using and old key you need to create a new license account here to get a new free lite license. If you have a premium license in the old licensing system please contact us to receive your new license key. Changes Improved reading performance for large structure sets. Changed the way the visualization image list is ordered, the most recently added item is now always at the bottom of the list. Changed the title of images in the visualizer to display the image name as title, the name of the output is now displayed below the title. Python plugin API changed, please see below. Added new metadata structure to images. Added passing of image metadata to plugin nodes. Added new image metadata viewer. Added functionality to connect several nodes to one input at the same time. Added NIfTI export. Added support for NIfTI metadata .json files. Added save warnings when closing the application or process tab. Added import of Open Slide images (microscopy). Added MR emulator. Added run button. Added save warnings when closing. Added simplified license sign-up. Added split panel between image sets and view-port items to improve scaling. Added create image node. Added new FFT nodes. Added basic support for reading &lsquo;Parametric Map&rsquo; type DICOM images containing float pixel data. Bug Fixes Fixed NIfTI import node not being able to parse certain orientations correctly. Fixed bug related to missing metadata in some images. Fixed license use for multiple users using the same machine. Fixed EUD normalization error. Fixed multiple inputs on plugin nodes. Fixed 2D/2D registration requiring 3D images. Fixed bug when batching MIQA database images with name &lsquo;No Description&rsquo;. Fixed saving bug in plugin editor where the asterisk indicating changes wasn't removed when saving. Fixed bool values in plugins to be either True or False, not 1 and 0. Fixed generation of the InputPaths variable in plugins. General Changes Updated SimpleITK to 1.2.0. Updated UI layout. Plugins We have made substantial changes to the Python plugin API, so if you want to use your old plugins you will probably have to update the code. We have also added import and export of image metadata to all images sent to and from python and MATLAB plugins. Python API Changes The code now adheres to PEP8, which means that many methods and property names have changed slightly. A new module has been added, mtk.utils, which contains many of the methods and functions previously found in Image4D. Class mtk.image.Image4D Changes Changed the constructor to only require shape and dtype parameters. All other parameters are optional. Changed shape, voxel_size and position are now given as a list or a tuple. Changed to_itk_image() to take one optional argument, frame, which selects the frame to send to SimpleITK. By default frame=0. Changed clone_empty() to take one optional argument dtype, which can be used to change the data type of the cloned image. Renamed method toItkImage() to to_itk_image(). Renamed method writemhd() to mtk.utils.write_mhd() and moved it to mtk.utils. Renamed readmhd() to tk.utils.read_mhd() and moved it to mtk.utils. Removed create(), create4d(), create3d(), create2d(). Please use the Image4D class constructor instead. Additions Added transpose(self, *axes). Returns a copy of the image with the axes transposed. Use this if you want to change the order of the image dimensions according to the optional input axes. Added method T(). This methods reverses the order of the axes. Support for metadata has been added. A metadata structure is exported to the python environment in a TypedList, where each element contains the metadata for each frame of the image. Class mtk.utils read_csv(filename, delimiter=&quot;;&quot;): Reads a csv file from disk. write_csv(data, filename, delimiter=&quot;;&quot;): Writes a csv file to disk. read_metadata(path): Read image metadata from an .xml file given in path. from_itk_image(itkimage): Convert a SimpleITK image to an Image4D class. valid_variable(variable_name): Checks if a variable name is valid in MICE/Python. valid_type(value): Checks if a variable has a valid type. TypedList(list): Creates a list datatype with strong typing. This datatype is used in the metadata representation. Struct(object): Creates a structure datatype from a dictionary. This datatype is used in the metadata representation. Code Example # Image4D constructor image = mtk.image.Image4D([10, 10, 10, 3], name='Empty', dtype='bool') # Show overview of image properties image print(image) # Get shape, voxel size and position of image image.shape image.voxel_size image.position # ITK conversion itk_image = image.to_itk_image() itk_image_frame = image.to_itk_image(frame=2) image_from_itk = mtk.utils.from_itk_image(itk_image_frame, dtype='float') ''' Create some metadata. A metadata structure, defined in mtk.utils.Struct is compatible with a DICOM struct, but more flexible. Structs can contain fields, Structs, and TypedLists. A TypedList is a list with strong typing, where each element in must be of the same type. The metadata structure is stored in a TypedList, where each frame has its own Struct. ''' # Create a metadata struct, with fields common to all frames metadata_struct = mtk.utils.Struct(dict(PatientID='10',PatientName='Dummy')) # Add a field to the metadata metadata_struct.Age = 77 # Clone metadata_struct in a TypedList metadata_list = mtk.utils.TypedList([metadata_struct]*3) # Create a tag called &quot;Frame&quot;, that is different in each frame for i, _ in enumerate(metadata_list): metadata_list[i].Frame = i # Store metadata in the Image4D object image.metadata = metadata_list # Cloning mask = image.clone_empty(dtype='bool') # Write to MHD. The metadata is written to an XML file. mtk.utils.write_mhd(&quot;c:\\temp\\mhdimage.mhd&quot;, image) mhd_image = mtk.utils.read_mhd(&quot;c:\\temp\\mhdimage.mhd&quot;) # Verify that the metadata is intact mhd_image.metadata[0].PatientName ", "tags": "", "url": "changelog.1.1.0.html"},
{"title": "1.1.2", "text": "1.1.2 April 21, 2020 New features Added matlab plugins. You can select the programming language you want to use when creating the node, or when editing the node. Please convert your old matlab nodes. Matlab is now started only once per session unless you are using interactive mode. Added search node function. Added a Demo database that is always included in MICE. The database contains two fictitious patients with CT and MR exams, and RTSTRUCTs and RTDOSE. Added &lsquo;Extract Data&rsquo; node, to create a data table from a subset of another data table. Added default voxel value setting to &lsquo;Resample to reference&rsquo; node. Added database connection information in database import nodes. Please note that workflows using this node will not work in older versions of MICE. Added support for multiple masks in &lsquo;Descriptive Statistics&rsquo; node. Added support for RTDOSE images with a negative GridFrameOffsetVector. Added &lsquo;Structure to Data&rsquo; node, to convert an RTSTRUCT to a table of point coordinates. Added &lsquo;Data to Structure&rsquo; node to convert a table of point coordinates to an RTSTRUCT. Added &lsquo;Inverse transform&rsquo; node for linear transformix transforms. Added &lsquo;Apply Transform&rsquo; node for structures, to apply a transformix transform to an RTSTRUCT. NOTE! Due to the way registrations and transforms work, the INVERSE transform must be applied to coordinates in the moving image to transform them to the fixed image frame of reference. Changes Updated deformation analysis node to handle 2D images. Plugins can now have the same variable names in inputs, outputs and settings. Threshold filter and Otsu thresholding are separated into two nodes. Workflows with the old node will automatically change to the Otsu node if the filter uses Otsu thresholding. Regions are now called Label Maps in the Time Statistics node. Deformation analysis node can now be used without a reference image. Updated SimpleITK to 1.2.4. Updated Elastix to 5.0. Added a Windows service configuration panel to configure MICE Toolkit to run as a Windows service. Mask to struct node is no longer a micro node. Changed The &ldquo;Multiply&rdquo; title to &quot;Add&quot;, &ldquo;Divide&rdquo;, and &quot;Subtract&quot; in the settings for Add, Divide and Subtract nodes in Vector/Math. Operations. Python API changes: MHD images with gzip compression is now supported for both reading and writing. Large multi-frame images now export correctly with no line-break in the mhd header file. Time-stamps are automatically added when creating a time series. Image4D has new method: create_empty_metadata() to create an empty metadata dictionaty. Added pydicom module. Bug Fixes Time series now writes correctly from python Time stamps are automatically added when setting a new array in python. Fixed bug when using bool values in python plugins. Fixed 2D transformix to vector field. Fixed reading of dynamic series to sort frames by acquisition number. Viewport selection borders works again in the visualizer. ", "tags": "", "url": "changelog.1.1.2.html"},
{"title": "1.1.3", "text": "1.1.3 April 24, 2020 This is a hotfix to fix some issues in version 1.1.2, please see Version 1.1.2 for major changes. Fixed bug that would generate strange results when using slice wise processing in binary morphological filters Contour and Fill Hole. Fixed bug in Create Time Series that would generate corrupt metadata. ", "tags": "", "url": "changelog.1.1.3.html"},
{"title": "2021.1.0", "text": "2021.1.0 June 4, 2021 New Features AI Features It is now possible to load and apply a pre-trained neural network in any workflow. We currently support .onnx and .pb formats for the frozen, stand-alone networks. Multidimensional diffusion analysis using dVIEWR The dVIEWR license contains an extensive collection of functionality for analysing multidimensional diffusion images using the QTI and Full-DTD models that has been added in collaboration with Random Walk Imaging. Visualizer Features Added visualization node. Added support for simple ROI statistics in the visualizer. Adding a ROI to a locked viewport will visualize that ROI in other locked viewports. Vector images are now visualized as RGB in the visualizer. It's now possible to drag images from databases and viewport items to the viewport directly. Added colormap settings editor. DICOM RT Structure Features Added node struct apply transform. Added image iso to struct node. Added structure merge node. Added structure decimation node to reduce the number of points in a structure. Added simple count variable $i to struct renamer. Database Features Added support for MHD images in the database. Added support for NIfTI in MICE databases. Added NIfTI import control. Added support for importing images to MICE databases from workflows. Added support for tagging in MICE and MIQA databases. Datasets can now be linked in the database from workflows. Registration Features Added default pixel value to transformix processor. Added support for multiple initial transforms in transformix parameters. Added support for frame by frame elastix registrations. Added default pixel value to pre-defined registrations. Plot and Data Table Features Added node for Creating Expressions on columns of data tables. Added node to create a plot (Data to Curve) from the columns of data tables. Miscelaneous new nodes and functionality Added nodes CTD1, CTD2, CTD3. Added node String Concatenate. Added multiple quick processes. Added slicewise metdata. Added quick processes that can be used in the visualizer. Added application layouts. Added node to extract metadata string. Added node to extract image name. Added DTI Forward Model node. Add a repeater quickly by pressing ALT+Left Click on a connection. Added frame-wise and slice-wise settings to the Descriptive Statistics node. Added node to assert Boolean, Double, String and Image data. Added 4D support for multiple nodes. Added quartile statistics for ROI. Added support for mirror and wrap padding in the padding node. Changes Visualizer Changes Removed image sets from visualizer. Layer order inversed in visualizer. Histogram of RGB images now show the histogram of all three channels. DICOM RT Structure Changes Removed Struct Selector Removed Struct Renderer All struct related nodes now operate on collections of structs, no single struct is allowed. Improved RT-Struct export. Database Changes Patient images are now grouped by study in the database control. Registration Changes Transformix and Elastix transformations can now handle initial transforms. Inverting an Elastix transform can now handle initial transforms. Elastix node now handles multiple moving images faster. General Changes Images now use a new metadata structure. Updated the About form. Deprecated Patch Based Denoising node, and replaced it with Bilateral Denoising. PCA node now works in all dimensions. All reshape nodes now support multiple image types (Masks, Complex, Float). In the Chan Vese segmentation node, &ldquo;Image&rdquo; was changed to &quot;Initial Guess&quot; while &ldquo;Initial Guess&rdquo; was renamed to &quot;Initial Level Set&quot;. Bugfixes Fixed viewport shortcuts XYZR. Fixed group filenames with non filesystem friendly chars. Fixed colormap update bug. Fixed license update bug. Fixed reading of huge MHD files. Fixed json to metadata DateTime bug. Fixed resampling of non orthogonal image space. Mesh Generation of structures. Improved NaN handling in statistics and visualizer. Fixed metadata generation bugs. Better support for reading Philips diffusion series. Added a small delay between batch jobs. Better support for 4D images in multiple nodes. Fixed Rician noise generation. Fixed the histogram plots when using logarithmic scale. ", "tags": "", "url": "changelog.2021.1.0.html"},
{"title": "Image registration", "text": "Image registration with Elastix Image registration is an important part of medical image analysis, to align images taken with different modalities or at different times. The mathematical basis for image registration will not be covered in this article, which will focus on the practical aspects of image registration using elastix in MICE. If you want to know more about the mathematical foundation of image registration, please look in the excellent manual available at the elastix homepage. Some background on the image registration process is however necessary to review. The image registration process The basic image registration problem is based on two images, the fixed image and the moving image. The two images are defined in their own spatial domain, i.e. have their own coordinate systems, and the registration processes aims to find the displacement that spatially aligns the moving image to the fixed image. This is done by displacing the moving image using some transform, spatially mapping a point from the fixed image to the moving image and comparing the information in the two images at that point using some metric. By trying many different displacements using an optimizer, ideally the best alignment between the two images can be found, as illustrated below. In the following sections, the elastix parameter name highlighted as code. Registration components Metrics There are several similarity measures available in elastix, listed below with some pointers on their applicability: Mean squared difference (MSD): (AdvancedMeanSquares) This measure is simple, but only suitable for images with equal intensity distribution, i.e. mono-modal images. Normalised correlation coefficient (NCC): (AdvancedNormalizedCorrelation) The images to be registered must have a linear relationship between their intensity values, and is therefore less strict than MSD and can be used more often. Mutual information (MI): (AdvancedMattesMutualInformation) There must only be a relationship between the probability distributions of the intensity values, and is therefore more general than both MSD and NCC. It is the workhorse of image registration, and works well for both multi- and mono-modal image pairs. This is also the metric that works best in elastix performance wise. Normalized mutual information (NMI): (NormalizedMutualInformation) Similar to MI – there have been indications of better performance than MI in some cases. Kappa statistic (KS): (AdvancedKappaStatistic) Specific to registrations of binary images – measures overlap of segmentations. Transforms There are many transforms available in elastix with different degrees of freedom. Translation: (TranslationTransform) The moving image can only be translated to match the fixed image. Rigid: (EulerTransform) The moving image can be translated and rotated to match the fixed image. Similarity: (SimilarityTransform) The moving image can be translated, rotated and scaled isotropically. This is a quite uncommon transform. Affine: (AffineTransform) The moving image can be translated, rotated, scaled and sheared. B-splines: (BSplineTransform) A non-rigid transform which can model local deformations. The scale of the deformations is largely controlled by the control point spacing. Optimisers There are several different optimizers available in elastix - the most used ones are gradient descent (GD), Robbins-Monro (RM) and adaptive stochastic gradient descent (ASGD) (AdaptiveStochasticGradientDescent). The RM optimizer approximates the calculation of the derivative, making it faster to calculate, and is the recommended over GD in elastix. ASGD requires less parameters to be set and tends to be more robust than GD, and can be used as a default optimizer since it works well in most applications. There are many more optimizers available as well - we refer to the elastix manual for details on these. Other components There are other components necessary in the image registration scheme, such as the image sampler, interpolator and multi-resolution scheme. The image sampler defines the way the evaluated points are selected. In general, all of the points in the fixed image need not be evaluated in order to accomplish a good registration, a subset may suffice. The available choices are Full: (Full) The full sampler evaluates all point in the fixed image. Grid: (Grid) The grid sampler defines a regular grid on the fixed image with grid size defined by the user, effectively downsampling the image. Random: (Random) The random sampler randomly selects a user specified number of voxels from the fixed image. Every voxel has equal chance to be selected, and the same voxel can be selected several times. Random coordinate: (RandomCoordinate) Similar to the random sampler, but is not limited to voxel positions, i.e. points in between voxels can also be selected. The voxel values at these position must be obtained by interpolation. The interpolator is necessary since the optimization is evaluated at non-voxel positions (the moving image moves, rotates and deforms in physical space). There are several methods available with different quality and speed. The available interpolators are Nearest neighbour: (NearestNeighborInterpolator) Fast but course - the intensity of the voxel nearest in space is returned. Linear: (LinearInterpolator) The average of the nearest voxels, weighted by the distance to each voxels. This option usually gives good results during registration. N-th order B-spline: (BSplineInterpolator) The higher order, the better quality but requiring more computation time. The multi-resolution scheme is a way to increase the chance of successful registrations by starting the process with images of lower complexity. This is accomplished using image pyramids which can be smoothed, downsampled, or both, increasing the complexity (i.e. reducing the amount or smoothing and/or downsampling) as the registration process converges. This parameter should be specified for both the fixed and moving image as (Fixed______ImagePyramid) and (Moving______ImagePyramid) where the blank space indicates what kind of method is used. In elastix, the available choices are (parameters only given for the fixed image): Gaussian pyramid: (FixedRecursiveImagePyramid) Applies both smoothing and downsampling. Gaussian scale space: (FixedSmoothingImagePyramid) Applies only smoothing. Shrinking pyramid: (FixedShrinkingImagePyramid) Applies only downsampling. The elastix parameter file The registration components and their parameter values are defined in the elastix parameter file. The syntax is simple and is supplied as follows: (ParameterName &quot;value(s)&quot;) Below, a parameter file is supplied which specifies a 2D rigid registration without comments. The full parameter file with comments can be found here. Note that this is just one example - e.g. some parameters regarding the transform are only valid for the transform that is selected, so the parameter file can vary extensively. It is divided in sections. The first section defines the main settings of the registration - the most important setting for a MICE/elastix user is the image dimension settings, which must be changed between 2D and 3D depending on the application. // Main settings (FixedInternalImagePixelType &quot;float&quot;) (MovingInternalImagePixelType &quot;float&quot;) (FixedImageDimension 2) (MovingImageDimension 2) (UseDirectionCosines &quot;true&quot;) The second section defines the main components of the registration, many of which have been described in the above sections. Two of the components were not mentioned - the registration component connects all other components and implements the multi resolution aspect of the registration. It can also handle multi-metric registrations, which will be further described below in the examples. Also the re-sampler was not mentioned - it defines how to re-sample the final result. Is normally left unchanged. // **************** Main Components ************************** (Registration &quot;MultiResolutionRegistration&quot;) (Interpolator &quot;BSplineInterpolator&quot;) (ResampleInterpolator &quot;FinalBSplineInterpolator&quot;) (Resampler &quot;DefaultResampler&quot;) (FixedImagePyramid &quot;FixedRecursiveImagePyramid&quot;) (MovingImagePyramid &quot;MovingRecursiveImagePyramid&quot;) (Optimizer &quot;AdaptiveStochasticGradientDescent&quot;) (Transform &quot;EulerTransform&quot;) (Metric &quot;AdvancedMattesMutualInformation&quot;) The following section defines parameters pertaining to the transform - how to scale, combine and initialize them. // ***************** Transformation ************************** (AutomaticScalesEstimation &quot;true&quot;) (AutomaticTransformInitialization &quot;true&quot;) (HowToCombineTransforms &quot;Compose&quot;) This section specifies parameters regarding the metric. // ******************* Similarity measure ********************* (NumberOfHistogramBins 32) (ErodeMask &quot;false&quot;) Next, details regarding the multi-resolution scheme. // ******************** Multiresolution ********************** (NumberOfResolutions 4) (ImagePyramidSchedule 8 8 4 4 2 2 1 1 ) Details regarding the optimizer. // ******************* Optimizer **************************** (MaximumNumberOfIterations 250) This section defines how the image sampling should be done. // **************** Image sampling ********************** (NumberOfSpatialSamples 2048) (NewSamplesEveryIteration &quot;true&quot;) (ImageSampler &quot;Random&quot;) Finally, there is a section regarding details on how the interpolation and final re-sampling of the result should be done. // ************* Interpolation and Re-sampling **************** (BSplineInterpolationOrder 1) (FinalBSplineInterpolationOrder 3) (DefaultPixelValue 0) (WriteResultImage &quot;true&quot;) (ResultImagePixelType &quot;short&quot;) (ResultImageFormat &quot;mhd&quot;) There is detailed documentation on the available parameters on the elastix homepage, as well as several parameter file examples with references to literature, see below. In MICE, in the parameter file editor which you can access from the node settings panel or by double-clicking on the node itself in the Process pane, you can find some default parameter files in the PRESETS menu. Elastix parameter documentation Elastix parameter file database Examples in MICE Elastix is normally called via a command-line interpreter, using commands like this: elastix -f fixedImage.ext -m movingImage.ext -out outputDirectory -p parameterFile.txt MICE works like a wrapper to elastix, so you can use it in a graphical user interface. In the following section, examples are provided to demonstrate how to set up the elastix node in MICE to solve different registration tasks. To study the parameter file and node settings, open the example workflows. Rigid registration in 3D This is the simplest case, and it's only using the default settings of Elastix in MICE. Just connect the fixed and moving images and run the process. The parameter file is called Default rigid. Rigid 3D example Affine registration This example shows how to make an affine registration in 3D. The parameter file is called Default affine. The node looks exactly the same as in the rigid example, but the parameters are different. Affine 2D example Basic non-rigid registration in 3D This example shows how to make a basic non-rigid registration in 3D. Use the parameter-file Default non-rigid. The node has an extra input, Initial transform, which contains the initial rigid registration. You can either register the output image from the rigid registration without an initial transform, or the original moving image with an initial transform. It also has an extra output TFX1 which contains the transform parameters. This can be used to produce vector fields to analyze the deformation, apply it to other images, etc. Non-rigid 3D example Non-rigid registration with guiding structures in 2D This example is a little more involved than the previous ones. It is a deformable registration that simultaneously takes into account the image information create a global registration, as well as some guiding structures to guide the registration in a smaller section of the images. To create such a registration, you need to select Use Multiple Fixed Images and Multi Metric in the Node Settings pane. This will create inputs for two image pairs which will be registered simultaneously - note that this type of registration will register the images together, i.e. both image pairs will contribute to the loss function, but they will have the same transform. You will also need to toggle the 2D/2D Registration switch in the Node Settings pane. There are also some special parameter settings: (FixedImageDimension 2) (MovingImageDimension 2) (Registration &quot;MultiMetricMultiResolutionRegistration&quot;) (Interpolator &quot;LinearInterpolator&quot; &quot;LinearInterpolator&quot;) (ImageSampler &quot;RandomCoordinate&quot; &quot;RandomCoordinate&quot;) (FixedImagePyramid &quot;FixedSmoothingImagePyramid&quot; &quot;FixedSmoothingImagePyramid&quot;) (MovingImagePyramid &quot;MovingSmoothingImagePyramid&quot; &quot;MovingSmoothingImagePyramid&quot;) (Metric &quot;AdvancedMattesMutualInformation&quot; &quot;AdvancedMeanSquares&quot;) (Metric0Weight 0.3) (Metric1Weight 0.7) Several parameters need to be specified twice, as there are two simultaneous registrations running. In this registration, we also employ Fixed Masks. These are binary masks, specified in the fixed image space, which defines in what areas the image should be sampled. By using these, you can focus the registration on certain parts of the image. Non-rigid with guiding structures 2D example Partially rigid deformable registration in 2D This example shows how to use auxiliary images to guide the registration, here using an image specifying the rigidity of the image. Where the auxiliary image is 0, the moving image is deformable and where it is 1, the moving image is rigid. To use this type of registration, set the desired number of Auxiliary images to 1 in the Node Settings panel. There are some specific settings in the parameter file: (Registration &quot;MultiMetricMultiResolutionRegistration&quot;) (Metric &quot;AdvancedMattesMutualInformation&quot; &quot;TransformBendingEnergyPenalty&quot; &quot;TransformRigidityPenalty&quot;) (Metric0Weight 0.9) (Metric1Weight 0.1) (Metric2Weight 0.1 0.1 0.1 4) (MovingRigidityImageName AUX1) (DilateRigidityImages &quot;false&quot;) In this example, we change the metric weights depending on where in the multi-resolution scheme we are. In the final resolution, the rigidity penalty is dominant. Note that you call the auxiliary image using AUX1. For details regarding the use of partially rigid registrations and the specific parameters which can be user, we refer to the elastix homepage and the paper by Staring, Klein and Pluim. Non-rigid with guiding structures 2D example ", "tags": "", "url": "articles.image_registration.html"},
{"title": "Smooth masks", "text": "Smooth masks A smooth mask is a MICE specific concept which allows polygonal structures to be rendered on an image, allowing fractional values between 0 and 1. This makes it possible to improve the accuracy of the volume definition. If the polygon cuts a voxel precisely diagonally, the voxel value of the Smooth Mask at that voxel will be 0.5. When producing different statistics based on regions of interest, these can be weighted by the intensity of the Smooth Mask, greatly improving the accuracy especially for structures with small volumes. Note that the Smooth Mask is an ordinary Image and not a specific datatype, so the user must ensure that the input really is a Smooth Mask to avoid nonsense statistics. ", "tags": "", "url": "articles.smooth_masks.html"},
{"title": "Tensor parameterization", "text": "Tensor parameterization General case Let us introduce an arbitrary symmetric semipositive-definite tensor \(\mathbf{\Lambda}\) in a general frame of reference (e.g. that of the lab): \[ \mathbf{\Lambda} = \begin{pmatrix} \lambda_{xx} &amp; \lambda_{xy} &amp; \lambda_{xz} \\ \lambda_{yx} &amp; \lambda_{yy} &amp; \lambda_{yz} \\ \lambda_{zx} &amp; \lambda_{zy} &amp; \lambda_{zz} \end{pmatrix} = \begin{pmatrix} \lambda_{xx} &amp; \lambda_{xy} &amp; \lambda_{xz} \\ \cdot &amp; \lambda_{yy} &amp; \lambda_{yz} \\ \cdot &amp; \cdot &amp; \lambda_{zz} \end{pmatrix} \, , \] where symmetry imposes that \(\lambda_{ij} = \lambda_{ji}\), yielding six independent elements in total. Upon diagonalization, \(\mathbf{\Lambda}\) can be expressed in its eigenbasis (basis of eigenvectors) using the Haeberlen convention [@Haeberlen:1976]: \[ \mathbf{b}^{(\mathrm{diag})} = \begin{pmatrix} \lambda_{XX} &amp; 0 &amp; 0 \\ 0 &amp; \lambda_{YY} &amp; 0 \\ 0 &amp; 0 &amp; \lambda_{ZZ} \end{pmatrix} \quad \mathrm{with} \quad \left\vert \lambda_{YY} - \lambda_\mathrm{iso} \right\vert \leq \left\vert \lambda_{XX} - \lambda_\mathrm{iso} \right\vert \leq \left\vert \lambda_{ZZ} - \lambda_\mathrm{iso} \right\vert , \] where \(\lambda_\mathrm{iso} = \mathrm{Tr}(\mathbf{\Lambda})/3\) is the average of \(\mathbf{\Lambda}\)'s eigenvalues (also called &ldquo;isotropic average&rdquo;). This ordering convention assures that \(\lambda_{ZZ}\) is furthest from the isotropic average while \(\lambda_{YY}\) is closest. In particular, the eigenvector associated with \(\lambda_{ZZ}\) is, therefore, the main eigenvector of \(\mathbf{\lambda}\). \(\mathbf{\Lambda}\) can also be written in an eigenbasis form that directly reflects its size and shape, namely \[ \mathbf{\Lambda}^{(\mathrm{diag})} = \lambda_\mathrm{iso} \left\{ \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix} + \lambda_\Delta \left[ \begin{pmatrix} -1 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 2 \end{pmatrix} +\lambda_\eta \begin{pmatrix} -1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix} \right] \right\} , \] where \(\lambda_\Delta\) and \(\lambda_\eta\) denote \(\mathbf{\Lambda}\)'s normalized anisotropy and asymmetry, respectively. These shape parameters are related to the eigenvalues \(\lambda_{XX}\), \(\lambda_{YY}\) and \(\lambda_{ZZ}\) as follows: \[ \begin{aligned} \lambda_\Delta &amp; = \frac{1}{b}\left( \lambda_{ZZ} - \frac{\lambda_{XX} + \lambda_{YY}}{2} \right) \in [-0.5,1]\, , \\ \lambda_\eta &amp; = \frac{1}{2}\, \frac{\lambda_{YY} - \lambda_{XX}}{\lambda_\mathrm{iso}\lambda_\Delta}\in\left[ \mathrm{max}\!\left(-\left\vert 1-\frac{1}{\lambda_\Delta} \right\vert,-1 \right)\, ,\, \mathrm{min}\!\left(\left\vert 1-\frac{1}{\lambda_\Delta} \right\vert,1 \right) \right] \, , \end{aligned} \] where the bounds of \(\lambda_\eta\) ensure the positivity of \(\lambda_{XX}\) and \(\lambda_{YY}\) when \(\lambda_\Delta &gt; 0\). Equivalently, one has \[ \begin{aligned} \lambda_{XX} &amp; = \lambda_\mathrm{iso} [1-\lambda_\Delta(1+\lambda_\eta)]\, , \\ \lambda_{YY} &amp; = \lambda_\mathrm{iso} [1-\lambda_\Delta(1-\lambda_\eta)]\, , \\ \lambda_{ZZ} &amp; = \lambda_\mathrm{iso} [1+2\lambda_\Delta] \, . \end{aligned} \] Transfer between the previous representations of \(\mathbf{\Lambda}\) is ensured via Euler rotation according to \[ \mathbf{\Lambda}= \mathbf{R}_\mathrm{Euler}(\alpha,\beta,\gamma) \cdot \mathbf{\Lambda}^{(\mathrm{diag})} \cdot \mathbf{R}_\mathrm{Euler}^{\mathrm{T}}(\alpha,\beta,\gamma) \, , \] where the superscript &ldquo;\(\mathrm{T}\)&rdquo; indicates transposition and the Euler rotation matrix \(\mathbf{R}_\mathrm{Euler}(\alpha,\beta,\gamma)\) depends on the three Euler angles according to \[ \mathbf{R}_\mathrm{Euler}(\alpha,\beta,\gamma) = \mathbf{R}_z(\gamma)\cdot\mathbf{R}_y(\beta)\cdot\mathbf{R}_z(\alpha) \, , \] with \[ \begin{aligned} \mathbf{R}_y(\theta) &amp; = \begin{pmatrix} \cos\theta &amp; 0 &amp; \sin\theta \\ 0 &amp; 1 &amp; 0 \\ -\sin\theta &amp; 0 &amp; \cos\theta \end{pmatrix} \, , \\ \mathbf{R}_z(\theta) &amp; = \begin{pmatrix} \cos\theta &amp; -\sin\theta &amp; 0 \\ \sin\theta &amp; \cos\theta &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix} \, , \end{aligned} \] for any arbitrary angle \(\theta\). While the normalized anisotropy \(\lambda_\Delta\) was first introduced in the context of diffusion tensors in Ref.[@Conturo:1996], subsequently related to other measures of diffusion anisotropy [@Kingsley:2006], it was first applied to b-tensors in Ref.[@Eriksson:2015]. Axisymmetric case The axisymmetric case corresponds to \(\lambda_\eta = 0\). In this context, the number of independent elements in \(\mathbf{\Lambda}\) reduces to four. Indeed, \(\lambda_\eta\) is set to zero and only two Euler angles are now necessary to describe \(\mathbf{\Lambda}\)'s main orientation. Using previous equations, an axisymmetric tensor is parametrized as \[ \mathbf{\Lambda}^{(\mathrm{diag})} = \begin{pmatrix} \lambda_\mathrm{iso}(1-\lambda_\Delta) &amp; 0 &amp; 0 \\ 0 &amp; \lambda_\mathrm{iso}(1-\lambda_\Delta) &amp; 0 \\ 0 &amp; 0 &amp; \lambda_\mathrm{iso}(1+2\lambda_\Delta) \end{pmatrix} = \begin{pmatrix} \lambda_\perp &amp; 0 &amp; 0 \\ 0 &amp; \lambda_\perp &amp; 0 \\ 0 &amp; 0 &amp; \lambda_\parallel \end{pmatrix} \, , \] where \(\lambda_\parallel\) and \(\lambda_\perp\) are the axial and radial eigenvalues, respectively. Moreover, transfer between the previous representations of \(\mathbf{\Lambda}\) in the axisymmetric case is ensured via \[ \mathbf{\Lambda} = \mathbf{R}(\theta,\phi) \cdot \mathbf{\Lambda}^{(\mathrm{diag})} \cdot \mathbf{R}^{\mathrm{T}}(\theta,\phi)\, , \] with \[ \mathbf{R}(\theta,\phi) = \mathbf{R}_z(\phi)\cdot\mathbf{R}_y(\theta) \, , \] using the rotation matrices given above. While the isotropic diffusivity corresponds to the isotropic average of the diffusion tensor, \(D_\mathrm{iso} = \mathrm{Tr}(\mathbf{D})/3\), the b-value is directly given by the trace of the b-tensor \(\mathbf{b}\): \(b = \mathrm{Tr}(\mathbf{b}) = 3b_\mathrm{iso}\). ", "tags": "", "url": "dviewr.theory.tensor_parameterization.html"},
{"title": "Voxel content", "text": "Capturing the voxel content in terms of a diffusion tensor distribution Signal description The measured diffusion signal \(\mathcal{S}\) probes diffusion processes over specific observational time-scales that depend on the choice of experimental time parameters. For given observational time-scales, a common description of the sub-voxel composition of heterogeneous tissues is obtained by considering a &ldquo;snapshot&rdquo; of the combined non-Gaussian diffusion effects of restriction and exchange, and by approximating the signal decay as a continuous weighted sum of exponential decays, giving the following multidimensional Laplace transform: \[ \mathcal{S}(\mathbf{b}) = \mathcal{S}_0 \int_{\mathrm{Sym}^{+}(3)} \! \mathcal{P}(\mathbf{D})\, \exp(-\mathbf{b}:\mathbf{D}) \, \mathrm{d}\mathbf{D} \, , \] where \(\mathbf{b}\) is the diffusion-encoding tensor from tensor-valued diffusion encoding [@Westin:2016 ; @Topgaard:2017 ; @Reymbaut_book_chapter:2020], \(\mathcal{S}_0 = \mathcal{S}(\mathbf{b}=\mathbf{0})\) is the non diffusion-weighted signal, and \(\mathcal{P}(\mathbf{D})\) is the diffusion tensor distribution [@Jian:2007]. Here, \(\mathrm{Sym}^{+}(3)\) denotes the space of symmetric positive-semidefinite $3\times3$ tensors and &ldquo;:&rdquo; is the Frobenius inner product. Time-dependent effects Changing the observational time-scales may very well lead to a different set of exponential decays as a result of restricted diffusion [@Woessner:1963] and exchange [@Johnson:1993], which implies that the measured distribution \(\mathcal{P}(\mathbf{D})\) may depend on the spectral content of the diffusion-encoding gradients [@Stepisnik:1981 ; @Stepisnik:1985 ; @Callaghan_Stepisnik:1995 ; @Topgaard_dim_rand_walks:2019 ; @Lundell_Lasic_book_chapter:2020 ; @Szczepankiewicz_arXiv:2020]. In other words, the retrieved diffusion tensors should be interpreted as apparent ones, including all potential time-dependent effects of restriction and exchange. Even though time-dependent effects have been measured in human-brain white matter [@Van:2014 ; @Baron_Beaulieu:2014 ; @Baron_Beaulieu:2015 ; @Fieremans:2016 ; @Veraart:2019 ; @Lundell:2019 ; @dellAcqua_ISMRM:2019], spinal cord [@Jespersen:2018 ; @Grussu:2019] and prostate [@Lemberskiy:2017 ; @Lemberskiy:2018] using pulse sequences specifically designed for varying the observational spectral content over extended ranges, the above \(\mathcal{P}(\mathbf{D})\) description holds for the limited range of spectral contents probed by clinical dMRI experiments in the brain [@Clark:2001 ; @Ronen:2006 ; @Nilsson:2009 ; @Nilsson:2013a ; @Nilsson:2013b ; @deSantis_T1:2016 ; @Lampinen:2017 ; @Veraart:2018 ; @Grussu:2019 ; @Lampinen:2019 ; @Szczepankiewicz_ISMRM:2019]. ", "tags": "", "url": "dviewr.theory.voxel_content.html"},
{"title": "Signal representation", "text": "Signal representation Generalized two-term cumulant expansion Published in Ref.[@Westin:2016], q-space trajectory imaging (QTI) fits the multidimensional diffusion signal using the following generalized two-term cumulant expansion: \[ \mathcal{S}(\mathbf{b}) = \mathcal{S}_0\,\exp\!\left(-\mathbf{b}:\langle \mathbf{D}\rangle + \frac{1}{2}\, \mathbf{b}^{\otimes 2}:\mathbb{C}\right) , \] where \(\mathbf{b}\) is the second-order b-tensor, \(\langle \mathbf{D} \rangle\) is the second-order mean diffusion tensor, \[ \mathbb{C} = \langle \mathbf{D}^{\otimes 2} \rangle - \langle \mathbf{D} \rangle^{\otimes 2} \] is the fourth-order covariance tensor, and \(\mathbf{D}^{\otimes 2} = \mathbf{D}\otimes\mathbf{D}\) denotes the outer tensor product of \(\mathbf{D}\) with itself. Sometimes called &ldquo;covariance tensor approximation&rdquo;, QTI can equivalently be thought of as assuming that the intra-voxel distribution of diffusion tensors \(\mathcal{P}(\mathbf{D})\) is well captured by a normal distribution of tensors. Voigt notation The symmetry of all previous tensors allows for drastic simplifications during implementation using the Voigt notation \[ \mathbf{D} = \begin{pmatrix} D_{xx} &amp; D_{xy} &amp; D_{xz} \\ \cdot &amp; D_{yy} &amp; D_{yz} \\ \cdot &amp; \cdot &amp; D_{zz} \end{pmatrix} \equiv \mathbf{d}_\mathrm{Voigt} = \begin{pmatrix} D_{xx} &amp; D_{yy} &amp; D_{zz} &amp; \sqrt{2}\, D_{yz} &amp; \sqrt{2}\, D_{xz} &amp; \sqrt{2}\, D_{xy} \end{pmatrix}^\mathrm{T}\, . \] Indeed, this notation allows to write the \(\ 3\times 3 \times 3 \times 3\) tensor \(\mathbf{D}^{\otimes 2}\) as the following \(\ 6\times 6\) tensor: \(\mathbf{D}^{\otimes 2} \equiv \mathbf{d}_\mathrm{Voigt}\cdot\mathbf{d}_\mathrm{Voigt}^\mathrm{T}\). Moreover, these symmetries imply that the mean diffusion tensor possesses 6 independent elements, and that the covariance tensor possesses 21 independent elements: \[ \mathbb{C} = \begin{pmatrix} C_{xx,xx} &amp; C_{xx,yy} &amp; C_{xx,zz} &amp; \sqrt{2}\, C_{xx,yz} &amp; \sqrt{2}\, C_{xx,xz} &amp; \sqrt{2}\, C_{xx,xy} \\ \cdot &amp; C_{yy,yy} &amp; C_{yy,zz} &amp; \sqrt{2}\, C_{yy,yz} &amp; \sqrt{2}\, C_{yy,xz} &amp; \sqrt{2}\, C_{yy,xy} \\ \cdot &amp; \cdot &amp; C_{zz,zz} &amp; \sqrt{2}\, C_{zz,yz} &amp; \sqrt{2}\, C_{zz,xz} &amp; \sqrt{2}\, C_{zz,xy} \\ \cdot &amp; \cdot &amp; \cdot &amp; 2\, C_{yz,yz} &amp; 2\, C_{yz,xz} &amp; 2\, C_{yz,xy} \\ \cdot &amp; \cdot &amp; \cdot &amp; \cdot &amp; 2\, C_{xz,xz} &amp; 2\, C_{xz,xy} \\ \cdot &amp; \cdot &amp; \cdot &amp; \cdot &amp; \cdot &amp; 2\, C_{xy,xy} \\ \end{pmatrix}\, , \] where \(C_{ij,kl} = \langle D_iD_j\rangle - \langle D_k\rangle \langle D_l \rangle\) with \(i,j,k,l\in \{x,y,z\}\). Therefore, with the addition of \(\mathcal{S}_0\), QTI consists in a 28-dimensional fitting procedure. A lightening fast inversion While a 28-dimensional fit seems daunting, it can be made incredibly fast upon taking the logarithm of the QTI signal and writing it as \[  \end{pmatrix} }_{\mathbf{S}\in\mathbb{R}^{N_\mathrm{acq}\times 1}} =  \begin{pmatrix} 1 &amp; -\mathbf{b}_{\mathrm{Voigt},1}^\mathrm{T} &amp; \frac{1}{2}\, \tilde{b}_{\mathrm{Voigt},1}^\mathrm{T} \\ \vdots &amp; \vdots &amp; \vdots \\ 1 &amp; -\mathbf{b}_{\mathrm{Voigt},N_\mathrm{acq}}^\mathrm{T} &amp; \frac{1}{2}\, \tilde{b}_{\mathrm{Voigt},N_\mathrm{acq}}^\mathrm{T} \end{pmatrix} }_{\mathbf{X}\in\mathbb{R}^{N_\mathrm{acq}\times 28}} \cdot { \begin{pmatrix} \mathcal{S}_0 \\ \langle \mathbf{d} \rangle_\mathrm{Voigt} \\ \tilde{c}_\mathrm{Voigt} \end{pmatrix} }_{\mathbf{\beta}\in\mathbb{R}^{28\times 1}} \, , \] where \(N_\mathrm{acq}\) is the number of acquisition points, \(\mathbf{b}_\mathrm{Voigt}\) and \(\langle\mathbf{d} \rangle_\mathrm{Voigt}\) are the \(\ 6\times 1\) versions of \(\mathbf{b}\) and \(\langle\mathbf{D}\rangle\), respectively, and \(\tilde{b}_\mathrm{Voigt}\) and \(\tilde{c}_\mathrm{Voigt}\) are the \(\ 21\times 1\) versions of \(\mathbf{b}^{\otimes 2}\) and \(\mathbb{C}\), respectively. The \(\mathbf{\beta}\) vector can now be estimated by mere pseudoinversion according to \[ \mathbf{\beta} = (\mathbf{X}^\mathrm{T}\cdot \mathbf{X})^{-1} \cdot\mathbf{X}^\mathrm{T}\cdot\mathbf{S} \, . \] Projection tensors Introducing \(\mathbf{E}_\mathrm{iso} = \mathbf{I}_3/3\) and \(\mathbb{E}_\mathrm{iso} = \mathbf{I}_6/3\), where \(\mathbf{I}_n\) is the \(n\times n\) identity matrix, the definition of QTI's heterogeneity metrics relies on inner products of the covariance tensor with the following projection tensors: \[ \mathbb{E}_\mathrm{bulk} = \mathbf{E}_\mathrm{iso}^{\otimes 2} \qquad , \qquad \mathbb{E}_\mathrm{shear} = \mathbb{E}_\mathrm{iso} - \mathbb{E}_\mathrm{bulk} \, , \] by analogy with the bulk and shear modulus of the fourth-order stress tensor in mechanics. In Voigt notation, these projection tensors write \[ \begin{aligned} \mathbb{E}_\mathrm{bulk} &amp; = \frac{1}{9} \begin{pmatrix} 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \end{pmatrix} \, , \\ \mathbb{E}_\mathrm{shear} &amp; = \frac{1}{9} \begin{pmatrix} 2 &amp; -1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\ -1 &amp; 2 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\ -1 &amp; -1 &amp; 2 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 3 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 3 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 3 \end{pmatrix} \, . \end{aligned} \] They satisfy the following relationships: \[ \begin{aligned} \langle \mathbf{D}\rangle^{\otimes 2} : \mathbb{E}_\mathrm{bulk} &amp; = E_\lambda[\langle \mathbf{D} \rangle]^2 \, , \\ \langle \mathbf{D}^{\otimes 2}\rangle : \mathbb{E}_\mathrm{bulk} &amp; = \mathrm{E}[E_\lambda[\mathbf{D}]^2] \, , \\ \langle \mathbf{D}\rangle^{\otimes 2} : \mathbb{E}_\mathrm{shear} &amp; = V_\lambda (\langle \mathbf{D}\rangle) \, , \\ \langle \mathbf{D}^{\otimes 2}\rangle : \mathbb{E}_\mathrm{shear} &amp; = \mathrm{E}[ V_\lambda (\mathbf{D})] \, , \end{aligned} \] where \(E_\lambda (\mathbf{T})\) and \(V_\lambda (\mathbf{T})\) are the eigenvalue expectation and variance of any arbitrary tensor \(\mathbf{T}\), respectively. Note that we use \(\langle \,\cdot\, \rangle\) and \(\mathrm{E}[ \,\cdot\, ]\) for matrix-valued and scalar averages over the voxel content, respectively, for clarity. Besides, one has \[ \langle \mathbf{D}^{\otimes 2}\rangle = \mathbb{C} + \langle \mathbf{D}\rangle^{\otimes 2} \, , \] by definition of the covariance tensor. Simplification as diffusion tensor imaging (DTI) Diffusion tensor imaging (DTI) [@Basser:1994] corresponds to QTI, albeit with a zero covariance tensor \(\mathbb{C} = 0\). Naturally, this simplification implies that no heterogeneity measure can be extracted from DTI. ", "tags": "", "url": "dviewr.theory.q-space_trajectory_imaging_(qti).signal_representation.html"},
{"title": "Diffusion contrasts", "text": "Diffusion contrasts This section presents the list of available diffusion contrasts in DTI and QTI, indicating which contrasts can be estimated with both DTI and QTI (other contrasts cannot be estimated with DTI). Also, note that Ref.[@Martin:2020] provides an analysis of the contrast-to-noise ratio of various microscopic diffusion anisotropy indices in the context of QTI. Non-diffusion weighted signal [DTI/QTI] The intensity of the non diffusion-weighted signal, \(\mathcal{S}_0\), is directly fitted in QTI. Note that \(\mathcal{S}_0\) remains weighted by relaxation. Mean diffusivity [DTI/QTI] The mean diffusivity (\(\mathrm{MD}\)) is computed from the mean diffusion tensor \(\langle \mathbf{D} \rangle\) as \[ \mathrm{MD} = E_\lambda[\langle \mathbf{D}\rangle] = \mathrm{E}[D_\mathrm{iso}] = \langle \mathbf{D}\rangle : \mathbf{E}_\mathrm{iso} \, . \] Equivalent of the apparent diffusion coefficient (\(\mathrm{ADC}\)), \(\mathrm{MD}\) reports on the average rate of diffusion (in \(\mu\mathrm{m}^2\mathrm{/ms}\)) of water molecules in their corresponding medium. In tissue, \(\mathrm{MD}\) is roughly inversely proportional to cell density (or cellularity): the higher \(\mathrm{MD}\), the lower the cell density. Fractional anisotropy [DTI/QTI] The fractional anisotropy (\(\mathrm{FA}\)) [@Pierpaoli_Basser:1996] is computed from the mean diffusion tensor \(\langle \mathbf{D} \rangle\) as \[ \mathrm{FA} = \left[ \frac{2}{3} \left( 1 + \frac{E_\lambda[\langle \mathbf{D}\rangle]^2}{V_\lambda[\langle \mathbf{D}\rangle]} \right) \right]^{-1/2} = \left[\frac{2}{3}\left( 1 + \frac{\langle\mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{bulk}}{\langle\mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{shear}} \right)\right]^{-1/2} = \sqrt{\frac{3}{2}\,\frac{\langle\mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{shear}}{\langle\mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{iso}}} \in [0,1] \, . \] \(\mathrm{FA}\) reports on the voxel-averaged anisotropy of the voxel content. The higher \(\mathrm{FA}\), the more anisotropic the voxel content on the voxel scale. This means that reaching a high \(\mathrm{FA}\) requires that (i) the voxel contains elongated cells and that (ii) these cells are aligned over the typical lengh-scale associated with the voxel size. This explains why \(\mathrm{FA}\) vanishes in areas of crossing fibers, because the diffusion profile of these crossing configurations tend to appear isotropic on the voxel scale. In other words, \(\mathrm{FA}\) confonds the effects of microscopic anisotropy (see \(\mu\mathrm{FA}\) below) and orientational order (see \(\mathrm{OP}\) below). Diffusional variance The diffusional variance (\(V_\mathrm{iso}\)) is given by \[ V_\mathrm{iso} = \mathrm{V}[E_\lambda[\mathbf{D}]] = \mathrm{E}[E_\lambda[\mathbf{D}]^2] - = \mathbb{C}:\mathbb{E}_\mathrm{bulk} \, , \] Given that \(D_\mathrm{iso} = E_\lambda[\mathbf{D}]\), \(V_\mathrm{iso}\) corresponds to the variance of isotropic diffusivities \(D_\mathrm{iso}\). Consequently, \(V_\mathrm{iso}\) reports on variations in cell density within the voxel content. The higher \(V_\mathrm{iso}\), the less uniform the cell density in a given voxel. Typically, a \(V_\mathrm{iso}\) map tends to be bright in regions at the interface between the high-diffusive ventricles and the low-diffusive white matter, and in regions at the interface between the high-diffusive cerebrospinal fluid surrounding the brain and the low-diffusive grey matter. It also tends to appear bright in glioblastomas, due to their non-uniform cell density. Microscopic fractional anisotropy The microscopic fractional anisotropy (\(\mu\mathrm{FA}\)) [@Lasic:2014 ; @Szczepankiewicz:2015 ; @Szczepankiewicz:2016] is defined as \[ \mu\mathrm{FA} = \left[ \frac{2}{3} \left( 1 + \frac{\mathrm{E}[E_\lambda[\mathbf{D}]^2]}{\mathrm{E}[V_\lambda[\mathbf{D}]]} \right) \right]^{-1/2} = \left[ \frac{2}{3} \left( 1 + \frac{\langle \mathbf{D}^{\otimes 2}\rangle : \mathbb{E}_\mathrm{bulk}}{\langle \mathbf{D}^{\otimes 2}\rangle : \mathbb{E}_\mathrm{shear}} \right) \right]^{-1/2} = \sqrt{\frac{3}{2}\,\frac{\langle\mathbf{D}^{\otimes 2}\rangle:\mathbb{E}_\mathrm{shear}}{\langle\mathbf{D}^{\otimes 2}\rangle:\mathbb{E}_\mathrm{iso}}} \in [0,1] \, . \] \(\mu\mathrm{FA}\) reports on microscopic anisotropy by quantifying the average anisotropy of the voxel content's cellular components, disregarding whether or not these cells are aligned or not on the voxel scale. Importantly, one has \(\mathrm{FA} \leq \mu\mathrm{FA}\). Unlike \(\mathrm{FA}\), \(\mu\mathrm{FA}\) does not vanish in areas of crossing fibers and at the interface between white matter and grey matter. This explains why \(\mu\mathrm{FA}\) correlates with clinical scores in multiple sclerosis [@Andersen_Lasic:2020] and enables to differentiate cortex and white matter in malformations of cortical development associated with epilepsy [@Lampinen_epilepsy:2020]. These works support the idea that \(\mu\mathrm{FA}\) can serve as a proper biomarker of white-matter integrity. Orientational order parameter The orientational order parameter (\(\mathrm{OP}\)) can be defined as \[ \mathrm{OP} = \left(\frac{\mathrm{FA}}{\mu\mathrm{FA}}\right)^2 = \frac{\langle\mathbf{D}^{\otimes 2}\rangle:\mathbb{E}_\mathrm{iso}}{\langle\mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{iso}} \, \frac{\langle\mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{shear}}{\langle\mathbf{D}^{\otimes 2}\rangle:\mathbb{E}_\mathrm{shear}} \in [0,1] \, . \] The bounds of \(\mathrm{OP}\) are justified by the fact that $0 \leq \mathrm \leq \mu\mathrm$. Note that \(\mathrm{OP}\) is meaningful only if the voxel content contains an amount of elongated cells sufficient to ensure that \(\mu\mathrm{FA}\) does not approach zero too closely, which would render \(\mathrm{OP}\) very sensitive to any noise in the data inversion. This mathematical constraint translates the fact that measuring orientational order is only meaningful when studying elongated cells, as isotropic cells do not possess an intrinsic orientation. With this constraint implemented, an \(\mathrm{OP}\) map tends to resemble an \(\mathrm{FA}\) map, with \(\mathrm{OP}\) vanishing in particular in areas of crossing fibers. In fact, \(\mathrm{FA}\) can be roughly thought as the product between \(\mu\mathrm{FA}\) and \(\mathrm{OP}\) [@Lasic:2014]. Isotropic and anisotropic mean kurtoses The total mean kurtosis \(\mathrm{MKT}\) introduced in the context of diffusion kurtosis imaging (DKI) [@Jensen:2005 ; @Jensen_Helpern:2010] represents a first attempt at quantifying tissue heterogeneity within the voxel content. Indeed, DKI captures the voxel content in terms of a normal distribution of diffusivities and relates \(\mathrm{MKT}\) to the variance of this distribution. However, it is not specific as it entangles two contributions to this variance: mere anisotropy (see \(\mathrm{FA}\) and \(\mu\mathrm{FA}\) above) and diffusional variance (see \(V_\mathrm{iso}\) above). QTI enables to tease apart these two sources as the unitless isotropic and anisotropic mean kurtoses: \[ \begin{aligned} \mathrm{MKI} &amp; = 3\, \frac{\mathbb{C}:\mathbb{E}_\mathrm{bulk}}{\langle \mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{bulk}} \, , \\ \mathrm{MKA} &amp; = \frac{6}{5}\, \frac{\mathbb{C}:\mathbb{E}_\mathrm{shear}}{\langle \mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{bulk}} \, , \end{aligned} \] with \(\mathrm{MKT} = \mathrm{MKI} + \mathrm{MKA}\). While \(\mathrm{MKI}\) relates to diffusional variance as \[ \mathrm{MKI} = 3\, \frac{V_\mathrm{iso}}{\mathrm{MD}^2}\, , \] \(\mathrm{MKA}\) relates to fractional anisotropy and microsopic fractional anisotropy as \[ \mathrm{MKA} = \frac{4}{5} \left[ \frac{\langle \mathbf{D}^{\otimes 2}\rangle:\mathbb{E}_\mathrm{iso} }{\mathrm{MD}^2}\, \mu\mathrm{FA}^2 - \mathrm{FA}^2 \right] \, . \] In other words, \(\mathrm{MKI}\) maps are similar to \(V_\mathrm{iso}\) maps, and \(\mathrm{MKA}\) maps are composites of \(\mathrm{FA}\) of \(\mu\mathrm{FA}\) maps. Microscopic anisotropic mean kurtosis The above anisotropic mean kurtosis \(\mathrm{MKA}\) still confounds microscopic anisotropy and orientational order, as shown by its dependence on \(\mathrm{FA}\). At the core, this dependence come from the fact that \(\mathrm{MKA}\) depends on \[ \mathbb{C}:\mathbb{E}_\mathrm{shear} =\langle \mathbf{D}^{\otimes 2}\rangle:\mathbb{E}_\mathrm{shear} - \langle \mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{shear}\, , \] with \(\langle \mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{shear}\) appearing in the \(\mathrm{FA}\) and \(\langle \mathbf{D}^{\otimes 2}\rangle:\mathbb{E}_\mathrm{shear}\) appearing in the \(\mu\mathrm{FA}\). A straightforward way to isolate the part of \(\mathrm{MKA}\) quantifying pure microscopic anisotropy is to ignore its \(\mathrm{FA}\)-related component, obtaining the microscopic anisotropic mean kurtosis [@Westin:2016]: \[ \mu\mathrm{MKA} = \frac{6}{5}\, \frac{\langle \mathbf{D}^{\otimes 2}\rangle:\mathbb{E}_\mathrm{shear}}{\langle \mathbf{D}\rangle^{\otimes 2}:\mathbb{E}_\mathrm{bulk}} \, . \] A \(\mu\mathrm{MKA}\) map is similar to a \(\mu\mathrm{FA}\) map. Directionally encoded color (DEC) maps In greyscale maps, information is only conveyed via intensity (contrast). Additional information can be brought upon coloring such maps. In QTI, each map related to anisotropy is available in its original greyscale version and in a &ldquo;directionally encoded color&rdquo; (DEC) version. While the intensity of DEC maps is given by the anisotropy measure of interest (e.g. \(\mathrm{FA}\), \(\mu\mathrm{FA}\), etc., their colors code for the main orientation of the voxel-averaged diffusion tensor \(\langle \mathbf{D}\rangle\) according to the following RGB triplet: \[ \text{[red, green, blue] = [left-right, anterior-posterior, superior-inferior]} \, . \] With this convention, the corpus callosum appears mostly red, the arcuate fasciculus appears mostly green, and the corticospinal tract appears mostly blue. ", "tags": "", "url": "dviewr.theory.q-space_trajectory_imaging_(qti).diffusion_contrasts.html"},
{"title": "Drawbacks", "text": "Drawbacks Given that QTI is a truncated two-term cumulant expansion, it tends to underestimate microscopic anisotropy in areas of crossing fibers, because proper description of voxel contents with low orientational order requires higher-order cumulants [@Reymbaut_accuracy_precision:2020]. ", "tags": "", "url": "dviewr.theory.q-space_trajectory_imaging_(qti).drawbacks.html"},
{"title": "Signal representation", "text": "Signal representation Towards discarding regularization Laplace inversion of the diffusion signal typically relies on regularization in order to guide the search for a suitable solution to the inversion problem [@Provencher:1982 ; @Kroeker:1986 ; @Whittall:1989 ; @Mitchell:2012]. However, the memory requirements of these algorithms make them impractical for high dimensions [@Sun:2005], imposing a need for data compression [@Venkataramanan:2002]. Besides, the choice of regularization term inherently influences the characteristics of the solution, potentially causing a mismatch between these characteristics and those of the underlying microstructure. To circumvent these problems, diffusion tensor distribution imaging (DTD) [@Topgaard:2019] explores the space of diffusion tensors using a quasi-genetic approach that does not rely on regularization nor on assumptions regarding the nature of the voxel content (other than those of the \(\mathcal{P}(\mathbf{D})\) description). Quasi-genetic inversion algorithm Discretization To facilitate the numerical inversion of the above signal, the continuous distribution \(\mathcal{P}(\mathbf{D})\) can be approximated by a discrete vector \(\mathbf{w}\) containing the weights of \(\mathit{N}\) distinct diffusion tensors. This allows us to rewrite the above multidimensional Laplace transform as \[ \mathcal{S}_m = \sum_{n=1}^{N} w_n\, \exp(-\mathbf{b}_m:\mathbf{D}_n) \, , \] where \(\mathcal{S}_\mathit{m}\) is the \(\mathit{m}\)-th signal amplitude measured with the encoding tensor \(\mathbf{b}_\mathit{m}\), and \(\mathit{w}_\mathit{n}\) is the weight of the \(\mathit{n}\)-th component of the discretized DTD. The weights \(w_n\) are normalized so that \(\sum_{n=1}^{N} w_n = \mathcal{S}_0\), implying that \(w_n/\sum_{m=1}^{N} w_m\) corresponds to the signal fraction of the \(\mathit{n}\)-th component of \(\mathcal{P}(\mathbf{D})\). Non-negative least-squares minimization Let us denote by \(M\) the number of acquisition points. Since \(\mathit{M}\) is typically larger than the number \(\mathit{N}\) of unknowns, inverting the above equation is an overdetermined system. The estimation of \(\mathbf{w}\) is thus formulated as a non-negative linear least squares (NNLS) problem [@Lawson_book:1974] \[ \, \Vert \mathbf{s}-\mathbf{K}\cdot\mathbf{w}^\prime \Vert_2 \, , \] where \(\Vert \cdot \Vert_2\) denotes the Euclidian norm, \(\mathbf{w}\) is the \(\mathit{N} \times 1\) sought-for probability vector, \(\mathbf{s}\) is the \(\mathit{M} \times 1\) vector containing the signal amplitude measurements, and \(\mathbf{K}\) is the \(\mathit{M} \times \mathit{N}\) matrix whose elements correpond to the various signal decays. While the above non-negativity constraint could be seen as a form of regularization, it merely enforces the fact that the weights \(w_n\) are positive numbers. Monte-Carlo inversion Overall, the signal inversion is performed using a quasi-genetic process called &ldquo;Monte Carlo inversion&rdquo;, introduced in the field of physical chemistry [@Prange:2009] and detailed in previous works [@Topgaard:2019 ; @Reymbaut_accuracy_precision:2020]. Its main steps read as follows: Proliferation - The algorithm selects a random set \(\{\mathbf{D}_{\mathit{n}}\}_{1\leq \mathit{n} \leq \mathit{N}_\mathrm{in}}\) consisting of \(\mathit{N}_\mathrm{in}\) axisymmetric diffusion tensors (diffusion components) within the following bounds: \(-11 \leq \mathrm{log}_{10}(\mathit{D}_{\parallel} / \mathrm{m}^{2}\mathrm{s}^{-1}) \leq -8.3\). \(-11 \leq \mathrm{log}_{10}(\mathit{D}_{\perp} / \mathrm{m}^{2}\mathrm{s}^{-1}) \leq -8.3\). \(\ 0 \leq \mathrm{cos}(\theta) \leq 1\). \(\ 0 \leq \phi \leq 2\pi\). Note that generating random values of \(\cos\theta\) instead of \(\theta\) enables to actually consider random orientations on the unit sphere. The algorithm then estimates the associated set of weights \(\{\mathit{w}_\mathit{n}\}_{1\leq\mathit{n}\leq\mathit{N}_\mathrm{in}}\) via a NNLS minimization routine, storing the components with non-zero weights \(\mathit{w}_\mathit{n}\). This process, called &ldquo;proliferation&rdquo;, is repeated for \(\mathit{N}_\mathrm{p}\) distinct rounds. At each new round, the new set of random components is appended to the previous set of &quot;surviving&quot; components before the NNLS minimization. Mutation/extinction - The set of components \(\{\mathbf{D}_{\mathit{n}}\}\) obtained at the end of all proliferation rounds is subjected to a small random perturbation, called &ldquo;mutation&rdquo;. In other words, the characteristics \(D_{\parallel}\), \(D_{\perp}\), \(\theta\) and \(\phi\) of each component is randomly altered by a small amount. This marks the beginning of the &quot;extinction&quot; step, wherein diffusion components compete with their respective mutations on the basis of lowest residual sums of squares. The winning components are kept for the next mutation/extinction round. The mutation/extinction steps are repeated \(\mathit{N}_\mathrm{m}\) times. Final trimming - Finally, the \(\mathit{N}_\mathrm{out}\) components with highest weights are taken as a solution \(\{ (\mathbf{D}_n, w_n) \}_{1\leq \mathit{n}\leq \mathit{N}_\mathrm{out}} \equiv \{(\mathit{D}_{\parallel,\mathit{n}}, \mathit{D}_{\perp,\mathit{n}} , \theta_\mathit{n}, \phi_\mathit{n}, \mathit{w}_\mathit{n})\}_{1\leq \mathit{n}\leq \mathit{N}_\mathrm{out}}\) of the inversion problem. Typically, one uses \(\mathit{N}_\mathrm{in} = 200\), \(\mathit{N}_\mathrm{p} = 20\), \(\mathit{N}_\mathrm{m} = 20\) and \(\mathit{N}_\mathrm{out} = 50\). Such a large value of \(\mathit{N}_\mathrm{out}\) ensures that voxel contents with low orientational order remain properly captured (as each relevant sub-voxel diffusion direction should be represented by at least one component). While the final trimming of \(\mathit{N}_\mathrm{out}\) components might seem restrictive, it concludes the rather random exploration of around \(\mathit{N}_\mathrm{in}(\mathit{N}_\mathrm{p}+\mathit{N}_\mathrm{m})\) components. As an order of magnitude, using the previous numbers gives \(\mathit{N}_\mathrm{in}(\mathit{N}_\mathrm{p}+\mathit{N}_\mathrm{m}) = 8\,000\) explored components. Bootstrapping Embracing the inherent ill-conditioning of Laplace inversion problems, the DTD method is usually performed using bootstrapping with replacement [@Efron:1979 ; @Efron:1997 ; @de_Kort:2014] on the acquired data. For each voxel, this results in estimating an ensemble of \(\mathit{N}_\mathrm{b}\) plausible sets of components, also called &ldquo;bootstrap solutions&rdquo;, each denoted by \(\{(\mathit{D}_{\parallel,\mathit{n}}, \mathit{D}_{\perp,\mathit{n}} , \theta_\mathit{n}, \phi_\mathit{n}, \mathit{w}_\mathit{n})\}_{1\leq \mathit{n}\leq \mathit{N}_\mathrm{out}}\). ", "tags": "", "url": "dviewr.theory.diffusion_tensor_distribution_imaging_(dtd).signal_representation.html"},
{"title": "Statistical descriptors and binning", "text": "Statistical descriptors and binning Global statistical descriptors The final solution of the Monte-Carlo inversion algorithm, \(\mathcal{P}(\mathbf{D})\), can be understood as the median of all bootstrap solutions, \(\mathcal{P}_{\mathit{n}_\mathrm{b}}(\mathbf{D})\) with $1\leq \mathit\mathrm \leq \mathit\mathrm$. To quantify the main features of this final solution, one computes for instance the medians over bootstrap solutions of the per-bootstrap means \(\mathrm{Med}_{(\mathit{n}_\mathrm{b})}\,(\mathrm{E}[\chi]_{\mathit{n}_\mathrm{b}})\), variances \(\mathrm{Med}_{(\mathit{n}_\mathrm{b})}\,(\mathrm{V}[\chi]_{\mathit{n}_\mathrm{b}})\) and covariances \(\mathrm{Med}_{(\mathit{n}_\mathrm{b})}\,(\mathrm{C}[\chi,\chi^\prime]_{\mathit{n}_\mathrm{b}})\) of \(\chi=\mathit{D}_\mathrm{iso}, D_\Delta^2\), respectively referred to as the &ldquo;size&rdquo; and &quot;shape&quot; of the diffusion tensors building up \(\mathcal{P}(\mathbf{D})\). Here, the median operator &ldquo;\(\mathrm{Med}\)&rdquo; acts across bootstrap solutions, and \(\mathrm{E}[\,\cdot\,]_{\mathit{n}_\mathrm{b}}\), \(\mathrm{V}[\,\cdot\,]_{\mathit{n}_\mathrm{b}}\) and \(\mathrm{C}[\,\cdot,\cdot\,]_{\mathit{n}_\mathrm{b}}\) denote the per-bootstrap average, variance and covariance over bootstrap solution \(\mathit{n}_\mathrm{b}\), respectively. For simplicity, the median operator is implicitly omitted when addressing a statistical descriptor, thereby writing averages, variances and covariances as &quot;\(\mathrm{E}[\chi]\)&quot;, &ldquo;\(\mathrm{V}[\chi]\)&rdquo; and &quot;\(\mathrm{C}[\chi,\chi^\prime]\)&quot;, respectively. While previous works have relied on means to compute averages across bootstrap solutions [@deAlmeidaMartins_Topgaard:2018 ; @Topgaard:2019], more recent works have employed medians instead, because of their enhanced robustness to statistical outliers [@Reymbaut_accuracy_precision:2020 ; @deAlmeidaMartins:2020]. Bin-specific statistical descriptors Given that the DTD method builds up \(\mathcal{P}(\mathbf{D})\) as a discrete sum of components, all aforementioned statistical descriptors can be extracted within tissue-specific bins, i.e. subdivisions of \(\mathcal{P}(\mathbf{D})\)'s configuration space. For instance, the &ldquo;thin&rdquo;, &quot;thick&quot; and &ldquo;big&rdquo; bins introduced in Refs.[@deAlmeidaMartins:2020 ; @Reymbaut_book_chapter:2020] aim to isolate the signal contributions from white matter, grey matter and cerebrospinal fluid, respectively. The boundaries of these bins, implemented as default bins in dVIEWR, are defined as follows: &ldquo;thin&rdquo; bin within \(\mathit{D}_\mathrm{iso} \in [0.1, 2.5] \;\mu\mathrm{m}^2/\mathrm{ms}\) and \(\mathit{D}_\parallel/\mathit{D}_\perp \in [4, 1000]\). &ldquo;thick&rdquo; bin within \(\mathit{D}_\mathrm{iso} \in [0.1, 2.5] \;\mu\mathrm{m}^2/\mathrm{ms}\) and \(\mathit{D}_\parallel/\mathit{D}_\perp \in [0.01, 4]\). &ldquo;big&rdquo; bin within \(\mathit{D}_\mathrm{iso} \in [2.5, 10] \;\mu\mathrm{m}^2/\mathrm{ms}\) and \(\mathit{D}_\parallel/\mathit{D}_\perp \in [0.01, 1000]\). ", "tags": "", "url": "dviewr.theory.diffusion_tensor_distribution_imaging_(dtd).statistical_descriptors_and_binning.html"},
{"title": "Diffusion measures", "text": "Diffusion measures Non-diffusion weighted signal [DTI/QTI/DTD] The intensity of the non diffusion-weighted signal, \(\mathcal{S}_0\), is given by \[ \mathcal{S}_0 = \sum_{n = 1}^{N_\mathrm{out}} w_n \, . \] Note that \(\mathcal{S}_0\) remains weighted by relaxation. Mean size [DTI/QTI/DTD] The mean size is computed as \[ \mathrm{E}[D_\mathrm{iso}]\, . \] Equivalent of the apparent diffusion coefficient (\(\mathrm{ADC}\)) and the mean diffusivity (\(\mathrm{MD}\)), \(\mathrm{E}[D_\mathrm{iso}]\) reports on the average rate of diffusion (in \(\mu\mathrm{m}^2\mathrm{/ms}\)) of water molecules in their corresponding medium. In tissue, \(\mathrm{E}[D_\mathrm{iso}]\) is roughly inversely proportional to cell density (or cellularity): the higher \(\mathrm{E}[D_\mathrm{iso}]\), the lower the cell density. Mean shape [QTI/DTD] The mean shape is computed as \[ \mathrm{E}[D_\Delta^2]\,. \] \(D_\Delta^2\) is chosen instead of \(D_\Delta\) to measure anisotropy to prevent any compensation within a mixed population of prolate (\(D_\Delta &gt; 0\)) and oblate (\(D_\Delta &lt; 0\)) components. This also relates to the fact that part of the second cumulant of the signal is given by \(\mathrm{E}[(D_\mathrm{iso} D_\Delta)^2]\). The unitless mean shape, bound between 0 and 1, is a measure of microscopic anisotropy: the higher \(\mathrm{E}[D_\Delta^2]\), the more elongated the tissue components of the voxel content, disregarding whether or not these are aligned on the voxel scale. Variance of sizes [QTI/DTD] The variance of sizes is given by \[ \mathrm{V}[D_\mathrm{iso}] = \mathrm{E}[D_\mathrm{iso}^2] - \mathrm{E}[D_\mathrm{iso}]^2\, , \] and is identical to \(V_\mathrm{iso}\) in the context of QTI. \(\mathrm{V}[D_\mathrm{iso}]\) reports on variations in cell density within the voxel content. The higher \(\mathrm{V}[D_\mathrm{iso}]\), the less uniform the cell density in a given voxel. Typically, a \(\mathrm{V}[D_\mathrm{iso}]\) map tends to be bright in regions at the interface between the high-diffusive ventricles and the low-diffusive white matter, and in regions at the interface between the high-diffusive cerebrospinal fluid surrounding the brain and the low-diffusive grey matter. It also tends to appear bright in glioblastomas, due to their non-uniform cell density. Variance of shapes The variance of shapes is given by \[ \mathrm{V}[D_\Delta^2] = \mathrm{E}[D_\Delta^4] - \mathrm{E}[D_\Delta^2]^2\, . \] \(\mathrm{V}[D_\Delta^2]\) reports on variations in cell elongation within the voxel content. The higher \(\mathrm{V}[D_\Delta^2]\), the more diverse cell elongations in a given voxel. Covariance of sizes and shapes The covariance of sizes and shapes is given by \[ \mathrm{C}[D_\mathrm{iso}, D_\Delta^2] = \mathrm{E}[D_\mathrm{iso}D_\Delta^2] - \mathrm{E}[D_\mathrm{iso}]\,\mathrm{E}[D_\Delta^2]\,. \] \(\mathrm{C}[D_\mathrm{iso}, D_\Delta^2]\) reports on whether or not diffusivity (roughly the inverse of cell density in tissue) correlates with diffusion anisotropy (cell elongation in tissue) within a given voxel. If components of high diffusivity tend to have high/low anisotropy and vice versa, then \(\mathrm{C}[D_\mathrm{iso}, D_\Delta^2]\) is positive/negative. If no specific trend exists, \(\mathrm{C}[D_\mathrm{iso}, D_\Delta^2]\) is zero. Let us, for instance, consider an heterogeneous voxel content featuring both cerebrospinal fluid from the ventricles and white matter, or both cerebrospinal fluid surrounding the brain and grey matter. In this case, the tissue components of high diffusivity are those of lowest anisotropy, and vice versa. \(\mathrm{C}[D_\mathrm{iso}, D_\Delta^2]\) is therefore negative. Computing the mean diffusion tensor using the DTD method The output of the DTD algorithm for a given bootstrap realization reads as a set of tuples, \[ \{(D_{\parallel,n}, D_{\perp,n}, \theta_n, \phi_n, w_n)\}_{1\leq n \leq N_\mathrm{out}}\, , \] wherein each tuple represents an axisymmetric diffusion tensor with probabilistic weight given by \(w_n/\sum_{n=1}^{N_\mathrm{out}} w_n = w_n/\mathcal{S}_0\). To compute the mean diffusion tensor \(\langle \mathbf{D}\rangle\) associated with this discrete distribution of diffusion tensors, one needs to follow these steps: For each \(n\), compute the diagonal diffusion tensor \(\mathbf{D}^\mathrm{(diag)}_n = \mathrm{Diag}(D_{\perp,n}, D_{\perp,n}, D_{\parallel,n})\), which has \(\begin{pmatrix} 0 &amp; 0 &amp; 1\end{pmatrix}\) as main eigenvector by construction. For each \(n\), rotate \(\mathbf{D}^\mathrm{(diag)}_n\) according to \(\mathbf{D}_n =\mathbf{R}(\theta_n,\phi_n) \cdot \mathbf{D}^\mathrm{(diag)}_n \cdot \mathbf{R}^{\mathrm{T}}(\theta_n,\phi_n)\). Compute the mean diffusion tensor as \[ \langle \mathbf{D} \rangle = \frac{\sum_{n=1}^{N_\mathrm{out}} w_n\, \mathbf{D}_n}{\sum_{n=1}^{N_\mathrm{out}} w_n} = \frac{1}{\mathcal{S}_0} \sum_{n=1}^{N_\mathrm{out}} w_n\, \mathbf{D}_n \, . \] Note that the mean diffusion tensor \(\langle \mathbf{D} \rangle\) is not necessarily axisymmetric. Moreover, the rotational invariance of the trace implies that the mean diffusivity corresponds to \[ \frac{\mathrm{Tr}(\langle \mathbf{D} \rangle)}{3} = \frac{\sum_{n=1}^{N_\mathrm{out}} w_n\, [\mathrm{Tr}(\mathbf{D}_n)/3]}{\sum_{n=1}^{N_\mathrm{out}} w_n} = \frac{\sum_{n=1}^{N_\mathrm{out}} w_n\, D_{\mathrm{iso},n}}{\sum_{n=1}^{N_\mathrm{out}} w_n} = \mathrm{E}[D_\mathrm{iso}] \, . \] Fractional anisotropy [QTI/DTD] The fractional anisotropy (\(\mathrm{FA}\)) [@Pierpaoli_Basser:1996] is obtained as \[ \mathrm{FA} = \left[ \frac{2}{3} \left( 1 + \frac{\lambda_\mathrm{iso}^2}{V_\lambda} \right) \right]^{-1/2} = \left[ \frac{2}{3} \left( 1 + \frac{3}{2\lambda_\Delta^2(\lambda_\eta^2 + 3)} \right) \right]^{-1/2} \in [0,1] \, , \] where \(\lambda_\mathrm{iso}\), \(\lambda_\Delta\) and \(\lambda_\eta\) are the isotropic diffusivity, normalized anisotropy and asymmetry of the mean diffusion tensor \(\langle \mathbf{D} \rangle\), respectively. \(V_\lambda = 2\lambda_\mathrm{iso}^2\lambda_\Delta^2(\lambda_\eta^2 + 3)/3\) is the variance of \(\langle \mathbf{D} \rangle\)'s eigenvalues. \(\mathrm{FA}\) reports on the voxel-averaged anisotropy of the voxel content. The higher the \(\mathrm{FA}\), the more anisotropic the voxel content on the voxel scale. This means that reaching a high \(\mathrm{FA}\) requires that (i) the voxel contains elongated cells and that (ii) these cells are aligned over the typical lengh-scale associated with the voxel size. This explains why \(\mathrm{FA}\) vanishes in areas of crossing fibers, because the diffusion profile of these crossing configurations tend to appear isotropic on the voxel scale. In other words, \(\mathrm{FA}\) confonds the effects of microscopic anisotropy (see \(\mu\mathrm{FA}\) below) and orientational order (see \(\mathrm{OP}\) below). Microscopic fractional anisotropy [QTI/DTD] The microscopic fractional anisotropy (\(\mu\mathrm{FA}\)) [@Lasic:2014 ; @Szczepankiewicz:2015 ; @Szczepankiewicz:2016] is defined as \[ \mu\mathrm{FA} = \left[ \frac{2}{3} \left( 1 + \frac{\mathrm{E}[D_\mathrm{iso}]^2 + \mathrm{V}[D_\mathrm{iso}]}{2\, \mathrm{E}[D_\mathrm{iso}^2 D_\Delta^2]} \right) \right]^{-1/2} \in [0,1]\, , \] where \(\mathrm{E}[D_\mathrm{iso}^2 D_\Delta^2]\) is an additional statistical descriptor that needs to be computed for this purpose. Note that no diffusion asymmetry \(D_\eta\) is involved in this calculation, because the microscopic diffusion tensors used to compute the statistical descriptors of the diffusion tensor distribution are axisymmetric. \(\mu\mathrm{FA}\) reports on microscopic anisotropy by quantifying the average anisotropy of the voxel content's cellular components, disregarding whether or not these cells are aligned or not on the voxel scale. Importantly, one has \(\mathrm{FA} \leq \mu\mathrm{FA}\). Unlike \(\mathrm{FA}\), \(\mu\mathrm{FA}\) does not vanish in areas of crossing fibers and at the interface between white matter and grey matter. This explains why \(\mu\mathrm{FA}\) correlates with clinical scores in multiple sclerosis [@Andersen_Lasic:2020] and enables to differentiate cortex and white matter in malformations of cortical development associated with epilepsy [@Lampinen_epilepsy:2020]. These works support the idea that \(\mu\mathrm{FA}\) can serve as a proper biomarker of white-matter integrity. Orientational order parameter [QTI/DTD] The orientational order parameter (\(\mathrm{OP}\)) can be defined as \[ \mathrm{OP} = \left(\frac{\mathrm{FA}}{\mu\mathrm{FA}}\right)^2 \in [0,1] \, . \] The bounds of \(\mathrm{OP}\) are justified by the fact that $0 \leq \mathrm \leq \mu\mathrm$. Note that \(\mathrm{OP}\) is meaningful only if the voxel content contains an amount of elongated cells sufficient to ensure that \(\mu\mathrm{FA}\) does not approach zero too closely, which would render \(\mathrm{OP}\) very sensitive to any noise in the data inversion. This mathematical constraint translates the fact that measuring orientational order is only meaningful when studying elongated cells, as isotropic cells do not possess an intrinsic orientation. With this constraint implemented, an \(\mathrm{OP}\) map tends to resemble an \(\mathrm{FA}\) map, with \(\mathrm{OP}\) vanishing in particular in areas of crossing fibers. In fact, \(\mathrm{FA}\) can be roughly thought as the product between \(\mu\mathrm{FA}\) and \(\mathrm{OP}\) [@Lasic:2014]. Directionally encoded color (DEC) maps In greyscale maps, information is only conveyed via intensity (contrast). Additional information can be brought upon coloring such maps. In QTI, each map related to anisotropy is available in its original greyscale version and in a &ldquo;directionally encoded color&rdquo; (DEC) version. While the intensity of DEC maps is given by the anisotropy measure of interest (e.g. \(\mathrm{FA}\), \(\mu\mathrm{FA}\), etc., their colors code for the main orientation of the voxel-averaged diffusion tensor \(\langle \mathbf{D}\rangle\) according to the following RGB triplet: \[ \text{[red, green, blue] = [left-right, anterior-posterior, superior-inferior]} \, . \] With this convention, the corpus callosum appears mostly red, the arcuate fasciculus appears mostly green, and the corticospinal tract appears mostly blue. Segmentation map and bin-specific maps Once several component bins are defined, one can use the segmentation map to identify where components falling into each bin are located. In the case of the three default &ldquo;thin&rdquo;, &quot;thick&quot; and &ldquo;big&rdquo; bins, the segmentation map as unit intensity and color corresponding to the respective bin signal fractions as \[ \text{[red, green, blue]} = \frac{1}{\mathrm{max}(f_\mathrm{thin},f_\mathrm{thick},f_\mathrm{big})} \, \frac{[f_\mathrm{thin}, f_\mathrm{thick}, f_\mathrm{big}]}{f_\mathrm{thin}+f_\mathrm{thick}+f_\mathrm{big}} \, . \] While the sum of signal fractions ensures the unit intensity of the segmentation map (in case outlier components fall out of the bin definitions), the maximum of signal fractions allows for smooth handling of heterogeneous voxels containing components belonging to distinct bins. All aforementioned statistical descriptors can also be mapped within specific bins (e.g. as a thick-bin mean size map, \(\mathrm{E}[D_\mathrm{iso}]_\mathrm{thick}\)). While the intensity of such maps is given by the signal fraction of the components falling into a given bin (e.g. \(f_\mathrm{thick}\)), their color code for the value of the mapped statistical descriptors (e.g. \(\mathrm{E}[D_\mathrm{iso}]\)) computed within that bin. The corresponding colormap goes from blue to red with increasing statistical descriptor and is common to all three bins, enabling simple comparisons between bin-specific maps aasociated with the same statistical descriptor. ", "tags": "", "url": "dviewr.theory.diffusion_tensor_distribution_imaging_(dtd).diffusion_measures.html"},
{"title": "Drawbacks", "text": "Drawbacks Due to its rather unconstrained nature, the DTD method is known to be noise-sensitive [@Reymbaut_accuracy_precision:2020]. Indeed, it merely estimates a set of diffusion components that best fits the measured signal. If the signal is noisy, the solution retrieved by the DTD method will also fit the acquisition noise. In particular, DTD tends to overestimate microscopic anisotropy in isotropic tissues. This problem is similar to the noise-induced overestimation of anisotropy observed in the context of diffusion tensor imaging [@Jones_Basser:2004]. Nonetheless, the noise sensitivity of the DTD method can be mitigated upon acquiring multiple b-tensor shapes and/or applying denoising/debiasing techniques to the acquired signals prior to data analysis. ", "tags": "", "url": "dviewr.theory.diffusion_tensor_distribution_imaging_(dtd).drawbacks.html"},
]};